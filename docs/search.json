[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Data Skills",
    "section": "",
    "text": "Overview\nThis book provides an overview of the basic skills needed to turn raw data into informative summaries and visualisations presented in professional reports and presentations. The book will introduce learners to R (R Core Team, 2022), a programming language that can help automate working with data. The book will cover importing and processing data from spreadsheets, producing data summaries of descriptive statistics in tables, creating beautiful and informative visualisations, and constructing reports and presentations that automatically update when the underlying data changes.\nBy the end of this book, you will be able to use R to:"
  },
  {
    "objectID": "index.html#structure-of-the-course",
    "href": "index.html#structure-of-the-course",
    "title": "Applied Data Skills",
    "section": "Structure of the course",
    "text": "Structure of the course\nThis book accompanies a 10-week course, covering one chapter per week. Each chapter will introduce you to some new skills and concepts using concrete examples. At various points, there will be multiple-choice or fill-in-the-blank questions for you to check your understanding. Each chapter has accompanying walk-through videos, where an instructor demonstrates the skills covered in the chapter. Each chapter also has accompanying exercises that you should do to reinforce your learning."
  },
  {
    "objectID": "index.html#how-to-learn-data-skills",
    "href": "index.html#how-to-learn-data-skills",
    "title": "Applied Data Skills",
    "section": "How to learn data skills",
    "text": "How to learn data skills\n\n\n\nLearning data skills is kind of like having a gym membership - you’ll be given state-of-the-art equipment to use and instructions for how to use them, but your data skills won’t get any stronger unless you practice.\n\n\n\nData skills do not require you to memorise lots of code. You will be introduced to many different functions, but the main skill to learn is how to efficiently find the information you need. This will require getting used to the structure of help files and cheat sheets, learning how to Goggle your problem and choose a helpful solution, and learning how to read error messages.\n\n\n\nLearning to code involves making a lot of mistakes. These mistakes are completely essential to the process, so try not to feel too frustrated. Many of the chapter exercises will give you broken code to fix so you get experience seeing what common errors look like. As you become a more experienced coder, you might not make fewer errors, but you’ll recover from them much faster.\n\n\n\n\nR Core Team. (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/"
  },
  {
    "objectID": "01-intro.html#sec-ilo-intro",
    "href": "01-intro.html#sec-ilo-intro",
    "title": "1  Intro to R and RStudio",
    "section": "Intended Learning Outcomes",
    "text": "Intended Learning Outcomes\n\nInstall R and RStudio\nBe able to install add-on packages\nBe able to get help for packages and functions\nBe able to create objects by writing and running code in the console"
  },
  {
    "objectID": "01-intro.html#functions-ch01",
    "href": "01-intro.html#functions-ch01",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.1 Functions used",
    "text": "1.1 Functions used\n.rs.restartR(), ?, Sys.Date(), as.Date(), beep(), devtools::install_github(), install.packages(), library(), paste(), sample(), vignette()."
  },
  {
    "objectID": "01-intro.html#sec-walkthrough-intro",
    "href": "01-intro.html#sec-walkthrough-intro",
    "title": "1  Intro to R and RStudio",
    "section": "Walkthrough video",
    "text": "Walkthrough video\nThere is a walkthrough video of this chapter available via Echo360. We recommend first trying to work through each section of the book on your own and then watching the video if you get stuck, or if you would like more information. This will feel slower than just starting with the video, but you will learn more in the long-run. Please note that there may have been minor edits to the book since the video was recorded. Where there are differences, the book should always take precedence.\nDownload the RStudio IDE Cheatsheet"
  },
  {
    "objectID": "01-intro.html#sec-intro-installing-r",
    "href": "01-intro.html#sec-intro-installing-r",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.2 Installing R and RStudio",
    "text": "1.2 Installing R and RStudio\nR is a programming language that you will write code in and RStudio is a program that makes working in R easier.\nAppendix A has technical details on installing R and RStudio on your computer. If you need any help installing R, please ask on Teams or attend office hours. Once you have installed R and RStudio, come back to this chapter. If you already had R and/or RStudio installed, we recommend updating to the latest version before you work through this course. Appendix B has more details on how to do that. Here, we’ll concentrate on introducing you to RStudio’s interface and getting it configured.\n\n\n\n\n\n\nBook version\n\n\n\nThis book was created using R version 4.3.1 (2023-06-16 ucrt) (Beagle Scouts) and RStudio version 2022.12.0.353 (Elsbeth Geranium). Most of the content of this book will work fine in versions of R above 4.0 and earlier versions of RStudio, although there may be some small differences in the interface.\n\n\n\n\n1.2.1 RStudio\nWhen you installed R, that gave your computer the ability to process the R programming language, and also installed an app called “R”. We will never use that app. Instead, we will use RStudio.\nRStudio is an Integrated Development Environment (IDE). Think of it as knowing English and using a plain text editor like NotePad to write a book versus using a word processor like Microsoft Word. You could do it, but it would be much harder without things like spell-checking and formatting and you wouldn’t be able to use some of the advanced features that Word has developed. In a similar way, you can use R without R Studio but we wouldn’t recommend it. RStudio serves as a text editor, file manager, spreadsheet viewer, and more. The key thing to remember is that although you will do all of your work using RStudio for this course, you are actually using two pieces of software, which means that from time to time, both of them may have separate updates.\nRStudio is arranged with four window panes.\n\n\n\n\nFigure 1.1: The RStudio IDE\n\n\n\nBy default, the upper left pane is the source pane, where you view, write, and edit code from files and view data tables in a spreadsheet format. When you first open RStudio, this pane won’t display until we open a document or load in some data – don’t worry, we’ll get to that soon.\nThe lower left pane is the console pane, where you can type in commands and view output messages. You can write code in the console to test it out. The code will run and can create objects in the environment, but the code itself won’t be saved. You need to write your code into a script in the source pane to save it, which we’ll cover in Chapter 2.\nThe right panes have several different tabs that show you information about your code. The most used tabs in the upper right pane are the Environment tab and the Help tab. The Environment tab lists some information about the objects that you have defined in your code. We’ll learn more about the Help tab in Section 1.4.5.\nIn the lower right pane, the most used tabs are the Files tab for directory structure, the Plots tab for plots made in a script, the Packages tab for managing add-on packages (see Section 1.4), and the Viewer tab to display reports created by your scripts. You can change the location of panes and what tabs are shown under Tools &gt; Global Options… &gt; Pane Layout.\n\n1.2.2 Reproducibility\nIn this class, you will be learning how to make reproducible reports. This involves writing scripts that transform data, create summaries and visualisations, and embed them in a report in a way that always gives you the same results.\nWhen you do things reproducibly, others (and future you) can understand and check your work. You can also reuse your work more easily. For example, if you need to create a report every month with the social media analytics for your company, a reproducible report allows you to download a new month’s data and create the report within seconds. It might take a little longer to set up the report in the first instance with reproducible methods, but the time it saves you in the long run is invaluable.\n\n\n\n\n\n\nSettings for Reproducibility\n\n\n\nSection A.4 shows you how to change two important settings in the Global Options to increase reproducibility. Your settings should have:\n\nRestore .RData into workspace at startup: \nChecked\nNot Checked\n\nSave workspace to .RData on exit: \nAlways\nNever\nAsk\n\n\n\n\n\n1.2.3 Themes and accessiblilty\nYou can customise how R Studio looks to make it work for you. Click Tools &gt; Global Options &gt; Appearance. You can change the default font, font size, and general appearance of R Studio, including using dark mode. Play around with the settings and see what you prefer - you’re going to spend a lot of time with R, it might as well look nice!"
  },
  {
    "objectID": "01-intro.html#sec-intro-sessions",
    "href": "01-intro.html#sec-intro-sessions",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.3 Sessions",
    "text": "1.3 Sessions\nIf you have the above settings configured correctly, when you open up RStudio and start writing code, loading packages, and creating objects, you will be doing so in a new session and your Environment tab should be completely empty. If you find that your code isn’t working and you can’t figure out why, it might be worth restarting your R session. This will clear the environment and detach all loaded packages - think of it like restarting your phone. There are several ways that you can restart R:\n\nMenu: Session &gt; Restart R\n\n\nCmd-Shift-F10 or Ctl-Shift-F10\n\ntype .rs.restartR() in the console\n\nTry doing each of these now. Additionally, now would be a good time to create a notebook where you can keep a record of useful hints and tips and things to try when your code isn’t working. Add “restart R session” to this notebook as your first item."
  },
  {
    "objectID": "01-intro.html#sec-packages",
    "href": "01-intro.html#sec-packages",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.4 Packages and functions",
    "text": "1.4 Packages and functions\nWhen you install R you will have access to a range of functions including options for data wrangling and statistical analysis. The functions that are included in the default installation are typically referred to as base R and you can think of them like the default apps that come pre-loaded on your phone.\nOne of the great things about R, however, is that it is user extensible: anyone can create a new add-on that extends its functionality. There are currently thousands of packages that R users have created to solve many different kinds of problems, or just simply to have fun. For example, there are packages for data visualisation, machine learning, interactive dashboards, web scraping, and playing games such as Sudoku.\nAdd-on packages are not distributed with base R, but have to be downloaded and installed from an archive, in the same way that you would, for instance, download and install PokemonGo on your smartphone. The main repository where packages reside is called CRAN, the Comprehensive R Archive Network.\nThere is an important distinction between installing a package and loading a package.\n\n1.4.1 Installing a package\n\nThis is done using install.packages(). This is like installing an app on your phone: you only have to do it once and the app will remain installed until you remove it. For instance, if you want to use PokemonGo on your phone, you install it once from the App Store or Play Store; you don’t have to re-install it each time you want to use it. Once you launch the app, it will run in the background until you close it or restart your phone. Likewise, when you install a package, the package will be available (but not loaded) every time you open up R.\nInstall the tidyverse package on your system. This is the main package we will use throughout this book for data wrangling, summaries, and visualisation. It is actually a bundle of packages, which we’ll explain further in Section 1.4.4.\n\n\n\nRun in the console\n\ninstall.packages(\"tidyverse\")\n\n\nIf you get a message that says something like package ‘tidyverse’ successfully unpacked and MD5 sums checked, the installation was successful. If you get an error and the package wasn’t installed, check the troubleshooting section of Section B.4.\n\n\n\n\n\n\nInstall packages from the console only\n\n\n\nNever install a package from inside a script. Only do this from the console pane or the packages tab of the lower right pane.\n\n\nHere are some other packages you’ll want to install for the first two chapters.\n\n\n\nRun in the console\n\ninstall.packages(\"beepr\") # for beeps\ninstall.packages(\"rmarkdown\") # for creating R markdown files\ninstall.packages(\"devtools\")  # for installing packages from github\n\n\nOnce you’ve installed the devtools package, you can also install packages from repositories other than CRAN, such as github. The following code installs the development version of a package for making waffle plots.\n\n\n\nRun in the console\n\n# install waffle package \ndevtools::install_github(\"hrbrmstr/waffle\")\n\n\n\n1.4.2 Loading a package\nThis is done using the library() function. This is like launching an app on your phone: the functionality is only there where the app is launched and remains there until you close the app or restart. For example, when you run library(devtools) within a session, the functions in the package referred to by devtools will be made available for your R session. The next time you start R, you will need to run library(devtools) again if you want to access that package.\nAfter installing the beepr package, you can load it for your current R session as follows:\n\n\n\nRun in the console\n\nlibrary(beepr)\n\n\nYou might get some red text when you load a package, this is normal. It is usually warning you that this package has functions that have the same name as other packages you’ve already loaded.\n\n\n\n\n\n\nNote\n\n\n\nYou can use the convention package::function() to indicate in which add-on package a function resides. For instance, if you see readr::read_csv(), that refers to the function read_csv() in the {readr} add-on package. If the package is loaded using library(), you don’t have to specify the package name before a function unless there is a conflict (e.g., you have two packages loaded that have a function with the same name).\n\n\n\n1.4.3 Using a function\nNow you can run the function beep().\n\n\n\nRun in the console\n\nbeep()\n\n\nA function is a name that refers to some code you can reuse. We’ll start by using functions that are provided for you in packages, but you can also write your own functions. After the function name, there is a pair of parentheses, which contain zero or more arguments. These are options that you can set. In the example above, the sound argument has a default value of 1, which makes a “ping” sound. Try changing the argument to an integer between 1 and 11.\n\n\n\nRun in the console\n\nbeep(sound = 8)\n\n\nIf you type a function into the console pane, it will run as soon as you hit enter. If you put the function in a script or R Markdown document in the source pane, it won’t run until you run the script, knit the R Markdown file, or run a code chunk. You’ll learn more about this in Chapter 2.\n\n1.4.4 Tidyverse\ntidyverse is a meta-package that loads several packages we’ll be using in almost every chapter in this book:\n\n\nggplot2, for data visualisation (Chapter 3)\n\nreadr, for data import (Appendix G)\n\ntibble, for tables (Appendix G)\n\ntidyr, for data tidying (?sec-tidy)\n\ndplyr, for data manipulation (?sec-wrangle)\n\nstringr, for strings\n\n\nforcats, for factors\n\n\npurrr, for repeating things\n\nWhen you install tidyverse, it also installs some other useful packages that you can load individually. You can get the full list using tidyverse_packages(), but the packages we’ll be using in this book are:\n\n\ngooglesheets4, for working with Google spreadsheets\n\nreadxl, for Excel files\n\nlubridate, for working with dates\n\nhms, for working with times\n\nrvest, for web scraping\n\n1.4.5 Function Help\nWhen you load the tidyverse it automatically loads all of the above packages, however, it can be helpful to know which package a function comes from if you need to Google it. If a function is in base R or a loaded package, you can type ?function_name in the console to access the help file. At the top of the help it will give you the function and package name.\nIf the package isn’t loaded, use ?package_name::function_name or specify the package in the help() function. When you aren’t sure what package the function is in, use the shortcut ??function_name.\n\n\n\nRun in the console\n\n# if the package is loaded\n?beepr\nhelp(\"beepr\")\n\n# works whether or not the package is loaded\n?beepr::beep\nhelp(\"beep\", package=\"beepr\") \n\n# shows a list of potentially matching functions\n??beep\n\n\n\n\n\nFunction help is always organised in the same way. For example, look at the help for ?beepr::beep. At the top, it tells you the name of the function and its package in curly brackets, then a short description of the function, followed by a longer description. The Usage section shows the function with all of its arguments. If any of those arguments have default values, they will be shown like function(arg = default). The Arguments section lists each argument with an explanation. There may be a Details section after this with even more detail about the functions. The Examples section is last, and shows examples that you can run in your console window to see how the function works.\n\n\n\n\n\n\nFunction Help\n\n\n\n\nWhat is the first argument to the mean function? \ntrim\nna.rm\nmean\nx\n\nWhat package is read_excel in? \nreadr\nreadxl\nbase\nstats\n\n\n\n\n\n1.4.6 Arguments\nYou can look up the arguments/options that a function has by using the help documentation. Some arguments are required, and some are optional. Optional arguments will often use a default (normally specified in the help documentation) if you do not enter any value.\nAs an example, look at the help documentation for the function sample() which randomly samples items from a list.\n\n\n\nRun in the console\n\n?sample\n\n\nThe help documentation for sample() should appear in the bottom right help panel. In the usage section, we see that sample() takes the following form:\n\nsample(x, size, replace = FALSE, prob = NULL)\n\nIn the arguments section, there are explanations for each of the arguments. x is the list of items we want to choose from, size is the number of items we want to choose, replace is whether or not each item may be selected more than once, and prob gives the probability that each item is chosen. In the details section it notes that if no values are entered for replace or prob it will use defaults of FALSE (each item can only be chosen once) and NULL (all items will have equal probability of being chosen). Because there is no default value for x or size, they must be specified otherwise the code won’t run.\nLet’s try an example and just change the required arguments to x and size to ask R to choose 5 random letters (letters is a built-in vector of the 26 lower-case Latin letters).\n\nsample(x = letters, size = 5)\n\n[1] \"z\" \"v\" \"y\" \"w\" \"j\"\n\n\n\n\n\n\n\n\nWhy are my letters different to your letters?\n\n\n\n\n\nsample() generates a random sample. Each time you run the code, you’ll generate a different set of random letters (try it). The function set.seed() controls the random number generator - if you’re using any functions that use randomness (such as sample()), running set.seed() will ensure that you get the same result (in many cases this may not be what you want to do). To get the same numbers we do, run set.seed(1242016) in the console, and then run sample(x = letters, size = 5) again.\n\n\n\nNow we can change the default value for the replace argument to produce a set of letters that is allowed to have duplicates.\n\nset.seed(8675309)\nsample(x = letters, size = 5, replace = TRUE)\n\n[1] \"t\" \"k\" \"j\" \"k\" \"m\"\n\n\nThis time R has still produced 5 random letters, but now this set of letters has two instances of “k”. Always remember to use the help documentation to help you understand what arguments a function requires.\n\n1.4.7 Argument names\nIn the above examples, we have written out the argument names in our code (i.e., x, size, replace), however, this is not strictly necessary. The following two lines of code would both produce the same result (although each time you run sample() it will produce a slightly different result, because it’s random, but they would still work the same):\n\nsample(x = letters, size = 5, replace = TRUE)\nsample(letters, 5, TRUE)\n\nImportantly, if you do not write out the argument names, R will use the default order of arguments. That is, for sample it will assume that the first value you enter is x, the second value is size and the third value is replace.\nIf you write out the argument names, then you can write the arguments in whatever order you like:\n\nsample(size = 5, replace = TRUE, x = letters)\n\nWhen you are first learning R, you may find it useful to write out the argument names as it can help you remember and understand what each part of the function is doing. However, as your skills progress you may find it quicker to omit the argument names and you will also see code examples online that do not use argument names, so it is important to be able to understand which argument each bit of code is referring to (or look up the help documentation to check).\nIn this course, we will always write out the argument names the first time we use each function. However, in subsequent uses they may be omitted.\n\n1.4.8 Tab auto-complete\nOne very useful feature of R Studio is tab auto-complete for functions. If you write the name of the function and then press the tab key, R Studio will show you the arguments that function takes along with a brief description. If you press enter on the argument name it will fill in the name for you, just like auto-complete on your phone. This is incredibly useful when you are first learning R and you should remember to use this feature frequently.\n\n\n\n\nFigure 1.2: Tab auto-complete"
  },
  {
    "objectID": "01-intro.html#sec-objects",
    "href": "01-intro.html#sec-objects",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.5 Objects",
    "text": "1.5 Objects\nA large part of your coding will involve creating and manipulating objects. Objects contain stuff. That stuff can be numbers, words, or the result of operations and analyses. You assign content to an object using &lt;-.\nRun the following code in the console, but change the values of name and age to your own details and change christmas to a holiday or date you care about.\n\n\n\nRun in the console\n\nname &lt;- \"Emily\"\nage &lt;- 36\ntoday &lt;- Sys.Date()\nchristmas &lt;- as.Date(\"2024-12-25\")\n\n\nYou’ll see that four objects now appear in the environment pane:\n\n\nname is character (text) data. In order for R to recognise it as text, it must be enclosed in double quotation marks \" \".\n\nage is numeric data. In order for R to recognise this as a number, it must not be enclosed in quotation marks.\n\ntoday stores the result of the function Sys.Date(). This function returns your computer system’s date. Unlike name and age, which are hard-coded (i.e., they will always return the values you enter), the contents of the object today will change dynamically with the date. That is, if you run that function tomorrow, it will update the date to tomorrow’s date.\n\nchristmas is also a date but it’s hard-coded as a specific date. It’s wrapped within the as.Date() function that tells R to interpret the character string you provide as a date rather than text.\n\n\n\n\n\n\n\nNote\n\n\n\nTo print the contents of an object, type the object’s name in the console and press enter. Try printing all four objects now.\n\n\nFinally, a key concept to understand is that objects can interact and you can save the results of those interactions in new object. Edit and run the following code to create these new objects, and then print the contents of each new object.\n\n\n\nRun in the console\n\ndecade &lt;- age + 10\nfull_name &lt;- paste(name, \"Nordmann\")\nhow_long &lt;- christmas - today"
  },
  {
    "objectID": "01-intro.html#sec-help",
    "href": "01-intro.html#sec-help",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.6 Getting help",
    "text": "1.6 Getting help\nYou will feel like you need a lot of help when you’re starting to learn. This won’t really go away; it’s impossible to memorise everything. The goal is to learn enough about the structure of R that you can look things up quickly. This is why we’ll introduce specialised jargon in the glossary for each chapter; it’s easier to google “convert character to numeric in R” than “make numbers in quotes be actual numbers not words”. In addition to the function help described above, here’s some additional resources you should use often.\n\n1.6.1 Package reference manuals\nStart up help in a browser by entering help.start() in the console. Click on Packages under Reference to see a list of packages. Scroll down to the readxl package and click on it to see a list of the functions that are available in that package.\n\n1.6.2 Googling\nIf the function help doesn’t help, or you’re not even sure what function you need, try Googling your question. It will take some practice to be able to use the right jargon in your search terms to get what you want. It helps to put “R” or “tidyverse” in the search text, or the name of the relevant package, like “ggplot2”.\n\n1.6.3 AI\nGenerative AI platforms have exploded in popularity, particularly when it comes to coding. Because of this, we have created a companion book AITutoR to show you how to use AI responsibly to support your coding journey.\n\n1.6.4 Vignettes\nMany packages, especially tidyverse ones, have helpful websites with vignettes explaining how to use their functions. Some of the vignettes are also available inside R. You can access them from a package’s help page or with the vignette() function.\n\n\n\nRun in the console\n\n# opens a list of available vignettes\nvignette(package = \"ggplot2\")\n\n# opens a specific vignette in the Help pane\nvignette(\"ggplot2-specs\", package = \"ggplot2\")"
  },
  {
    "objectID": "01-intro.html#sec-glossary-intro",
    "href": "01-intro.html#sec-glossary-intro",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.7 Glossary",
    "text": "1.7 Glossary\nThe glossary at the end of each chapter defines common jargon you might encounter while learning R. This specialised vocabulary can help you to communicate more efficiently and to search for solutions to problems. The terms below link to our PsyTeachR glossary, which contains further information and examples.\n\n\n\n\n\nterm\n\n\ndefinition\n\n\n\n\n\nargument\n\n\nA variable that provides input to a function.\n\n\n\n\nbase R\n\n\nThe set of R functions that come with a basic installation of R, before you add external packages.\n\n\n\n\ncharacter\n\n\nA data type representing strings of text.\n\n\n\n\nchunk\n\n\nA section of code in an R Markdown file\n\n\n\n\nconflict\n\n\nHaving two packages loaded that have a function with the same name.\n\n\n\n\nCRAN\n\n\nThe Comprehensive R Archive Network: a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R.\n\n\n\n\ndata wrangling\n\n\nThe process of preparing data for visualisation and statistical analysis.\n\n\n\n\ndefault value\n\n\nA value that a function uses for an argument if it is skipped.\n\n\n\n\nfactor\n\n\nA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimenter\n\n\n\n\nfunction\n\n\nA named section of code that can be reused.\n\n\n\n\nIDE\n\n\nIntegrated Development Environment: a program that serves as a text editor, file manager, and provides functions to help you read and write code. RStudio is an IDE for R.\n\n\n\n\nknit\n\n\nTo create an HTML, PDF, or Word document from an R Markdown (Rmd) document\n\n\n\n\nnumeric\n\n\nA data type representing a real decimal number or integer.\n\n\n\n\nobject\n\n\nA word that identifies and stores the value of some data for later use.\n\n\n\n\npackage\n\n\nA group of R functions.\n\n\n\n\npanes\n\n\nRStudio is arranged with four window “panes”.\n\n\n\n\nR Markdown\n\n\nThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.\n\n\n\n\nscript\n\n\nA plain-text file that contains commands in a coding language, such as R.\n\n\n\n\nstring\n\n\nA piece of text inside of quotes.\n\n\n\n\nvector\n\n\nA type of data structure that collects values with the same data type, like T/F values, numbers, or strings."
  },
  {
    "objectID": "01-intro.html#sec-resources-intro",
    "href": "01-intro.html#sec-resources-intro",
    "title": "1  Intro to R and RStudio",
    "section": "\n1.8 Further Resources",
    "text": "1.8 Further Resources\n\nRStudio IDE Cheatsheet\nRStudio Cloud"
  },
  {
    "objectID": "02-reports.html#sec-ilo-reports",
    "href": "02-reports.html#sec-ilo-reports",
    "title": "2  Reports with R Markdown",
    "section": "Intended Learning Outcomes",
    "text": "Intended Learning Outcomes\n\nBe able to structure a project\nBe able to knit a simple reproducible report with R Markdown\nBe able to create code chunks, tables, images, and inline R in an R Markdown document"
  },
  {
    "objectID": "02-reports.html#functions-ch02",
    "href": "02-reports.html#functions-ch02",
    "title": "2  Reports with R Markdown",
    "section": "\n2.1 Functions used",
    "text": "2.1 Functions used\ncount(), filter(), geom_bar(), geom_col(), ggplot(), include_graphics(), install_tinytex(), kable(), kable_classic(), labs(), max(), min(), nrow(), read_csv(), row_spec(), str(), summary(), View().\nDownload the R Markdown Cheat Sheet"
  },
  {
    "objectID": "02-reports.html#sec-walkthrough-reports",
    "href": "02-reports.html#sec-walkthrough-reports",
    "title": "2  Reports with R Markdown",
    "section": "Walkthrough video",
    "text": "Walkthrough video\nThere is a walkthrough video of this chapter available via Echo360. Please note that there may have been minor edits to the book since the video was recorded. Where there are differences, the book should always take precedence."
  },
  {
    "objectID": "02-reports.html#sec-setup-reports",
    "href": "02-reports.html#sec-setup-reports",
    "title": "2  Reports with R Markdown",
    "section": "\n2.2 Setup",
    "text": "2.2 Setup\nFor reference, here are the packages we will use in this chapter. You may need to install them, as explained in Section 1.4.1, if running the code below in the console pane gives you the error Error in library(package_name) : there is no package called ‘packagename’.\n\n\n\nChapter packages\n\nlibrary(tidyverse)  # various data manipulation functions\nlibrary(knitr)      # for rendering a report from a script\nlibrary(rmarkdown)  # for using R markdown\nlibrary(kableExtra) # for styling tables"
  },
  {
    "objectID": "02-reports.html#sec-projects",
    "href": "02-reports.html#sec-projects",
    "title": "2  Reports with R Markdown",
    "section": "\n2.3 Organising a project",
    "text": "2.3 Organising a project\nBefore we write any code, first, we need to get organised. Projects in RStudio are a way to group all the files you need for one project. Most projects include scripts, data files, and output files like the PDF report created by the script or images.\n\n2.3.1 Default working directory\nFirst, make a new directory (i.e., folder) on your computer where you will keep all of your R projects. Name it something like “R-projects” (avoid spaces and other special characters). Make sure you know how to get to this directory using your computer’s Finder or Explorer.\n\n\n\n\n\n\nAvoid networked drives\n\n\n\nIf possible, don’t use a network or cloud drive (e.g., OneDrive or Dropbox), as this can sometimes cause problems. If you’re working from a networked drive and you are having issues, a helpful test is to try moving your project folder to the desktop to see if that solves the problem.\n\n\nNext, open Tools &gt; Global Options…, navigate to the General pane, and set the “Default working directory (when not in a project)” to this directory. Now, if you’re not working in a project, any files or images you make will be saved in this working directory.\n\n\n\n\n\n\nAvoid long path names\n\n\n\nOn some versions of Windows 10 and 11, it can cause problems if path names are longer than 260 characters. Set your default working directory to a path with a length well below that to avoid problems when R creates temporary files while rendering a report. If you are having issues, a helpful test is to try moving your project folder to the desktop to see if that solves the problem as this will likely have a much short path name than most other folders on your computer.\n\n\nYou can set the working directory to another location manually with menu commands: Session &gt; Set Working Directory &gt; Choose Directory… However, there’s a better way of organising your files by using Projects in RStudio.\n\n2.3.2 Start a Project\nStart by making a directory inside your default project directory where you will keep all of your materials for this class; we’d suggest naming it something like ADS-23.\nTo create a new project for the work we’ll do in this chapter:\n\nFile &gt; New Project…\nName the project 02-reports\n\nSave it inside the ADS-23 directory\n\nRStudio will restart itself and open with this new project directory as the working directory.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.1: Starting a new project.\n\n\nClick on the Files tab in the lower right pane to see the contents of the project directory. You will see a file called 02-reports.Rproj, which is a file that contains all of the project information. When you’re in the Finder/Explorer, you can double-click on it to open up the project.\n\n\n\n\n\n\nDot files\n\n\n\nDepending on your settings, you may also see a directory called .Rproj.user, which contains your specific user settings. You can ignore this and other “invisible” files that start with a full stop.\n\n\n\n\n\n\n\n\nDon’t nest projects\n\n\n\nDon’t ever save a new project inside another project directory. This can cause some hard-to-resolve problems.\n\n\n\n2.3.3 Naming Things\nBefore we start creating new files, it’s important to review how to name your files. This might seem a bit pedantic, but following clear naming rules so that both people and computers can easily find things will make your life much easier in the long run. Here are some important principles:\n\nfile and directory names should only contain letters, numbers, dashes, and underscores, with a full stop (.) between the file name and extension (that means no spaces!)\nbe consistent with capitalisation (set a rule to make it easy to remember, like always use lowercase)\nuse underscores (_) to separate parts of the file name, like the title and date, and dashes (-) to separate words in each part (e.g., social-media-report_2021-10.Rmd)\nname files with a pattern that alphabetises in a sensible order and makes it easy for you to find the file you’re looking for\nprefix a file name with an underscore to move it to the top of the list, or prefix all files with numbers to control their order\n\nFor example, these file names are a mess:\n\nreport.doc\nreport final.doc\nData (Customers) 11-15.xls\nCustomers Data Nov 12.xls\nfinal report2.doc\nproject notes.txt\nVendor Data November 15.xls\n\nHere is one way to structure them so that similar files have the same structure and it’s easy for a human to scan the list or to use code to find relevant files. See if you can figure out what the last one should be.\n\n_project-notes.txt\nreport_v1.doc\nreport_v2.doc\nreport_v3.doc\ndata_customer_2021-11-12.xls\ndata_customer_2021-11-15.xls\n\nvendor-data_2021-11-15.xls\ndata-vendor-2021_11_15.xls\ndata_vendor_2021-11-15.xls\ndata_2021-11-15_vendor.xls\n\n\n\n\n\n\n\nNaming practice\n\n\n\nThink of other ways to name the files above. Look at some of your own project files and see what you can improve."
  },
  {
    "objectID": "02-reports.html#sec-rmarkdown",
    "href": "02-reports.html#sec-rmarkdown",
    "title": "2  Reports with R Markdown",
    "section": "\n2.4 R Markdown",
    "text": "2.4 R Markdown\nThroughout this course we will use R Markdown to create reproducible reports with a table of contents, text, tables, images, and code. The text can be written using markdown, which is a way to specify formatting, such as headers, paragraphs, lists, bolding, and links.\n\n2.4.1 New document\nTo open a new R Markdown document, click File &gt; New File &gt; R Markdown. You will be prompted to give it a title; title it Important Info. You can also change the author name. Keep the output format as HTML.\nOnce you’ve opened a new document be sure to save it by clicking File &gt; Save As…. You should name this file important_info (if you are on a Mac and can see the file extension, name it important_info.Rmd). This file will automatically be saved in your project folder (i.e., your working directory) so you should now see this file appear in your file viewer pane.\nWhen you first open a new R Markdown document you will see a bunch of welcome text that looks like this:\n\n\n\n\nFigure 2.2: New R Markdown text\n\n\n\nDo the following steps:\n\nChange the title to “Important Information” and the author to your name\nDelete everything after the setup chunk\nSkip a line after the setup chunk and type “## My info” (with the hashes but without the quotation marks); make sure there are no spaces before the hashes and at least one space after the hashes before the subtitle\nSkip a line and click the insert new code menu (a green box with a C and a plus sign) then choose R\n\n\nYour Markdown document should now look something like this:\n\n\n\n\nFigure 2.3: New R chunk\n\n\n\n\n2.4.2 Code chunks\nWhat you have created is a subtitle and a code chunk. In R Markdown, anything written in a grey code chunk is assumed to be code, and anything written in the white space (between the code chunks) is regarded as normal text (the actual colours will depend on which theme you have applied, but we will refer to the default white and grey). This makes it easy to combine both text and code in one document.\n\n\n\n\n\n\nCode chunk errors\n\n\n\nWhen you create a new code chunk you should notice that the grey box starts and ends with three back ticks ```. One common mistake is to accidentally delete these back ticks. Remember, code chunks and text entry are different colours - if the colour of certain parts of your Markdown doesn’t look right, check that you haven’t deleted the back ticks.\n\n\nIn your code chunk, write the code you created in Section 1.5.\n\n\n\nimportant_info.Rmd\n\nname &lt;- \"Emily\"\nage &lt;- 36\ntoday &lt;- Sys.Date()\nchristmas &lt;- as.Date(\"2024-12-25\")\n\n\n\n\n\n\n\n\nConsole vs Scripts\n\n\n\nIn Chapter 1, we asked you to type code into the console. Now, we want you to put code into code chunks in R Markdown files to make the code reproducible. This way, you can re-run your code any time the data changes to update the report, and you or others can inspect the code to identify and fix any errors.\nHowever, there will still be times that you need to put code in the console instead of in a script, such as when you install a new package. In this book, code chunks will be labelled with whether you should run them in the console or add the code to a script.\n\n\n\n2.4.3 Running code\nWhen you’re working in an R Markdown document, there are several ways to run your lines of code.\nFirst, you can highlight the code you want to run and then click Run &gt; Run Selected Line(s), however this is tedious and can cause problems if you don’t highlight exactly the code you want to run.\nAlternatively, you can press the green “play” button at the top-right of the code chunk and this will run all lines of code in that chunk.\n\n\n\n\nFigure 2.4: Click the green arrow to run all the code in the chunk.\n\n\n\nEven better is to learn some of the keyboard short cuts for R Studio. To run a single line of code, make sure that the cursor is in the line of code you want to run (it can be anywhere) and press Ctrl+Enter or Cmd+Enter. If you want to run all of the code in the code chunk, press Ctrl+Shift+Enter or Cmd+Shift+Enter. Learn these short cuts; they will make your life easier!\n\n\n\n\nFigure 2.5: Use the keyboard shortcut to run only highlighted code, or run one line at a time by placing the cursor on a line without highlighting anything.\n\n\n\nRun your code using each of the methods above. You should see the variables name, age, today, and christmas appear in the environment pane. (Restart R to reset.)\n\n2.4.4 Inline code\nWe keep talking about using R Markdown for reproducible reports, but it’s easier to show you than tell you why this is so powerful and to give you an insight into how this course will (hopefully!) change the way you work with data forever!\nOne important feature of R Markdown is that you can combine text and code to insert values into your writing using inline coding. If you’ve ever had to copy and paste a value or text from one file to another, you’ll know how easy it can be to make mistakes. Inline code avoids this. Again it’s easier to show you what inline code does rather than to explain it so let’s have a go.\nFirst, copy and paste this text to the white space underneath your code chunk. If you used a different variable name than christmas, you should update this with the name of the object you created, but otherwise don’t change anything else.\nMy name is `r name` and I am `r age` years old. \nIt is `r christmas - today` days until Christmas, \nwhich is my favourite holiday.\n\n\n\n\n\n\nDisplaying Plots\n\n\n\nYou cannot display a plot using inline R. Plots should be displayed from code chunks. We’ll come back to how to do this soon.\n\n\n\n2.4.5 Knitting your file\nNow we are going to knit, or compile, the file into a document type of our choosing. In this case we’ll create a default html file, but you will learn how to create other files like Word and PDF throughout this course. To knit your file, click Knit &gt; Knit to HMTL.\nR Markdown will create and display a new HTML document, but it will also automatically save this file in your working directory.\nAs if by magic, that slightly odd bit of text you copied and pasted now appears as a normal sentence with the values pulled in from the objects you created.\n\nMy name is Emily and I am 36 years old. It is 267 days until Christmas, which is my favourite holiday.\n\n\n\n\n\n\n\nKnitting with Code\n\n\n\n\n\nYou can also knit by typing the following code into the console. Never put this in an Rmd script itself, or it will try to knit itself in an infinite loop.\n\n\n\nRun in the console\n\nrmarkdown::render(\"important_info.Rmd\")\n\n# alternatively, you can use this, but may get a warning\nknitr::knit2html(\"important_info.Rmd\")"
  },
  {
    "objectID": "02-reports.html#loading-data",
    "href": "02-reports.html#loading-data",
    "title": "2  Reports with R Markdown",
    "section": "\n2.5 Loading data",
    "text": "2.5 Loading data\nNow let’s try another example of using Markdown, but this time rather than using objects we have created from scratch, we will read in a data file.\nSave and close your important_info.Rmd document. Then open and save a new Markdown document, this time named sales_data.Rmd. You can again get rid of everything after the setup chunk. Add library(tidyverse) to the setup chunk so that tidyverse functions are available to your script.\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\n```\n\n\n\n2.5.1 Online sources\nFirst, let’s try loading data that is stored online. Create a code chunk in your document and copy, paste, and run the below code. This code loads some simulated sales data.\n\nThe data is stored in a .csv file so we’re going to use the read_csv() function to load it in.\nNote that the url is contained within double quotation marks - it won’t work without this.\n\n\n\n\nsales_data.Rmd\n\nsales_online &lt;- read_csv(\"https://psyteachr.github.io/ads-v2/data/sales_data_sample.csv\")\n\n\n\n\n\n\n\n\nCould not find function\n\n\n\nIf you get an error message that looks like:\n\nError in read_csv(“https://psyteachr.github.io/ads-v2/data/sales_data_sample.csv”) :\ncould not find function “read_csv”\n\nThis means that you have not loaded tidyverse. Check that library(tidyverse) is in the setup chunk and that you have run the setup chunk.\n\n\nThis dataset is simulated sales data for different types of vehicles (originally from Kaggle) where each line of data is a single order. There are multiple ways to view and check a dataset in R. Do each of the following and make a note of what information each approach seems to give you. If you’d like more information about each of these functions, you can look up the help documentation with ?function:\n\nClick on the sales_online object in the environment pane\nRun head(sales_online) in the console\nRun summary(sales_online) in the console\nRun str(sales_online) in the console\nRun View(sales_online) in the console\n\n2.5.2 Local data files\nMore commonly, you will be working from data files that are stored locally on your computer. But where should you put all of your files? You usually want to have all your scripts and data files for a single project inside one folder on your computer, that project’s working directory, and we have already set up the main directory 02-reportsfor this chapter.\nYou can organise files in subdirectories inside this main project directory, such as putting all raw data files in a subdirectory called data and saving any image files to a subdirectory called images. Using subdirectories helps avoid one single folder becoming too cluttered, which is important if you’re working on big projects.\nIn your 02-reports directory, create a new folder named data, download a copy of the sales data file, and save it in this new subdirectory.\nTo load in data from a local file, again we can use the read_csv() function, but this time rather than specifying a url, give it the subdirectory and file name.\n\n\n\nsales_data.Rmd\n\nsales_local &lt;- read_csv(\"data/sales_data_sample.csv\")\n\n\n\n\n\n\n\n\nTab-autocomplete file names\n\n\n\nUse tab auto-complete when typing file names in a code chunk. After you type the first quote, hit tab to see a drop-down menu of the files in your working directory. You can start typing the name of the subdirectory or file to narrow it down. This is really useful for avoiding annoying errors because of typos or files not being where you expect.\n\n\nThings to note:\n\nYou must include the file extension (in this case .csv)\nThe subdirectory folder name (data) and the file name are separated by a forward slash /\n\nPrecision is important, if you have a typo in the file name it won’t be able to find your file; remember that R is case sensitive - Sales_Data.csv is a completely different file to sales_data.csv as far as R is concerned.\n\n\n\n\n\n\n\nView sales_local\n\n\n\nRun head(), summary(), str(), and View() on sales_local to confirm that the data is the same as sales_online."
  },
  {
    "objectID": "02-reports.html#writing-a-report",
    "href": "02-reports.html#writing-a-report",
    "title": "2  Reports with R Markdown",
    "section": "\n2.6 Writing a report",
    "text": "2.6 Writing a report\nWe’re going to write a basic report for this sales dataset using R Markdown to show you some of the features. We’ll be expanding on almost every bit of what we’re about to show you throughout this course; the most important outcome is that you start to get comfortable with how R Markdown works and what you can use it to do.\n\n2.6.1 Data analysis\nFor this report we’re just going to present some simple sales stats for three types of vehicles: planes, motorcycles, and classic cars. We’ll come back to how to write this kind of code yourself in Chapter 4. For now, see if you can follow the logic of what the code is doing via the code comments.\nCreate a new code chunk, then copy, paste and run the following code and then view sales_counts by clicking on the object in the environment pane. Note that it doesn’t really matter whether you use sales_local or sales_online in the first line as they’re identical.\n\n\n\nsales_data.Rmd\n\n# keep only the data from planes, motorcycles, and cars\nsales_pmc &lt;- filter(sales_online,\n         PRODUCTLINE %in% c(\"Planes\", \"Motorcycles\", \"Classic Cars\"))\n\n# count how many are in each PRODUCTLINE\nsales_counts &lt;-count(sales_pmc, PRODUCTLINE)\n\n\nBecause each row of the dataset is a sale, this code gives us a nice and easy way of seeing how many sales were made of each type of vehicle; it just counts the number of rows in each group.\n\n\n\n\n\n\n\nPRODUCTLINE\n\n\nn\n\n\n\n\n\nClassic Cars\n\n\n967\n\n\n\n\nMotorcycles\n\n\n331\n\n\n\n\nPlanes\n\n\n306\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nJust putting an object by itself on a line “prints” it. Section 2.6.5 will show you how to print the table in different formats for your report.\n\n\n\n2.6.2 Text formatting\nYou can use the visual markdown editor if you have RStudio version 1.4 or higher. This will be a button at the top of the source pane and the menu options should be very familiar to anyone who has worked with software like Microsoft Word.\n\n\n\n\nFigure 2.6: The visual editor.\n\n\n\nThis is useful for complex styling, but you can also use these common plain-text style markups:\n\nHeaders are created by prefacing subtitles with one or more hashes (#) and a space (do not exclude the space). If you include a table of contents, this will be created from your document headers.\nFormat text with italics or bold by surrounding the text with one or two asterisks or underscores.\nMake lists using numbers, asterisks or dashes before items. Indent items to make nested lists.\nMake links like this: [psyTeachR](https://psyteachr.github.io/)\n\nDownload the R Markdown Cheat Sheet to learn more.\n\nCopy and paste the below text into the white space below the code chunk that loads in the data. Save the file and then click knit to view the results. It will look a bit messy for now as it contains the code and messages from loading the data but don’t worry, we’ll get rid of that soon.\n## Sample sales report\n\nThis report summarises the sales data for different types of vehicles sold between 2003 and 2005. This data is from [Kaggle](https://www.kaggle.com/kyanyoga/sample-sales-data).\n\n### Sales by type\n\nThe *total* number of **planes** sold was `r sales_counts$n[3]`\n\nThe *total* number of **classic cars** sold was `r sales_counts$n[1]`.\n\n\n\n\n\n\nWarning\n\n\n\nThe example markdown above (and in the rest of this book) is shown for the regular editor, not the visual editor. In the visual editor, you won’t see the hashes that create headers, or the asterisks that create bold and italic text. You also won’t see the backticks that demarcate inline code.\n\n\n\n\nThe example code above shown in the visual editor.\n\n\n\nIf you try to add the hashes, asterisks and backticks to the visual editor, you will get frustrated as they disappear. If you succeed, your code in the regular editor will look mangled like this:\n\\#\\#\\# Sales by type\n\nThe \\*total\\* number of \\*\\*planes\\*\\* sold was \\`r sales_counts\\$n\\[3]\\`\n\n\nTry and match up the inline code with what is in the sales_counts table. Of note:\n\nThe $ sign is used to indicate specific variables (or columns) in an object using the object$variable syntax.\nSquare brackets with a number e.g., [3] indicate a particular observation\nSo sales_counts$n[3] asks the inline code to display the third observation of the variable n in the dataset sales_online.\n\n\n\n\n\n\n\nFurther Practice\n\n\n\nAdd another line that reports the total numbers of motorcycles using inline code. Using either the visual editor or text markups, add in bold and italics so that it matches the others.\n\n\nSolution\n\nThe *total* number of **motorcycles** sold was `r sales_counts$n[2]`.\n\n\n\n\n2.6.3 Code comments\nIn the above code we’ve used code comments and it’s important to highlight how useful these are. You can add comments inside R chunks with the hash symbol (#). R will ignore characters from the hash to the end of the line.\n\n# important numbers\n\nn &lt;- nrow(sales_online) # the total number of sales (number of rows)\nfirst &lt;- min(sales_online$YEAR_ID) # the first (minimum) year\nlast &lt;- max(sales_online$YEAR_ID) # the last (maximum) year\n\nIt’s usually good practice to start a code chunk with a comment that explains what you’re doing there, especially if the code is not explained in the text of the report.\nIf you name your objects clearly, you often don’t need to add clarifying comments. For example, if I’d named the three objects above total_number_of_sales, first_year and last_year, I would omit the comments. It’s a bit of an art to comment your code well, but try to add comments as you’re working through this book - it will help consolidate your learning and when future you comes to review your code, you’ll thank past you for being so clear.\n\n2.6.4 Images\nAs the saying goes, a picture paints a thousand words and sometimes you will want to communicate your data using visualisations.\nCreate a code chunk to display a graph of the data in your document after the text we’ve written so far. We’ll use some code that you’ll learn more about in Chapter 3 to make a simple bar chart that represents the sales data – focus on trying to follow how bits of the code map on to the plot that is created.\nCopy and paste the below code. Run the code in your Markdown to see the plot it creates and then knit the file to see how it is displayed in your document.\n\n\n\nsales_data.Rmd\n\nggplot(data = sales_counts, \n       mapping = aes(x = PRODUCTLINE, \n                     y = n, \n                     fill = PRODUCTLINE)) +\n  geom_col(show.legend = FALSE) +\n  labs(x = \"Type of vehicle\",\n       y = \"Number of sales\",\n       title = \"Sales by vehicle type\",\n       subtitle = \"2003 - 2005\")\n\n\n\n\n\n\n\n\nYou can also include images that you did not create in R using the markdown syntax for images or knitr::include_graphics(). This is very similar to loading data in that you can either use an image that is stored on your computer, or via a url.\nCreate a new code chunk underneath each of the sales figures for planes, classic cars, and motorcycles and add in an image from Google or Wikipedia for each (right click on an image and select copy image address to get a url). See the section on chunk defaults to see how to change the display size.\n\n\n\nsales_data.Rmd\n\nknitr::include_graphics(\"https://upload.wikimedia.org/wikipedia/commons/3/3f/P-51_Mustang_edit1.jpg\")\n\n\n\n\n\n\n\n\nImage Licenses\n\n\n\n\n\nMost images on Wikipedia are public domain or have an open license. You can search for images by license on Google Images by clicking on the Tools button and choosing “Creative Commons licenses” from the “Usage Rights” menu.\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, you can use the markdown notation ![caption](url) to show an image. This goes in the markdown text section of the document, not inside is grey code block. The caption is optional; you can omit it like this:\n![](images/reports/google-images.png)\n\n2.6.5 Tables\nRather than a figure, we might want to display our data in a table.\n\nAdd a new level 2 heading (two hashtags) to your document, name the heading “Data in table form” and then create a new code chunk below this.\n\nFirst, let’s see what the table looks like if we don’t make any edits. Simply write the name of the table you want to display in the code chunk (in our case sales_counts) and then click knit to see what it looks like.\n\n\n\nsales_data.Rmd\n\nsales_counts\n\n\n## # A tibble: 3 × 2\n## # Groups:   PRODUCTLINE [3]\n##   PRODUCTLINE      n\n##   &lt;chr&gt;        &lt;int&gt;\n## 1 Classic Cars   967\n## 2 Motorcycles    331\n## 3 Planes         306\nIt’s just about readable but it’s not great.\nAnother way to customise tables uses the function kable() from the kableExtra package.\nAmend your code to load the kableExtra package and apply the kable() function to the table. Once you’ve done this, knit the file again to see the output.\n\n\n\nsales_data.Rmd\n\nlibrary(kableExtra) # for table display\n\nkable(sales_counts) # apply the kable function\n\n\n\n\nPRODUCTLINE\nn\n\n\n\nClassic Cars\n967\n\n\nMotorcycles\n331\n\n\nPlanes\n306\n\n\n\n\n\nIt’s better, but it’s still not amazing. So let’s make a few adjustments. We can change the names of the columns, add a caption, and also change the alignment of the cell contents using arguments to kable().\nWe can also add a theme to change the overall style. In this example we’ve used kable_classic but there are 5 others: kable_paper, kable_classic_2, kable_minimal, kable_material and kable_material_dark. Try them all and see which one you prefer.\nFinally, we can change the formatting of the first row using row_spec. Look up the help documentation for row_spec to see what other options are available. Try changing the value of any of the arguments below to figure out what they do.\n\n\n\nsales_data.Rmd\n\nk &lt;- kable(sales_counts, \n      col.names = c(\"Product\", \"Sales\"),\n      caption = \"Number of sales per product line.\", \n      align = \"c\")\nk_style &lt;- kable_classic(k, full_width = FALSE) \nk_highlighted &lt;- row_spec(k_style, row = 0, bold = TRUE, color = \"red\") \n\nk_highlighted\n\n\n\nNumber of sales per product line.\n\nProduct\nSales\n\n\n\nClassic Cars\n967\n\n\nMotorcycles\n331\n\n\nPlanes\n306\n\n\n\n\n\n\n\n\n\n\n\nCaption placement\n\n\n\nThe appearance and placement of the table caption depends on the type of document you are creating. Your captions may look different to those in this book because you are creating a single-page html_document, while this book uses the html style from quarto, which is a newer alternative to R Markdown. You’ll learn more about other document output types in ?sec-custom-reports.\n\n\n\n\n\n\n\n\nAdvanced table customisation\n\n\n\n\n\nIf you’re feeling confident with what we have covered so far, the kableExtra vignette gives a lot more detail on how you can edit your tables using kableExtra.\nYou can also explore the gt package, which is complex, but allows you to create beautiful customised tables. Riding tables with {gt} and {gtExtras} is an outstanding tutorial."
  },
  {
    "objectID": "02-reports.html#refining-your-report",
    "href": "02-reports.html#refining-your-report",
    "title": "2  Reports with R Markdown",
    "section": "\n2.7 Refining your report",
    "text": "2.7 Refining your report\n\n2.7.1 Chunk defaults\nLet’s finish by tidying up the report and organising our code a bit better. When you create a new R Markdown file in RStudio, a setup chunk is automatically created - we’ve mostly ignored this chunk until now.\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n\nYou can set more default options for your document here. Type the following code into the console to see the full list of options that you can set and their default values. However, the most useful and common options to change for the purposes of writing reports revolve around whether you want to show your code and the size of your images.\n\n\n\nRun in the console\n\n# list option default values\nstr(knitr::opts_chunk$get())\n\n\nReplace the code in your setup chunk with the below code and then try changing each option from FALSE to TRUE and changing the numeric values then knit the file again to see the difference it makes.\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo       = FALSE, # whether to show code chunks\n  message    = FALSE, # whether to show messages from your code\n  warning    = FALSE, # whether to show warnings from your code\n  fig.width  = 8,     # figure width in inches (at 96 dpi)\n  fig.height = 5,     # figure height in inches (at 96 dpi)\n  out.width = \"50%\"   # figures/images span 50% of the page width\n)\n```\n\n\n\n\n\n\n\n\nFigure versus output dimensions\n\n\n\n\n\nNote that fig.width and fig.height control the original size and aspect ratio of images generated by R, such as plots. This will affect the relative size of text and other elements in plots. It does not affect the size of existing images at all. However, out.width controls the display size of both existing images and figures generated by R. This is usually set as a percentage of the page width.\n\n\n\n\nFigure 2.7: A plot with the default values of fig.width = 8, fig.height = 5, out.width = “100%”\n\n\n\n\n\n\n\nFigure 2.8: The same plot with half the default width and height: fig.width = 4, fig.height = 2.5, out.width = “100%”\n\n\n\n\n\n\n\nFigure 2.9: The same plot as above at half the output width: fig.width = 4, fig.height = 2.5, out.width = “50%”\n\n\n\n\n\n\n\n2.7.2 Override defaults\nThese setup options change the behaviour for the entire document, however, you can override the behaviour for individual code chunks.\nFor example, by default you might want to hide your code but there also might be an occasion where you want to show the code you used to analyse your data. You can set echo = FALSE in your setup chunk to make hiding code the default but in the individual code chunk for your plot set echo = TRUE. Try this now and knit the file to see the results.\n\n\n```{r, echo = TRUE}\nggplot(data = sales_counts, \n       mapping = aes(x = PRODUCTLINE, \n                     y = n, \n                     fill = PRODUCTLINE)) +\n  geom_col(show.legend = FALSE) +\n  labs(x = \"Type of vehicle\",\n       y = \"Number of sales\",\n       title = \"Sales by vehicle type\",\n       subtitle = \"2003 - 2005\")\n```\n\n\nAdditionally, you can also override the default image display size or dimensions.\n\n\n```{r, out.width='25%'}\nknitr::include_graphics(\"https://upload.wikimedia.org/wikipedia/commons/3/3f/P-51_Mustang_edit1.jpg\")\n```\n\n\n\n\n```{r, fig.width = 10, fig.height = 20}\nggplot(data = sales_counts, \n       mapping = aes(x = PRODUCTLINE, y = n, fill = PRODUCTLINE)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  labs(x = \"Type of vehicle\",\n       y = \"Number of sales\",\n       title = \"Sales by vehicle type\",\n       subtitle = \"2003 - 2005\")\n```\n\n\n\n2.7.3 Loading packages\nYou should add the packages you need in your setup chunk using library(). Often when you are working on a script, you will realize that you need to load another add-on package. Don’t bury the call to library(package_I_need) way down in the script. Put it in the setup chunk so the user has an overview of what packages are needed.\n\n\n\n\n\n\nMove library calls to the setup chunk\n\n\n\nMove the code that loads the tidyverse and kableExtra to the setup chunk.\n\n\n\n2.7.4 YAML header\nFinally, the YAML header is the bit at the very top of your Markdown document. You can set several options here as well.\n---\ntitle: \"Sales Data Report\"\nauthor: \"Your name\"\noutput:\n  html_document:\n    df_print: paged\n    theme: \n      version: 4\n      bootswatch: yeti\n    toc: true\n    toc_float:\n      collapsed: false\n      smooth_scroll: false\n    toc_depth: 3\n    number_sections: false\n---\n\n\n\n\n\n\nTry\n\n\n\nTry changing the values from false to true to see what the options do.\n\n\nThe df_print: paged option prints data frames using rmarkdown::paged_table() automatically. You can use df_print: kable to default to the simple kable style, but you will need the code from Section 2.6.5 for more complex tables with kableExtra.\nThe built-in bootswatch themes are: default, cerulean, cosmo, darkly, flatly, journal, lumen, paper, readable, sandstone, simplex, spacelab, united, and yeti. You can view and download more themes. Try changing the theme to see which one you like best.\n\n\n\n\nFigure 2.10: Light themes in versions 3 and 4.\n\n\n\n\n\n\n\n\n\nYAML formatting\n\n\n\nYAML headers can be very picky about spaces and semicolons (the rest of R Markdown is much more forgiving). For example, if you put a space before “author”, you will get an error that looks like:\nError in yaml::yaml.load(..., eval.expr = TRUE) : \n  Parser error: while parsing a block mapping at line 1, \n  column 1 did not find expected key at line 2, column 2\nThe error message will tell you exactly where the problem is (the second character of the second line of the YAML header), and it’s usually a matter of fixing typos or making sure that the indenting is exactly right.\n\n\n\n2.7.5 Table of Contents\nThe table of contents is created by setting toc: true. It will be displayed at the top of your document unless you set toc_float: true or include toc_float: with its options collapsed and smooth_scroll (options for a setting are indented under it).\n---\noutput:\n  html_document:\n    toc: true\n    toc_float:\n      collapsed: false\n      smooth_scroll: false\n    toc_depth: 3\n---\nThis will use the markdown header structure to create the table of contents. toc_depth: 3 means that the table of contents will only display headers up to level 3 (i.e., those that start with three hashes: ###). Add {-} after the header title to remove it from the table of contents (e.g., ### Overview {-}).\n\n\n\n\n\n\nMalformated ToC\n\n\n\nIf your table of contents isn’t showing up correctly, this probably means that your headers are not set up right. Make sure that headers have no spaces before the hashes and at least one space after the hashes. For example, ##Analysis won’t display as a header and be added to the table of contents, but ## Analysis will.\n\n\n\n2.7.6 Formats\nSo far we’ve just knitted to html. To generate PDF reports, you need to install tinytex(Xie, 2021) and run the following code in the console (do not add this to your Rmd file):\n\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n\nOnce you’ve done this, update your YAML heading to add a pdf_document section and knit a PDF document. The options for PDFs are more limited than for HTML documents, so if you just replace html_document with pdf_document, you may need to remove some options, such as toc_float if you get an error that looks like “Functions that produce HTML output found in document targeting PDF output.”\n---\noutput:\n  pdf_document:\n    toc: TRUE\n  html_document:\n    toc: TRUE\n    toc_float: TRUE\n---\nAs an alternative, you can also knit to a Word document. When you click the Knit button, the first format will knit by default, but you can use the drop-down menu under the Knit button to choose another format.\n---\noutput:\n  pdf_document:\n    toc: TRUE\n  html_document:\n    toc: TRUE\n    toc_float: TRUE\n  word_document:\n    toc: TRUE\n---\n\n\n\n\n\n\nKnitting errors\n\n\n\nIf you encounter errors, ask on Teams for help - knitting to PDF or Word can be tricky.\n\n\n\n2.7.7 Summary\nThis chapter has covered a lot but hopefully now you have a much better idea of what Markdown is able to do. Whilst working in Markdown takes longer in the initial set-up stage, once you have a fully reproducible report you can plug in new data each week or month and simply click knit, reducing duplication of effort, and the human error that comes with it.\nYou can access a working R Markdown file with the code from the example above to compare to your own code.\nAs you continue to work through the book you will learn how to wrangle and analyse your data and how to use Markdown to present it. We’ll slowly build on the available customisation options so over the course of next few weeks, you’ll find your Markdown reports start to look more polished and professional."
  },
  {
    "objectID": "02-reports.html#sec-exercises-reports",
    "href": "02-reports.html#sec-exercises-reports",
    "title": "2  Reports with R Markdown",
    "section": "\n2.8 Exercises",
    "text": "2.8 Exercises\nBelow are some additional exercises that will let you apply what you have learned in this chapter. We would suggest taking a break before you do these - it might feel slightly more effortful, but spreading out your practice will help you learn more in the long run.\n\n2.8.1 New project\nCreate a new project called “demo_report” (Section 2.3).\n\n2.8.2 New script\nIn the “demo_report” project, create a new Rmarkdown document called “job.Rmd” (Section 2.4). Edit the YAML header to output tables using kable and set a custom theme (Section 2.7.4).\n\n\nSolution\n\n---\ntitle: \"My Job\"\nauthor: \"Me\"\noutput:\n  html_document:\n    df_print: kable\n    theme: \n      version: 4\n      bootswatch: sandstone\n---\n\n\n2.8.3 R Markdown\nWrite a short paragraph describing your job or a job you might like to have in the future (Section 2.6.2). Include a bullet-point list of links to websites that are useful for that job (Section 2.6.2).\n\n\nSolution\n\nI am a research psychologist who is interested in open science \nand teaching computational skills.\n\n* [psyTeachR books](https://psyteachr.github.io/)\n* [Google Scholar](https://scholar.google.com/)\n\n\n2.8.4 Tables\nUse the following code to load a small table of tasks (Section 2.4.2). Edit it to be relevant to your job (you can change the categories entirely if you want).\n\n\n\njob.Rmd\n\ntasks &lt;- tibble::tribble(\n  ~task,                   ~category,      ~frequency,\n  \"Respond to tweets\",     \"social media\", \"daily\",\n  \"Create a twitter poll\", \"social media\", \"weekly\",\n  \"Make the sales report\", \"reporting\",    \"montly\"\n)\n\n\nFigure out how to make it so that code chunks don’t show in your knitted document (Section 2.7.1).\n\n\nSolution\n\nYou can set the default to echo = FALSE in the setup chunk at the top of the script.\n\nknitr::opts_chunk$set(echo = FALSE)\n\nTo set visibility for a specific code chunk, put echo = FALSE inside the curly brackets.\n\n\n```{r, echo=FALSE}\n# code to hide\n```\n\n\n\nDisplay the table with purple italic column headers. Try different styles using kableExtra (Section 2.6.5).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nk &lt;- kableExtra::kable(tasks)\nk_style &lt;- kableExtra::kable_minimal(k)\nk_highlight &lt;- kableExtra::row_spec(k_style,\n                                    row = 0, \n                                    italic = TRUE, \n                                    color = \"purple\")\nk_highlight\n\n\n\ntask\ncategory\nfrequency\n\n\n\nRespond to tweets\nsocial media\ndaily\n\n\nCreate a twitter poll\nsocial media\nweekly\n\n\nMake the sales report\nreporting\nmontly\n\n\n\n\n\n\n\n\n\n2.8.5 Images\nAdd an image of anything relevant (Section 2.6.4).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nknitr::include_graphics(\"https://psyteachr.github.io/ads-v2/images/logos/logo.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nAlternative Solution\n\nYou can add an image from the web using its URL:\n![Applied Data Skills](https://psyteachr.github.io/ads-v2/images/logos/logo.png)\nOr save an image into your project directory (e.g., in the images folder) and add it using the relative path:\n![Applied Data Skills](images/logos/logo.png)\n\n\n2.8.6 Inline R\nUse inline R to include the version of R you are using in the following sentence: “This report was created using R version 4.3.1 (2023-06-16 ucrt).” You can get the version using the object R.version.string (Section 2.4.4).\n\n\nSolution\n\nThis report was created using R version 4.3.1 (2023-06-16 ucrt).\n\n\n2.8.7 Knit\nKnit this document to html (Section 2.4.5).\n\n\nSolution\n\nClick on the knit button or run the following code in the console. (Do not put it the Rmd script!)\n\nrmarkdown::render(\"job.Rmd\")\n\n\n\n2.8.8 Share on Teams\nOnce you’re done, share your knitted html file and the Rmd file for the exercises on Teams in the Week 02 channel."
  },
  {
    "objectID": "02-reports.html#sec-glossary-reports",
    "href": "02-reports.html#sec-glossary-reports",
    "title": "2  Reports with R Markdown",
    "section": "\n2.9 Glossary",
    "text": "2.9 Glossary\n\n\n\nterm\ndefinition\n\n\n\ndirectory\nA collection or \"folder\" of files on a computer.\n\n\nextension\nThe end part of a file name that tells you what type of file it is (e.g., .R or .Rmd).\n\n\nknit\nTo create an HTML, PDF, or Word document from an R Markdown (Rmd) document\n\n\nmarkdown\nA way to specify formatting, such as headers, paragraphs, lists, bolding, and links.\n\n\nproject\nA way to organise related files in RStudio\n\n\nr-markdown\nThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.\n\n\nscript\nA plain-text file that contains commands in a coding language, such as R.\n\n\nworking-directory\nThe filepath where R is currently reading and writing files.\n\n\nyaml\nA structured format for information"
  },
  {
    "objectID": "02-reports.html#sec-resources-reports",
    "href": "02-reports.html#sec-resources-reports",
    "title": "2  Reports with R Markdown",
    "section": "\n2.10 Further Resources",
    "text": "2.10 Further Resources\n\n\nR Markdown Cheat Sheet \n\nR Markdown Tutorial\n\nR Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, & Garrett Grolemund\n\nProject Structure by Danielle Navarro\n\nHow to name files by Jenny Bryan\nkableExtra\ngt\n\n\n\n\n\nXie, Y. (2021). Tinytex: Helper functions to install and maintain TeX live, and compile LaTeX documents. https://github.com/yihui/tinytex"
  },
  {
    "objectID": "03-viz.html#sec-ilo-viz",
    "href": "03-viz.html#sec-ilo-viz",
    "title": "3  Data Visualisation",
    "section": "Intended Learning Outcomes",
    "text": "Intended Learning Outcomes\n\nBe able to identify categorical versus continuous data\nBe able to create plots in layers using ggplot\nBe able to choose appropriate plots for data"
  },
  {
    "objectID": "03-viz.html#functions-ch03",
    "href": "03-viz.html#functions-ch03",
    "title": "3  Data Visualisation",
    "section": "\n3.1 Functions used",
    "text": "3.1 Functions used\naes(), as.numeric(), c(), col_character(), col_datetime(), col_double(), col_factor(), col_integer(), cols(), coord_cartesian(), count(), element_blank(), facet_wrap(), factor(), geom_bar(), geom_boxplot(), geom_col(), geom_histogram(), geom_jitter(), geom_point(), geom_smooth(), ggplot(), ggtitle(), glimpse(), guides(), mean(), now(), plot_layout(), read_csv(), rgb(), scale_fill_manual(), scale_x_continuous(), scale_x_date(), scale_x_discrete(), scale_y_continuous(), seq(), spec(), stat_summary(), theme(), theme_bw(), theme_gdocs(), theme_set(), today()"
  },
  {
    "objectID": "03-viz.html#sec-walkthrough-viz",
    "href": "03-viz.html#sec-walkthrough-viz",
    "title": "3  Data Visualisation",
    "section": "Walkthrough video",
    "text": "Walkthrough video\nThere is a walkthrough video of this chapter available via Echo360. Please note that there may have been minor edits to the book since the video was recorded. Where there are differences, the book should always take precedence."
  },
  {
    "objectID": "03-viz.html#sec-setup-viz",
    "href": "03-viz.html#sec-setup-viz",
    "title": "3  Data Visualisation",
    "section": "\n3.2 Set-up",
    "text": "3.2 Set-up\nCreate a new project for the work we’ll do in this chapter:\n\nFile &gt; New Project…\nName the project 03-visualisation\n\nSave it inside your ADS directory (not inside another project)\n\nThen, create and save a new R Markdown document named plots.Rmd, get rid of the default template text, and load the packages in the set-up code chunk. You should have all of these packages installed already, but if you get the message Error in library(x) : there is no package called ‘x’, please refer to Section 1.4.1.\n\n\n```{r setup, include=FALSE}\nlibrary(tidyverse) # includes ggplot2\nlibrary(patchwork) # for multi-part plots\nlibrary(ggthemes)  # for plot themes\nlibrary(lubridate) # for manipulating dates\n```\n\n\nWe’d recommend making a new code chunk for each different activity, and using the white space to make notes on any errors you make, things you find interesting, or questions you’d like to ask the course team.\nDownload the ggplot2 cheat sheet."
  },
  {
    "objectID": "03-viz.html#variable-types",
    "href": "03-viz.html#variable-types",
    "title": "3  Data Visualisation",
    "section": "\n3.3 Variable types",
    "text": "3.3 Variable types\nIf a spreadsheet is in a tidy data format, each row is an observation, each column is a variable, and the information in each cell is a single value. We’ll learn more about how to get our data into this format in ?sec-tidy, but to get started we’ll use datasets with the right format.\nFor example, the table below lists pets owned by members of the psyTeachR team. Each row is an observation of one pet. There are 6 variables for each pet, their name, owner, species, birthdate, weight (in kg), and rating (on a 5-point scale from “very evil” to “very good”).\n\n\n\n\n\nname\nowner\nspecies\nbirthdate\nweight\nrating\n\n\n\nDarwin\nLisa\nferret\n1998-04-02\n1.2\na little evil\n\n\nOy\nLisa\nferret\nNA\n2.9\nvery good\n\n\nKhaleesi\nEmily\ncat\n2014-10-01\n4.5\nvery good\n\n\nBernie\nPhil\ndog\n2017-06-01\n32.0\nvery good\n\n\n\n\n\n\nVariables can be classified as continuous (numbers) or categorical (labels). When you’re plotting data, it’s important to know what kind of variables you have, which can help you decide what types of plots are most appropriate. Each variable also has a data type, such as numeric (numbers), character (text), or logical (TRUE/FALSE values). Some plots can only work on some data types. Make sure you have watched the mini-lecture on types of data from last week before you work through this chapter. Additionally, Appendix H has more details, as this concept will be relevant repeatedly.\n\n\n\n\nData types are like the categories when you format cells in Excel.\n\n\n\n\n3.3.1 Continuous\nContinuous variables are properties you can measure, like weight. You can use continuous variables in mathematical operations, like calculating the sum total of a column of prices or the average number of social media likes per day. They may be rounded to the nearest whole number, but it should make sense to have a measurement halfway between.\nContinuous variables always have a numeric data type. They are either integers like 42 or doubles like 3.14159.\n\n3.3.2 Categorical\nCategorical variables are properties you can count, like the species of pet. Categorical variables can be &lt;a href=‘https://psyteachr.github.io/glossary/n#nominal’ target=’_blank’ class=‘glossary’ title=‘Categorical variables that don’t have an inherent order, such as types of animal.’&gt;nominal, where the categories don’t really have an order, like cats, dogs and ferrets (even though ferrets are obviously best), or ordinal, where they have a clear order but the distance between the categories isn’t something you could exactly equate, like points on a Likert rating scale. Even if a data table uses numbers like 1-7 to represent ordinal variables, you shouldn’t treat them like continuous variables.\nCategorical data can have a character data type, also called strings. These are made by putting text inside of quotes. That text can be letters, punctuation, or even numbers. For example, \"January\" is a character string, but so is \"1\" if you put it in quotes. The character data type is best for variables that can have a lot of different values that you can’t predict ahead of time.\nCategorical data can also be factors, a specific type of integer that lets you specify the category names and their order. This is useful for making plots display with categories in the order you want (otherwise they default to alphabetical order). The factor data type is best for categories that have a specific number of levels.\n\n\n\n\n\n\nDo not factor numbers\n\n\n\nIf you factor numeric data, it gets converted to the integers 1 to the number of unique values, no matter what the values are. Additionally, you can no longer use the values as numbers, such as calculating the mean.\n\n\n\nExample\n\nx &lt;- c(-3, 0, .5)  # numeric vector\nf &lt;- factor(x)     # convert to factor\nx == as.numeric(f) # does not convert back to numeric \n\n\n[1] FALSE FALSE FALSE\n\n\n\n\n\nYou cannot average a factor\n\nm &lt;- mean(f)\n\n\nWarning in mean.default(f): argument is not numeric or logical: returning NA\n\n\n\n\nSometimes people represent categorical variables with numbers that correspond to names, like 0 = “no” and 1 = “yes”, but values in between don’t have a clear interpretation. If you have control over how the data are recorded, it’s better to use the character names for clarity. You’ll learn how to recode columns in ?sec-wrangle.\n\n3.3.3 Dates and times\nDates and times are a special case of variable. They can act like categorical or continuous variables, and there are special ways to plot them. Dates and times can be hard to work with, but the [lubridate(https://lubridate.tidyverse.org/) package provides functions to help you with this.\n\n# the current date\nlubridate::today()\n\n[1] \"2024-04-02\"\n\n\n\n# the current date and time in the GMT timezone\nlubridate::now(tzone = \"GMT\")\n\n[1] \"2024-04-02 14:55:09 GMT\"\n\n\n\n\n\n\n\n\nTest your understanding\n\n\n\nComing back to the pets dataset, what type of variable is in each column? You can use the function glimpse() to show a list of the column names, their data types, and the first few values in each column - here is the output of running glimpse() on the pets dataset.\n\nglimpse(pets)\n\nRows: 4\nColumns: 6\n$ name      &lt;chr&gt; \"Darwin\", \"Oy\", \"Khaleesi\", \"Bernie\"\n$ owner     &lt;chr&gt; \"Lisa\", \"Lisa\", \"Emily\", \"Phil\"\n$ species   &lt;fct&gt; ferret, ferret, cat, dog\n$ birthdate &lt;date&gt; 1998-04-02, NA, 2014-10-01, 2017-06-01\n$ weight    &lt;dbl&gt; 1.2, 2.9, 4.5, 32.0\n$ rating    &lt;fct&gt; a little evil, very good, very good, very good\n\n\n\n\n\n\n\n\n\nColumn\nVariable type\nData type\n\n\n\nname\n\ncontinuous\nnominal\nordinal\ndate\n\nnumeric\ncharacter\nfactor\ndate\n\n\nowner\n\ncontinuous\nnominal\nordinal\ndate\n\nnumeric\ncharacter\nfactor\ndate\n\n\nspecies\n\ncontinuous\nnominal\nordinal\ndate\n\nnumeric\ncharacter\nfactor\ndate\n\n\nbirthdate\n\ncontinuous\nnominal\nordinal\ndate\n\ncontinuous\nnominal\nordinal\ndate\n\n\nweight\n\ncontinuous\nnominal\nordinal\ndate\n\nnumeric\ncharacter\nfactor\ndate\n\n\nrating\n\ncontinuous\nnominal\nordinal\ndate\n\nnumeric\ncharacter\nfactor\ndate"
  },
  {
    "objectID": "03-viz.html#building-plots",
    "href": "03-viz.html#building-plots",
    "title": "3  Data Visualisation",
    "section": "\n3.4 Building plots",
    "text": "3.4 Building plots\nThere are multiple approaches to data visualisation in R; in this course we will use the popular package ggplot2, which is part of the larger tidyverse collection of packages. A grammar of graphics (the “gg” in “ggplot”) is a standardised way to describe the components of a graphic. ggplot2 uses a layered grammar of graphics, in which plots are built up in a series of layers. It may be helpful to think about any picture as having multiple elements that sit semi-transparently over each other. A good analogy is old Disney movies where artists would create a background and then add moveable elements on top of the background via transparencies.\nFigure 3.1 displays the evolution of a simple scatterplot using this layered approach. First, the plot space is built (layer 1); the variables are specified (layer 2); the type of visualisation (known as a geom) that is desired for these variables is specified (layer 3) - in this case geom_point() is called to visualise individual data points; a second geom is added to include a line of best fit (layer 4), the axis labels are edited for readability (layer 5), and finally, a theme is applied to change the overall appearance of the plot (layer 6).\n\n\n\n\nFigure 3.1: Evolution of a layered plot\n\n\n\nImportantly, each layer is independent and independently customisable. For example, the size, colour and position of each component can be adjusted, or one could, for example, remove the first geom (the data points) to only visualise the line of best fit, simply by removing the layer that draws the data points (Figure 3.2). The use of layers makes it easy to build up complex plots step-by-step, and to adapt or extend plots from existing code.\n\n\n\n\nFigure 3.2: Final plot with scatterplot layer removed.\n\n\n\n\n3.4.1 Plot Data\nLet’s build up the plot above, layer by layer. First we need to get the data. We’ll learn how to load data from different sources in Appendix G, but this time we’ll use the same method as we did in Section 2.5.1 and load it from an online source.\nWhen you load the data, read_csv() will produce a message that gives you information about the data it has imported and what assumptions it has made. The “column specification” tells you what each column is named and what type of data R has categorised each variable as. The abbreviation “chr” is for character columns, “dbl” is for double columns, and “dttm” is a date/time column.\n\nsurvey_data &lt;- read_csv(\"https://psyteachr.github.io/ads-v2/data/survey_data.csv\")\n\nRows: 707 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): caller_id, employee_id, issue_category\ndbl  (3): wait_time, call_time, satisfaction\ndttm (1): call_start\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis data is simulated data for a call centre customer satisfaction survey. The first thing you should do when you need to plot data is to get familiar with what all of the rows (observations) and columns (variables) mean. Sometimes this is obvious, and sometimes it requires help from the data provider. Here, each row represents one call to the centre.\n\n\ncaller_id is a unique ID for each caller\n\nemployee_id is a unique ID for each employee taking calls\n\ncall_start is the date and time that the call arrived\n\nwait_time is the number of seconds the caller had to wait\n\ncall_time is the number of seconds the call lasted after the employee picked up\n\nissue_category is whether the issue was tech, sales, returns, or other\n\nsatisfaction is the customer satisfaction rating on a scale from 1 (very unsatisfied) to 5 (very satisfied)\n\nUnless you specify the column types, data importing functions will just guess the types and usually default to double for columns with numbers and character for columns with letters. Use the function spec() to find out all of the column types and edit them if needed.\n\nspec(survey_data)\n\ncols(\n  caller_id = col_character(),\n  employee_id = col_character(),\n  call_start = col_datetime(format = \"\"),\n  wait_time = col_double(),\n  call_time = col_double(),\n  issue_category = col_character(),\n  satisfaction = col_double()\n)\n\n\nLet’s set issue_category as a factor and set the order of the levels. By default, R will order the levels of a factor alphanumerically, however in many cases you will want or need to set your own order. For example, in this data, it makes most sense for the category “other” to come at the end of the list. After you update the column types, you have to re-import the data by adjusting the read_csv() code to set the col_types argument to the new column types.\n\n\n\n\n\n\nDefine objects before you use them\n\n\n\nBecause read_csv() is going to use the object survey_col_types, you must create survey_col_types before you run the adjusted read_csv() code. If you ever need to adjust your code, try to think about the order that the code will run in if you start from scratch and make sure it’s organised appropriately.\n\n\n\n# updated column types\nsurvey_col_types &lt;- cols(\n  caller_id = col_character(),\n  employee_id = col_character(),\n  call_start = col_datetime(format = \"\"),\n  wait_time = col_double(),\n  call_time = col_double(),\n  issue_category = col_factor(levels = c(\"tech\", \"sales\", \"returns\", \"other\")),\n  satisfaction = col_integer()\n)\n\n# re-import data with correct column  types\nsurvey_data &lt;- read_csv(\"https://psyteachr.github.io/ads-v2/data/survey_data.csv\",\n                        col_types = survey_col_types)\n\n\n3.4.2 Plot setup\n\n3.4.2.1 Default theme\nPlots in this book use the black-and-white theme, not the default grey theme, so set your default theme to the same so your plots will look like the examples below. At the top of your script, in the setup chunk after you’ve loaded the tidyverse package, add the following code and run it. You’ll learn more ways to customise your theme in Section 3.4.3.4 and Section J.3.\n\ntheme_set(theme_bw()) # set the default theme\n\n\n3.4.2.2 Data\nEvery plot starts with the ggplot() function and a data table. If your data are not loaded or you have a typo in your code, this will give you an error message. It’s best to check your plot after each step, so that you can figure out where errors are more easily.\n\nggplot(data = survey_data)\n\n\n\nFigure 3.3: A blank ggplot.\n\n\n\n\n3.4.2.3 Mapping\nThe next argument to ggplot() is the mapping. This tells the plot which columns in the data should be represented by, or “mapped” to, different aspects of the plot, such as the x-axis, y-axis, line colour, object fill, or line style. These aspects, or “aesthetics”, are listed inside the aes() function.\nSet the arguments x and y to the names of the columns you want to be plotted on those axes. Here, we want to plot the wait time on the x-axis and the call time on the y-axis.\n\n# set up the plot with mapping\nggplot(\n  data = survey_data, \n  mapping = aes(x = wait_time, y = call_time)\n)\n\n\n\nFigure 3.4: A blank plot with x- and y- axes mapped.\n\n\n\n\n\n\n\n\n\nggplot argument names\n\n\n\nIn the example above, we wrote out the names of the arguments data and mapping, but in practice, almost everyone omits them. Just make sure you put the data and mapping in the right order.\n\nggplot(survey_data,  aes(x = wait_time, y = call_time))\n\n\n\n\n3.4.2.4 Geoms\nNow we can add our plot elements in layers. These are referred to as geoms and their functions start with geom_. You add layers onto the base plot created by ggplot() with a plus (+).\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point() # scatterplot\n\n\n\nFigure 3.5: Adding a scatterplot with geom_point().\n\n\n\n\n\n\n\n\n\nLocation of the +\n\n\n\n\n\nSomewhat annoyingly, the plus has to be on the end of the previous line, not at the start of the next line. If you do make this mistake, it will run the first line of code to produce the base layer but then you will get the following error message rather than adding on geom_point().\n\nggplot(survey_data, aes(x = wait_time, y = call_time))\n\n\n\n\n\n\n+ geom_point() # scatterplot\n\nError:\n! Cannot use `+` with a single argument\nℹ Did you accidentally put `+` on a new line?\n\n\n\n\n\n\n3.4.2.5 Multiple geoms\nPart of the power of ggplot2 is that you can add more than one geom to a plot by adding on extra layers and so it quickly becomes possible to make complex and informative visualisation. Importantly, the layers display in the order you set them up. The code below uses the same geoms to produce a scatterplot with a line of best fit, but orders them differently.\n\n# Points first\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point() + # scatterplot\n  geom_smooth(method = lm) # line of best fit\n\n# Line first\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_smooth(method = lm) + # line of best fit\n  geom_point() # scatterplot\n\n\n\n\n\nFigure 3.6: Points first versus line first.\n\n\n\n\n3.4.2.6 Saving plots\nJust like you can save numbers and data tables to objects, you can also save the output of ggplot(). The code below produces the same plots we created above but saves them to objects named point_first and line_first. If you run just this code, the plots won’t display like they have done before. Instead, you’ll see the object names appear in the environment pane.\n\npoint_first &lt;- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point() + # scatterplot\n  geom_smooth(method = lm) # line of best fit\n  \nline_first &lt;-\n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_smooth(method = lm) + # line of best fit\n  geom_point() # scatterplot\n\nTo view the plots, call the objects by name. This will output each plot separately.\n\npoint_first # view first plot\nline_first # view second plot\n\n\n3.4.2.7 Combining plots\nOne of the reasons to save your plots to objects is so that you can combine multiple plots using functions from the patchwork package. The below code produces the above plot by combining the two plots with + and then specifying that we want the plots produced on a single row with the nrow argument in plot_layout().\n\n# add plots together in 1 row\npoint_first + line_first + plot_layout(nrow = 1)\n\n\n\nFigure 3.7: Combining plots with patchwork.\n\n\n\n\n\n\n\n\n\nTry changing nrow to 2\n\n\n\n\n\n\n\n3.4.3 Customising plots\nThere are nearly endless ways to customise ggplots. We’ll cover a few of the basic customisations here.\n\n3.4.3.1 Styling geoms\nWe should definitely put the line in front of the points, but the points are still a bit dark. If you want to change the overall style of a geom, you can set the arguments colour, alpha, shape, size and linetype inside the geom function. There are many different values that you can set these to; Appendix J) gives details of these. Play around with different values below and figure out what the default values are for shape and size.\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(colour = \"dodgerblue\", \n             alpha = 0.2, # 20% transparency\n             shape = 18,  # solid diamond\n             size = 2) + \n  geom_smooth(method = lm, \n              formula = y~x, # formula used to draw line, \n              # setting method & formula avoids an annoying message\n              colour = rgb(0, .5, .8),\n              linetype = 3) \n\n\n\nFigure 3.8: Changing geom styles.\n\n\n\n\n\n\n\n\n\nSetting aesthetics overall versus by category\n\n\n\nThis method is only for changing the style of all the shapes made with that geom. If you want, for example, points to have different colours depending on which issue category they are from, you set the argument colour = issue_category inside the aes() function for the mapping. You can customise the colours used with scale_ functions, which you will learn about below and in Appendix J).\n\n\n\n3.4.3.2 Format axes\nNow we need to make the axes look neater. There are several functions you can use to change the axis labels, but the most powerful ones are the scale_ functions. You need to use a scale function that matches the data you’re plotting on that axis and this is where it becomes particularly important to know what type of data you’re working with. Both of the axes here are continuous, so we’ll use scale_x_continuous() and scale_y_continuous().\nThe name argument changes the axis label. The breaks argument sets the major units and needs a vector of possible values, which can extend beyond the range of the data (e.g., wait time only goes up to 350, but we can specify breaks up to 600 to make the maths easier or anticipate updates to the data). The seq() function creates a sequence of numbers from one to another by specified steps.\n\n\n\nExample of seq()\n\nseq(from = 0, to = 600, by = 60)\n\n\n [1]   0  60 120 180 240 300 360 420 480 540 600\n\n\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(colour = \"dodgerblue\", \n             alpha = 0.2) + \n  geom_smooth(method = lm, \n              formula = y~x, \n              colour = rgb(0, .5, .8)) +\n  # customise axis labels and breaks\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30))\n\n\n\nFigure 3.9: Formatting plot axes with scale_ functions.\n\n\n\n\n\n\n\n\n\nMinor breaks\n\n\n\nCheck the help for ?scale_x_continuous to see how you would set the minor units or specify how many breaks you want instead.\n\n\n\n3.4.3.3 Axis limits\nIf you want to change the minimum and maximum values on an axis, use the coord_cartesian() function. Many plots make more sense if the minimum and maximum values represent the range of possible values, even if those values aren’t present in the data. Here, wait and call times can’t be less than 0 seconds, so we’ll set the minimum values to 0 and the maximum values to the first break above the highest value.\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(colour = \"dodgerblue\", \n             alpha = 0.2) + \n  geom_smooth(method = lm, \n              formula = y~x, \n              colour = rgb(0, .5, .8)) +\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30)) +\n  # set axis limits\n  coord_cartesian(xlim = c(0, 360), \n                  ylim = c(0, 180))\n\n\n\nFigure 3.10: Changing the axis limits.\n\n\n\n\n\n\n\n\n\nSetting limits with the scale_ function\n\n\n\nYou can also set the limits argument inside the scale_ functions, but this actually removes any data that falls outside these limits, rather than cropping your plot, and this can change the appearance of certain types of plots like violin plots and density plots.\n\n\n\n3.4.3.4 Themes\nggplot2 comes with several built-in themes, such as theme_minimal() and theme_bw(), but the ggthemes package provides even more themes to match different software, such as GoogleDocs or Stata, or publications, such as the Economist or the Wall Street Journal. Let’s add the GoogleDocs theme, but change the font size to 20 with the base_size argument.\nIt’s also worth highlighting that this code is starting to look quite complicated because of the number of layers, but because we’ve built it up slowly it should (hopefully!) make sense. If you see examples of ggplot2 code online that you’d like to adapt, build the plot up layer by layer and it will make it easier to understand what each layer adds.\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(colour = \"dodgerblue\", \n             alpha = 0.2) + \n  geom_smooth(method = lm, \n              formula = y~x, \n              colour = rgb(0, .5, .8)) +\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30)) +\n  coord_cartesian(xlim = c(0, 360), \n                  ylim = c(0, 180)) +\n  # change the theme\n  ggthemes::theme_gdocs(base_size = 20)\n\n\n\nFigure 3.11: Changing the theme to the Google Docs style.\n\n\n\n\n3.4.3.5 Theme tweaks\nIf you’re still not quite happy with a theme, you can customise it even further with the themes() function. Check the help for this function to see all of the possible options. The most common thing you’ll want to do is to remove an element entirely. You do this by setting the relevant argument to element_blank(). Below, we’re getting rid of the x-axis line and the plot background, which removes the line around the plot.\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(colour = \"dodgerblue\", \n             alpha = 0.2) + \n  geom_smooth(method = lm, \n              formula = y~x, \n              colour = rgb(0, .5, .8)) +\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30)) +\n  coord_cartesian(xlim = c(0, 360), \n                  ylim = c(0, 180)) +\n  theme_gdocs(base_size = 11) +\n  # customise theme elements\n  theme(axis.line.x = element_blank(),\n        plot.background = element_blank())\n\n\n\nFigure 3.12: Customising the theme to remove the x-axis line and background outline.\n\n\n\n\n3.4.4 Figure captions\nYou can add a caption directly to the image using the labs() function, which also allows you to add or edit the title, subtitle, and axis labels.\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(colour = \"dodgerblue\", \n             alpha = 0.2) + \n  geom_smooth(method = lm, \n              formula = y~x, \n              colour = rgb(0, .5, .8)) +\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30)) +\n  coord_cartesian(xlim = c(0, 360), \n                  ylim = c(0, 180)) +\n  theme_gdocs(base_size = 11) +\n  theme(axis.line.x = element_blank(),\n        plot.background = element_blank()) +\n  labs(title = \"The relationship between wait time and call time\",\n       subtitle = \"2020 Call Data\",\n       caption = \"Figure 1. As wait time increases, call time increases.\")\n\n\n\nFigure 3.13: Adding a title, subtitle, and caption.\n\n\n\nHowever, it is more accessible to include this sort of information in plain text for screen readers. You can add a text caption in the chunk header, and some document types will even automatically number figures for you (you’ll learn about this in ?sec-linked-docs). You can also add alt-text descriptions for screen readers that describe the image.\n\n\n```{r fig-wait-vs-call, fig.cap=\"As wait time increases, call time increases.\", fig.alt=\"A scatterplot showing wait time on the x-axis (range 0-360 seconds) and call time on the y-axis (range 0-180 seconds) with a trend line showing that as wait time increases, call time increases from about 60 wait/30 call to about 300 wait/65 call.\"}\n# figure code here\n```"
  },
  {
    "objectID": "03-viz.html#appropriate-plots",
    "href": "03-viz.html#appropriate-plots",
    "title": "3  Data Visualisation",
    "section": "\n3.5 Appropriate plots",
    "text": "3.5 Appropriate plots\nNow that you know how to build up a plot by layers and customise its appearance, you’re ready to learn about some more plot types. Different types of data require different types of plots, so this section is organised by data type.\nThe ggplot2 cheat sheet is a great resource to help you find plots appropriate to your data, based on how many variables you’re plotting and what type they are. The examples below all use the same customer satisfaction data, but each plot communicates something different.\nWe don’t expect you to memorise all of the plot types or the methods for customising them, but it will be helpful to try out the code in the examples below for yourself, changing values to test your understanding.\n\n3.5.1 Counting categories\n\n3.5.1.1 Bar plot\nIf you want to count the number of things per category, you can use geom_bar(). You only need to provide a x mapping to geom_bar() because by default geom_bar() uses the number of observations in each group of x as the value for y, so you don’t need to tell it what to put on the y-axis.\n\nggplot(survey_data, aes(x = issue_category)) +\n  geom_bar()\n\n\n\nFigure 3.14: A basic bar plot.\n\n\n\n\n\n\n\n\n\nCustomising bar plot appearance\n\n\n\nYou probably want to customise some things, like the colours, order of the columns, and their labels. Inspect the code below and try running it layer by layer to figure out where these things change. The functions scale_fill_manual() and scale_x_discrete() are new, but work in the same way as the other scale_ functions. You’ll learn more about this in ?sec-custom-viz.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(survey_data, aes(x = issue_category, \n                        fill = issue_category)) +\n  geom_bar() +\n  scale_x_discrete(\n    # change axis title\n    name = \"Issue Category\", \n    # change order\n    limits = c(\"tech\", \"returns\", \"sales\", \"other\"), \n    # change labels\n    labels = c(\"Technical\", \"Returns\", \"Sales\", \"Other\") \n  ) +\n  scale_fill_manual(\n    # change colours\n    values = c(tech = \"goldenrod\", \n                returns = \"darkgreen\", \n                sales = \"dodgerblue3\", \n                other = \"purple3\"),\n    # remove the legend\n    guide = \"none\" \n  ) +\n  scale_y_continuous(\n    name = \"\", # remove axis title\n    # remove the space above and below the y-axis\n    expand = expansion(add = 0)\n  ) +\n  # minimum = 0, maximum = 350\n  coord_cartesian(ylim = c(0, 350)) + \n  ggtitle(\"Number of issues per category\") # add a title\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.1.2 Column plot\nIf your data already have a column with the number you want to plot, you can use geom_col() to plot it. We can use the count() function to make a table with a row for each issue_category and a column called n with the number of observations in that category.\n\ncount_data &lt;- count(survey_data, issue_category)\n\n\n\nissue_category\nn\n\n\n\ntech\n311\n\n\nsales\n88\n\n\nreturns\n232\n\n\nother\n76\n\n\n\nThe mapping for geom_col() requires you to set both the x and y aesthetics. Set y = n because we want to plot the number of issues in each category, and that information is in the column called n.\n\nggplot(count_data, aes(x = issue_category, y = n)) +\n  geom_col()\n\n\n\nFigure 3.15: A basic column plot.\n\n\n\n\n3.5.1.3 Pie chart\nPie charts are a misleading form of data visualisation, so we won’t cover them. We’ll cover options for visualising proportions, like waffle, lollipop and treemap plots, in ?sec-other-plots.\n\n\n\n\n\n\nTest your understanding\n\n\n\nHere is a small data table.\n\n\ncountry\npopulation\nisland\n\n\n\nNorthern Ireland\n1,895,510\nIreland\n\n\nWales\n3,169,586\nGreat Britain\n\n\nRepublic of Ireland\n4,937,786\nIreland\n\n\nScotland\n5,466,000\nGreat Britain\n\n\nEngland\n56,550,138\nGreat Britain\n\n\n\n\nWhat geom would you use to plot the population for each of the 5 countries? \ngeom_bar\ngeom_col\n\n\n\n\nWhat mapping would you use?\n\naes(x = country, y = population)aes(x = population, y = country)aes(x = country)aes(x = island)aes(y = population)\n\n\n\n\n\nWhat geom would you use to plot the number of countries on each island? \ngeom_bar\ngeom_col\n\n\n\n\nWhat mapping would you use?\n\naes(x = country, y = population)aes(x = population, y = country)aes(x = country)aes(x = island)aes(y = population)\n\n\n\n\n\n\n\n3.5.2 One continuous variable\nIf you have a continuous variable, like the number of seconds callers have to wait, you can use geom_histogram() to show the distribution. Just like geom_bar() you are only required to specify the x variable.\nA histogram splits the data into “bins” along the x-axis and shows the count of how many observations are in each bin along the y-axis.\n\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nFigure 3.16: Histogram of wait times.\n\n\n\nYou should always set the binwidth or number of bins to something meaningful for your data (otherwise you get the annoying message above). You might need to try a few options before you find something that looks good and conveys the meaning of your plot – try changing the values of binwidth and bins below to see what works best.\n\n# adjust width of each bar\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(binwidth = 30)\n\n# adjust number of bars\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(bins = 5)\n\nBy default, the bars start centered on 0, so if binwidth is set to 30, the first bar would include -15 to 15 seconds, which doesn’t make much sense. We can set boundary = 0 so that each bar represents increments of 30 seconds starting from 0.\n\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(binwidth = 30, boundary = 0)\n\n\n\nFigure 3.17: A histogram with the boundary set to 0.\n\n\n\nFinally, the default style of grey bars is ugly, so you can change that by setting the fill and colour, as well as using scale_x_continuous() to update the axis labels.\n\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(binwidth = 15, \n                 boundary = 0, \n                 fill = \"white\", \n                 color = \"black\") +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60))\n\n\n\nFigure 3.18: Histogram with custom styles.\n\n\n\n\n\n\n\n\n\nTest your understanding\n\n\n\nImagine you have a table of the population for each country in the world with the columns country and population. We’ll just look at the 76 countries with populations of less than a million.\n\n\n\n\n\n\n\n\n\n\nHow would you set the mapping for this plot?\n\naes(x = country, y = population)aes(x = population, y = country)aes(x = population)aes(x = population, y = count)\n\n\n\n\n\nWhat is the binwidth of the histogram? \n1\n100\n100K\n1M\n\n\n\n\n\n\n\n\n\n\nAxis label customisation\n\n\n\n\n\nIf you’re curious how we got the x-axis labels to read “100K” instead of “100000”, you just need to add a vector of labels the same length as breaks.\n\n  scale_x_continuous(breaks = seq(0, 1e6, 1e5),\n                     labels = c(paste0(0:9*100, \"K\"), \"1M\"))\n\n\n\n\n\n3.5.3 Grouped continuous variables\nThere are several ways to compare continuous data across groups. Which you choose depends on what point you are trying to make with the plot.\n\n3.5.3.1 Stacked histogram\nIn previous plots, we have used fill purely for visual reasons, e.g., we changed the colour of the histogram bars to make them look nicer. However, you can also use fill to represent another variable so that the colours become meaningful.\nSetting the fill aesthetic in the mapping will produce different coloured bars for each category of the fill variable, in this case issue_category.\n\nggplot(survey_data, aes(x = wait_time, fill = issue_category)) +\n  geom_histogram(boundary = 0, \n                 binwidth = 15,\n                 color = \"black\")\n\n\n\nHistogram with categories represented by fill.\n\n\n\n\n\n\n\n\n\nArguments inside aes()\n\n\n\nWhen you set an aspect to represent the data, you do this inside the aes() function for the mapping, not as an argument to the geom. If you try to set this in a geom, you’ll get the following error (unless you coincidentally have an object named issue_category that is a colour word).\n\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(boundary = 0, \n                 binwidth = 15, \n                 color = \"black\",\n                 fill = issue_category)\n\nError in eval(expr, envir, enclos): object 'issue_category' not found\n\n\n\n\n\n\n\n\n\n\nArea plot alternative\n\n\n\n\n\nThe function geom_area() gives a similar effect when stat = \"bin\".\n\n# area plot\nggplot(survey_data, mapping = aes(x = wait_time, fill = issue_category)) +\n  geom_area(stat = \"bin\", \n            boundary = 0, \n            binwidth = 15, \n            color = \"black\")\n\n\n\nStacked area plot.\n\n\n\n\n\n\n\n3.5.3.2 Dodged histogram\nBy default, the categories are positioned stacked on top of each other. If you want to compare more than one distribution, you can set the position argument of geom_histogram() to “dodge” to put the bars for each group next to each other instead of stacking them. However, this can look confusing with several categories.\n\n# dodged histogram\nggplot(survey_data, aes(x = wait_time, \n                        fill = issue_category,\n                        colour = issue_category))+\n  geom_histogram(boundary = 0, \n                 binwidth = 15, \n                 position = \"dodge\") +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60))\n\n\n\nFigure 3.19: A histogram with multiple groups.\n\n\n\n\n\n\n\n\n\nFrequency plot alternative\n\n\n\n\n\nAlternatively, you can use geom_freqpoly() to plot a line connecting the top of each bin (see ?sec-freqpoly).\n\n# frequency plot\nggplot(survey_data, aes(x = wait_time,\n                        colour = issue_category)) +\n  geom_freqpoly(binwidth = 15, \n                boundary = 0,\n                size = 1) +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\nFigure 3.20: A frequency plot with multiple groups.\n\n\n\n\n\n\n\n3.5.3.3 Violin plot\nAnother way to compare groups of continuous variables is the violin plot. This is like a density plot, but rotated 90 degrees and mirrored - the fatter the violin, the larger proportion of data points there are at that value.\n\nviolin_area &lt;- \n  ggplot(survey_data, aes(x = issue_category, y = wait_time)) +\n  geom_violin() +\n  ggtitle('scale = \"area\"')\n\nviolin_count &lt;- \n  ggplot(survey_data, aes(x = issue_category, y = wait_time)) +\n  geom_violin(scale = \"count\") +\n  ggtitle('scale = \"count\"')\n\nviolin_area + violin_count\n\n\n\nFigure 3.21: The default violin plot gives each shape the same area. Set scale=‘count’ to make the size proportional to the number of observations.\n\n\n\n\n3.5.3.4 Boxplot\nBoxplots serve a similar purpose to violin plots (without the giggles from the back row). They don’t show you the shape of the distribution, but rather some statistics about it. The middle line represents the median; half the data are above this line and half below it. The box encloses the 25th to 75th percentiles of the data, so 50% of the data falls inside the box. The “whiskers” extending above and below the box extend 1.5 times the height of the box, although you can change this with the coef argument. The points show outliers – individual data points that fall outside of this range.\nBoxplots can be horizontal if you swap to x and y columns, and there are many other customisations you can apply.\n\nboxplot &lt;- ggplot(survey_data, aes(x = issue_category, y = wait_time)) +\n geom_boxplot() +\n  ggtitle(\"Default vertical boxplot\")\n\ncustom &lt;- ggplot(survey_data, aes(y = issue_category,x = wait_time)) +\n geom_boxplot(fill = \"grey80\", \n              outlier.colour = \"red\",\n              outlier.shape = 8,\n              coef = 1,   # length of whiskers relative to box\n              varwidth = TRUE, # set width proportional to sample size\n              notch = TRUE) +\n  ggtitle(\"Customised horizontal boxplot\")\n\nboxplot + custom\n\n\n\nFigure 3.22: Boxplots.\n\n\n\n\n3.5.3.5 Combo plots\nViolin plots are frequently layered with other geoms that represent the mean or median values in the data. This is a lot of code; to help your understanding, run it layer by layer to see how it builds up and change the values throughout the code.\n\n# add fill and colour to the mapping\n\nggplot(survey_data,  aes(x = issue_category, \n                         y = wait_time,\n                         fill = issue_category,\n                         colour = issue_category)) +\n  scale_x_discrete(name = \"Issue Category\") +\n  scale_y_continuous(name = \"Wait Time (seconds)\",\n                     breaks = seq(0, 600, 60)) +\n  coord_cartesian(ylim = c(0, 360)) +\n  guides(fill = \"none\", colour = \"none\") + \n  # add a violin plot\n  geom_violin(draw_quantiles = 0.5, # adds a line at median (50%) score\n              alpha = 0.4) + \n  # add a boxplot\n  geom_boxplot(width = 0.25, \n               fill = \"white\", \n               alpha = 0.75, \n               fatten = 0, # removes the median line\n               outlier.alpha = 0) + \n  # add a point that represents the mean\n  stat_summary(fun = mean, \n               geom = \"point\", \n               size = 2) + \n  ggtitle(\"ViolinBox\")\n\n\n\nFigure 3.23: Violin plots combined with different methods to represent means and medians.\n\n\n\n\n\n\n\n\n\nMisleading Bar Charts\n\n\n\n\n\nA very common type of plot is to produce a bar chart of means, however, the example below demonstrates just how misleading this is. It communicates the mean value for each category, but the bars hide the distribution of the actual data. You can’t tell if most wait times are close to 3 minutes, or spread from 0 to 6 minutes, or if the vast majority are less than 2 minutes, but the mean is pulled up by some very high outliers.\nColumn plots can also be very misleading. The plot on the left starts the y-axis at 0, which makes the bar heights proportional, showing almost no difference in average wait times. Since the differences are hard to see, you may be tempted to start the y-axis higher, but that makes it look like the average wait time for returns is double that for tech.\n\n\n\n\nFigure 3.24: Don’t plot continuous data with column plots. They are only appropriate for count data.\n\n\n\n\n\n\n\n\n\n\n\n\nTest your understanding\n\n\n\n\n\n\n\n\n\n\n\n\nHow would you create plot A? \ngeom_box()\ngeom_boxplot()\ngeom_violin()\ngeom_violinplot()\n\nHow would you create plot B? \ngeom_box()\ngeom_boxplot()\ngeom_violin()\ngeom_violinplot()\n\nWhat does the mapping look like for both plots?\n\naes(x = employee_id, y = call_time, colour = call_time)aes(x = employee_id, y = call_time, fill = employee_id)aes(x = employee_id, y = call_time, colour = employee_id)aes(x = employee_id, y = call_time, fill = call_time)\n\n\nWhich employee has the longest median call time? \ne01\ne02\ne03\ne04\ne05\ne06\ne07\ne08\ne09\ne10\n\nWhich employee has the record longest call? \ne01\ne02\ne03\ne04\ne05\ne06\ne07\ne08\ne09\ne10\n\n\n\n\n\n3.5.4 Two continuous variables\nWhen you want to see how two continuous variables are related, set one as the x-axis and the other as the y-axis. Usually, if one variable causes the other, you plot the cause on the x-axis and the effect on the y-axis. Here, we want to see if longer wait times cause the calls to be longer.\n\n3.5.4.1 Scatterplot\nThe function to create a scatterplot is called geom_point().\n\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point()\n\n\n\nFigure 3.25: Scatterplot with geom_point().\n\n\n\n\n3.5.4.2 Trendlines\nIn Figure 3.1, we emphasised the relationship between wait time and call time with a trendline created by geom_smooth() using the argument method = lm (“lm” stands for “linear model” or a straight line relationship). You can also set method = loess to visualise a non-linear relationship.\n\nlm_plot &lt;- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = lm, formula = y~x) +\n  ggtitle(\"method = lm\")\n\nloess_plot &lt;- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = loess, formula = y~x) +\n  ggtitle(\"method = loess\")\n\nlm_plot + loess_plot\n\n\n\nFigure 3.26: Different ways to show the relationship between two continuous variables.\n\n\n\n\n\n\n\n\n\nError shading\n\n\n\nIf there isn’t much data at the extremes of the x-axis, the curve can be very uncertain. This is represented by the wider shaded area, which means that the true relationship might be anywhere within that area. Add the argument se = FALSE to geom_smooth() to remove this “standard error” shading.\n\n\n\n3.5.4.3 Dates\nThe call_start column contains both a date and a time, so use the date() function from lubridate to convert it to just a date. We’ll need it in this format to be able to transform the x-axis below.\n\nggplot(survey_data, aes(x = lubridate::date(call_start), \n                        y = satisfaction)) + \n  geom_smooth(method = lm, formula = y~x)\n\n\n\nFigure 3.27: Plotting dates.\n\n\n\nWe can use scale_x_date() to set the date_breaks to be “1 month” apart. The date_labels argument uses a code for different date formats; you can see the full list of possibilities in the help for ?strptime. For example, %b means “Abbreviated month name”, whilst if you wanted to use a format like “2020/01/31” you could try \"%Y/%m/%d\".\n\nggplot(survey_data, aes(x = lubridate::date(call_start), \n                        y = satisfaction)) +\n  geom_smooth(method = lm, formula = y~x) +\n  scale_x_date(name = \"\",\n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  scale_y_continuous(name = \"Caller Satisfaction\") +\n  ggtitle(\"2020 Caller Satisfaction\")\n\n\n\nFigure 3.28: Plotting dates with breaks one month apart.\n\n\n\n\n\n\n\n\n\nTest yourself\n\n\n\nIt looks like customer satisfaction declined across the year, but is this change meaningful? See what the plot looks like when the y-axis spans the full range of possible satisfaction values from 1 to 5. You can also plot the individual data points to emphasise the range of values.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(survey_data, aes(x = lubridate::date(call_start), \n                        y = satisfaction)) +\n  # show individual data, jitter the height to avoid overlap\n  geom_jitter(width = 0, height = .1, alpha = 0.2) + \n  geom_smooth(method = lm,  formula = y~x) +\n  scale_x_date(name = \"\",\n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  scale_y_continuous(name = \"Caller Satisfaction\",\n                     breaks = 1:5) +\n  coord_cartesian(ylim = c(1, 5)) + # changes limits\n  ggtitle(\"2020 Caller Satisfaction\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.5 Overplotting\nWhen you have a limited range of numeric values, such as an ordinal rating scale, sometimes overlapping data makes it difficult to see what is going on in a point plot. For example, the plot below shows satisfaction ratings by call time, but because all the ratings are 1, 2, 3, 4 or 5, it makes it hard to see exactly how many data points there are at each point.\nIn this section, we’ll explore a few options for dealing with this.\n\nggplot(survey_data, aes(x = call_time, y = satisfaction)) + \n  geom_point()\n\n\n\nFigure 3.29: Overlapping data makes plots hard to understand.\n\n\n\n\n3.5.5.1 Jitter plot\nYou can use geom_jitter() to move the points around a bit to make them easier to see. You can also set alpha transparency. Here, the x-axis is continuous, so there is no need to jitter the width, but the y-axis is ordinal categories, so the height is jittered between -0.2 and +0.2 away from the true y-value.\n\n\n\n\n\n\nChange these values to understand what jitter is doing\n\n\n\n\n\n\n\nggplot(survey_data, aes(x = call_time, y = satisfaction)) +\n  geom_jitter(width = 0, height = .2, alpha = 0.5)\n\n\n\nFigure 3.30: Jitter plot.\n\n\n\n\n3.5.5.2 Facets\nAlternatively, you can use facet_wrap() to create a separate plot for each level of satisfaction. facet_wrap() uses the tilde (~) symbol, which you can roughly translate as “by”, e.g., facet the plot by satisfaction rating. The labeller function controls the labels above each plot. label_both specifies that we want both the variable name (satisfaction) and the value (e.g., 1) printed on the plot to make it easier to read.\n\nggplot(survey_data, aes(x = call_time)) +\n  geom_histogram(binwidth = 10, \n                 boundary = 0, \n                 fill = \"dodgerblue\", \n                 color = \"black\") +\n  facet_wrap(~satisfaction, \n             ncol = 1, # try changing this to 2 \n             labeller = label_both) +\n  scale_x_continuous(name = \"Call Time (seconds)\",\n                     breaks = seq(0, 600, 30))\n\n\n\nFigure 3.31: A histogram with facets.\n\n\n\n\n\n\n\n\n\nMore plots styles\n\n\n\nThese are not, by any means, all the plot types that you can make in R. This chapter just gave you a basic overview, and we will go into more detail in ?sec-custom-viz). The further resources section at the end of this chapter lists many resources, but the R Graph Gallery is especially useful to get inspiration for the kinds of beautiful plots you can make in R."
  },
  {
    "objectID": "03-viz.html#exercises",
    "href": "03-viz.html#exercises",
    "title": "3  Data Visualisation",
    "section": "\n3.6 Exercises",
    "text": "3.6 Exercises\nFor the final step in this chapter, we will create a report of data visualisations. You may need to refer back to Chapter 2) to help you complete these exercises and you may also want to take a break before you work through this section. We’d also recommend you knit at every step so that you can see how your output changes.\n\n3.6.1 New Markdown\nCreate and save a new R Markdown document named plots_report.Rmd and give it the title “Customer satisfaction report”. Remove the default template text and then load the packages and code below in the set-up code chunk:\n\nlibrary(tidyverse) \nlibrary(patchwork) \nlibrary(ggthemes)  \nlibrary(lubridate) \nlibrary(knitr)\nlibrary(kableExtra)\n\nsurvey_data &lt;- read_csv(\"https://psyteachr.github.io/ads-v2/data/survey_data.csv\")\n\n\n3.6.2 Summary\nCreate a level 1 heading titled “Overview”. Underneath this heading, write a short summary of what the data set contains and what each of the variables means (you can use the information from Section 3.4.1 if you like).\n\n3.6.3 Presenting plots\nPick your two favourites plots from all the examples we’ve made in this chapter. For each plot:\n\nCreate a level 2 heading in your R Markdown document and give it an informative title.\nWrite a short summary that interprets the data shown in the plots - it’s not enough just to present visualisations, effective reports will also help the reader understand the conclusions they should draw from the plots you’ve presented.\nLook through the different themes available with ggtheme and choose one to apply to your plots.\nMake sure each plot has a figure caption (either by adding this to the ggplot() code or adding it to the code chunk options).\nOrganise your Markdown so that the plots are shown after the text summary.\n\n3.6.4 Combining plots\nNow, pick your two least favourite plots:\n\nAdjust the visual aesthetics to make them look as bad and as difficult to read as possible.\nCombine the plots with the original version using patchwork functions.\nWrite a short summary that explains why you think these plots are so bad.\nOrganise your Markdown so that the plots are shown after the text summary.\n\n3.6.5 Editing your Markdown display\nAdjust the set-up of your Markdown so that your knitted report does not show any code, messages, or warnings, and all figures are 8 x 5 (see Section 2.7.1).\n\n3.6.6 Share your work\nOnce you’ve completed this activity, post it in the Week 3 channel on Teams so that you can compare which plots you chose and visual style with other learners on the course."
  },
  {
    "objectID": "03-viz.html#sec-glossary-viz",
    "href": "03-viz.html#sec-glossary-viz",
    "title": "3  Data Visualisation",
    "section": "\n3.7 Glossary",
    "text": "3.7 Glossary\n\n\n\nterm\ndefinition\n\n\n\nargument\nA variable that provides input to a function.\n\n\ncategorical\nData that can only take certain values, such as types of pet.\n\n\ncategorical\nData that can only take certain values, such as types of pet.\n\n\ncharacter\nA data type representing strings of text.\n\n\nchunk\nA section of code in an R Markdown file\n\n\ncontinuous\nData that can take on any values between other existing values.\n\n\ncontinuous\nData that can take on any values between other existing values.\n\n\ndata-type\nThe kind of data represented by an object.\n\n\ndefault-value\nA value that a function uses for an argument if it is skipped.\n\n\ndouble\nA data type representing a real decimal number\n\n\nfactor\nA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimenter\n\n\ngeom\nThe geometric style in which data are displayed, such as boxplot, density, or histogram.\n\n\ninteger\nA data type representing whole numbers.\n\n\nknit\nTo create an HTML, PDF, or Word document from an R Markdown (Rmd) document\n\n\nlikert\nA rating scale with a small number of discrete points in order\n\n\nlogical\nA data type representing TRUE or FALSE values.\n\n\nmedian\nThe middle number in a distribution where half of the values are larger and half are smaller.\n\n\nnominal\nCategorical variables that don't have an inherent order, such as types of animal.\n\n\nnumeric\nA data type representing a real decimal number or integer.\n\n\nobservation\nAll of the data about a single trial or question.\n\n\nordinal\nDiscrete variables that have an inherent order, such as level of education or dislike/like.\n\n\noutlier\nA data point that is extremely distant from most of the other data points\n\n\nr-markdown\nThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.\n\n\nstring\nA piece of text inside of quotes.\n\n\ntidy-data\nA format for data that maps the meaning onto the structure.\n\n\nvalue\nA single number or piece of data.\n\n\nvariable\n(coding): A word that identifies and stores the value of some data for later use; (stats): An attribute or characteristic of an observation that you can measure, count, or describe\n\n\nvector\nA type of data structure that collects values with the same data type, like T/F values, numbers, or strings."
  },
  {
    "objectID": "03-viz.html#sec-resources-viz",
    "href": "03-viz.html#sec-resources-viz",
    "title": "3  Data Visualisation",
    "section": "\n3.8 Further Resources",
    "text": "3.8 Further Resources\n\nggplot2 cheat sheet\n\nData visualisation using R, for researchers who don’t use R (Nordmann et al., 2021)\n\n\nChapter 1: Data Visualisation of R for Data Science\n\nggplot2 FAQs\nggplot2 documentation\n\nHack Your Data Beautiful workshop by University of Glasgow postgraduate students\n\nChapter 28: Graphics for communication of R for Data Science\n\n\ngganimate: A package for making animated plots\n\n\n\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L. M. (2021). Data visualisation using R, for researchers who don’t use R. PsyArXiv. https://doi.org/10.31234/osf.io/4huvw"
  },
  {
    "objectID": "04-summary.html#sec-ilo-summary",
    "href": "04-summary.html#sec-ilo-summary",
    "title": "4  Data Summaries",
    "section": "Intended Learning Outcomes",
    "text": "Intended Learning Outcomes\n\nBe able to load data from external files\nBe able to summarise data by groups\nUse pipes to chain together functions"
  },
  {
    "objectID": "04-summary.html#functions-ch04",
    "href": "04-summary.html#functions-ch04",
    "title": "4  Data Summaries",
    "section": "\n4.1 Functions used",
    "text": "4.1 Functions used\narrange(), clean_names(), col_factor(), col_skip(), cols(), count(), desc(), filter(), group_by(), head(), mean(), median(), mutate(), read_csv(), sum(), summarise(), ungroup()"
  },
  {
    "objectID": "04-summary.html#sec-walkthrough-summary",
    "href": "04-summary.html#sec-walkthrough-summary",
    "title": "4  Data Summaries",
    "section": "Walkthrough video",
    "text": "Walkthrough video\nThere is a walkthrough video of this chapter available via Echo360. Please note that there may have been minor edits to the book since the video was recorded. Where there are differences, the book should always take precedence."
  },
  {
    "objectID": "04-summary.html#sec-setup-summary",
    "href": "04-summary.html#sec-setup-summary",
    "title": "4  Data Summaries",
    "section": "\n4.2 Set-up",
    "text": "4.2 Set-up\nFirst, create a new project for the work we’ll do in this chapter named 04-summary. Second, download the data for this chapter (12.1_delivery.csv) and save it in your project data folder. Finally, open and save and new R Markdown document named summary.Rmd, delete the welcome text and load the required packages for this chapter.\n\n\n\nChapter packages\n\nlibrary(tidyverse)   # data wrangling functions\nlibrary(janitor)     # data cleaning functions\nlibrary(kableExtra)  # for nice tables\n\n\nDownload the Data transformation cheat sheet."
  },
  {
    "objectID": "04-summary.html#import-data",
    "href": "04-summary.html#import-data",
    "title": "4  Data Summaries",
    "section": "\n4.3 Import Data",
    "text": "4.3 Import Data\nThe data we’ll be working with is on method of delivery for singleton births from Public Health Scotland. You can see the most recent version at Method of Delivery, but we’ll be working from a saved version.\nThe data are in a CSV file, so we can read this with the function read_csv() , and assign it to a new object that we’ll call births. You can learn more about importing data from other file types in Appendix G.\n\nbirths &lt;- read_csv(\"data/12.1_delivery.csv\")\n\nRows: 97077 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): FinancialYear, CA, SIMDQuintileQF, SIMDVersion, AgeGroup, Delivery,...\ndbl (2): SIMDQuintile, Livebirths\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you load data with read_csv(), you get a quick summary that you should always check to see if the data were loaded correctly. One common problem is that data load with the the wrong type (see Appendix H), usually because a numeric column contains some unexpected text values. So the first thing to check is that each column has the expected data type. The abbreviation “chr” means this is a character column, which can contain any text. The abbreviation “dbl” is a double, which is a number that can have decimal places.\nThere are too many columns to show all of them in the summary, so it tells you to use the spec() function to check all the columns.\n\nspec(births)\n\ncols(\n  FinancialYear = col_character(),\n  CA = col_character(),\n  SIMDQuintile = col_double(),\n  SIMDQuintileQF = col_character(),\n  SIMDVersion = col_character(),\n  AgeGroup = col_character(),\n  Delivery = col_character(),\n  Induced = col_character(),\n  Livebirths = col_double()\n)\n\n\nThis gives you the info formatted inside the cols() function to make it easy for you to copy and edit this if any of the columns imported incorrectly.\nYou can also use the glimpse() function to check the type of each column, and see a few examples of the cell values.\n\nglimpse(births)\n\nRows: 97,077\nColumns: 9\n$ FinancialYear  &lt;chr&gt; \"1997/98\", \"1997/98\", \"1997/98\", \"1997/98\", \"1997/98\", …\n$ CA             &lt;chr&gt; \"RA2704\", \"RA2704\", \"RA2704\", \"RA2704\", \"RA2704\", \"RA27…\n$ SIMDQuintile   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ SIMDQuintileQF &lt;chr&gt; \":\", \":\", \":\", \":\", \":\", \":\", \":\", \":\", \":\", \":\", \":\", …\n$ SIMDVersion    &lt;chr&gt; \"SIMD2004\", \"SIMD2004\", \"SIMD2004\", \"SIMD2004\", \"SIMD20…\n$ AgeGroup       &lt;chr&gt; \"25-34\", \"25-34\", \"25-34\", \"25-34\", \"25-34\", \"25-34\", \"…\n$ Delivery       &lt;chr&gt; \"Caesarean - Elective\", \"Caesarean - Emergency\", \"Caesa…\n$ Induced        &lt;chr&gt; \"Not Induced\", \"Induced\", \"Not Induced\", \"Induced\", \"No…\n$ Livebirths     &lt;dbl&gt; 9, 5, 8, 1, 6, 21, 60, 4, 4, 3, 1, 1, 1, 14, 2, 6, 1, 7…\n\n\nThe column SIMDQuintileQF looks a little odd. We can quickly check what all the values are in a data table with the count() function:\n\ncount(births, SIMDQuintileQF)\n\n\n\n\n\n\nSIMDQuintileQF\n\n\nn\n\n\n\n\n\n:\n\n\n1137\n\n\n\n\nNA\n\n\n95940\n\n\n\n\n\n\n\nIt looks like this column doesn’t contain any useful info, so we can just ignore it, or skip it. To do this at the point of loading in the data, we create an object (birth_cols) that contains our column specification using the col_types argument and two helper functions, cols() and col_skip(). We then pass birth_cols to the col_types argument of read_csv() which uses this info to amend the file that is loaded in.\n\n# edit the output of spec(births)\nbirth_cols &lt;- cols(\n  SIMDQuintileQF = col_skip()\n)\n\nbirths &lt;- read_csv(\"data/12.1_delivery.csv\", col_types = birth_cols)\n\nThere’s also additional edits you can make to the initial file, for example, you can also set the order of levels for categorical data when you first import it.\nTo check which groups our data has, we can use the count() function to check the level labels for AgeGroup, Delivery and Induced; and set sort = TRUE to sort by frequency.\n\ncount(births, AgeGroup)\ncount(births, Delivery, sort = TRUE)\ncount(births, Induced, sort = TRUE)\n\n\n\n\n\n\nAgeGroup\n\n\nn\n\n\n\n\n\n25-34\n\n\n37557\n\n\n\n\n35 and over\n\n\n29592\n\n\n\n\nUnder 25\n\n\n29918\n\n\n\n\nUnknown\n\n\n10\n\n\n\n\n\n\n\n\n\n\nDelivery\n\n\nn\n\n\n\n\n\nSpontaneous\n\n\n25607\n\n\n\n\nCaesarean - Emergency\n\n\n22526\n\n\n\n\nForceps\n\n\n19041\n\n\n\n\nVacuum\n\n\n14573\n\n\n\n\nCaesarean - Elective\n\n\n12417\n\n\n\n\nBreech\n\n\n2483\n\n\n\n\nNot Known\n\n\n430\n\n\n\n\n\n\n\n\n\n\nInduced\n\n\nn\n\n\n\n\n\nNot Induced\n\n\n54217\n\n\n\n\nInduced\n\n\n39097\n\n\n\n\nUnknown\n\n\n3763\n\n\n\n\n\n\n\nWe’ll now add on extra code to birth_cols to set the order of our factors. What order you choose will depend on what makes most sense for the data. For AgeGroup we’ll list them in chronological order, whilst for Delivery and Induced, we’ll sort them according to the highest value - it can be helpful to think of what order you’ll like the bars to be in if you were making a graph.\n\n# edit the output of spec(births)\nbirth_cols &lt;- cols(\n  SIMDQuintileQF = col_skip(),\n  AgeGroup = col_factor(levels = c(\"Under 25\", \"25-34\", \"35 and over\",\"Unknown\")),\n  Delivery = col_factor(levels = c(\"Spontaneous\", \n                                   \"Caesarean - Emergency\", \n                                   \"Forceps\", \n                                   \"Vacuum\", \n                                   \"Caesarean = Elective\", \n                                   \"Breech\", \n                                   \"Not Known\")),\n  Induced = col_factor(levels = c(\"Not Induced\", \"Induced\", \"Unknown\"))\n)\n\nbirths &lt;- read_csv(\"data/12.1_delivery.csv\", col_types = birth_cols)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe levels for Delivery are numerous and complex, which increases the risk of a typo and is just tedious to type. Here is a quick trick to generate the text you can copy and paste into your code. The function dput() gives you the code you can use to recreate an object.\n\n\n\nType in the console\n\ndelivery_table &lt;- count(births, Delivery, sort = TRUE)\ndput(delivery_table$Delivery)\n\n\nstructure(c(1L, 2L, 3L, 4L, NA, 6L, 7L), levels = c(\"Spontaneous\", \n\"Caesarean - Emergency\", \"Forceps\", \"Vacuum\", \"Caesarean = Elective\", \n\"Breech\", \"Not Known\"), class = \"factor\")\n\n\n\n\n\n4.3.1 Clean up names\nData sets often import with column names that are a little difficult to use in code. You can manually rename them, but the janitor package makes this incredibly easy. This dataset has pretty good names, with no spaces or special characters, but it does use uppercase letters to separate words, which can be hard to remember. the clean_names() function changes everything to lowercase and uses underscores to separate word parts. Using clean_names everytime you import a dataset is a good habit to get into.\n\nbirths &lt;- clean_names(births)\n\ncolnames(births)\n\n[1] \"financial_year\" \"ca\"             \"simd_quintile\"  \"simd_version\"  \n[5] \"age_group\"      \"delivery\"       \"induced\"        \"livebirths\"    \n\n\n\n4.3.2 Exploring a Dataset\nThere are 97077 rows and 8 columns of data. The data dictionary on the NHS website includes the following, but doesn’t clearly state what the possible values are for each column. We’re going to practice figuring out more about how data is structured using data summaries in this exercise, since it’s a common task to get a mysteriously formatted data file and need to figure it out yourself. At the very least, this exercise should remind you to never do this to other people – always provide a clear codebook with all values!\n\n\n\n\n\n\n\nColumn\nType\nLabel\n\n\n\nFinancialYear\ntext\nData is recorded for financial years (1st April to 31st March) based on the date of the mother’s discharge\n\n\nCA\ntext\n9-digit code for Council areas based on boundaries as at 1st April 2019\n\n\nSIMDQuintile\ntext\nScottish Index of Multiple Deprivation (SIMD) quintile; 1(Most Deprived) - 5(Least Deprived)\n\n\nSIMDQuintileQF\ntext\nQualifier for SIMDQuintile indicating unknown quintiles\n\n\nSIMDVersion\ntext\nMost appropriate SIMD release used for each year\n\n\nAgeGroup\ntext\nAge Group of the mother at time of admission\n\n\nDelivery\ntext\nThe method by which the baby was delivered\n\n\nInduced\ntext\nWas the delivery induced, that is, was it started artificially\n\n\nLivebirths\nnumeric\nNumber of live births\n\n\n\n4.3.3 The $ operator\nWe need to take a couple of brief detours to introduce some additional coding conventions. First, let’s introduce the $ notation. The dollar sign allows you to select items from an object, such as columns from a table. The left-hand side is the object, and the right-hand side is the item. When you call a column like this, R will return all the observations in that column.\n\nyears &lt;- births$financial_year\n\nIf your item has multiple observations, you can specify which ones to return using square brackets [] and the row number or a vector of row numbers.\n\nbirths$financial_year[1] # select one observation\nbirths$age_group[c(20,30,40)] # select multiple with c()\n\n[1] \"1997/98\"\n[1] Under 25 25-34    Under 25\nLevels: Under 25 25-34 35 and over Unknown\n\n\n\n4.3.4 Pipes\n\n\n\nLet’s say you want to filter the dataset down to just the emergency C-sections, and then sum up the total number of live births per year, and then arrange the data from largest to smallest (don’t worry, we’ll introduce these functions soon). You could do it by creating intermediate objects for each step:\n\nc_sections &lt;- filter(births, delivery == \"Caesarean - Emergency\")\nc_per_year &lt;- summarise(c_sections, n = sum(livebirths), .by = financial_year)\nc_sorted &lt;- arrange(c_per_year, desc(n))\n\nhead(c_sorted)\n\n\n\n\n\n\nfinancial_year\n\n\nn\n\n\n\n\n\n2014/15\n\n\n8964\n\n\n\n\n2015/16\n\n\n8958\n\n\n\n\n2021/22\n\n\n8920\n\n\n\n\n2011/12\n\n\n8916\n\n\n\n\n2013/14\n\n\n8810\n\n\n\n\n2022/23\n\n\n8739\n\n\n\n\n\n\n\nWhilst the above code is functional, it adds three unnecessary objects to the environment, increasing the risk we’ll use one of these objects by mistake. Enter… the pipe.\nLet’s formally introduce the pipe, that weird %&gt;% you may have seen. Pipes allow you to send the output from one function straight into another function. Specifically, they send the result of the function before %&gt;% to be the first argument of the function after %&gt;%. It can be useful to translate the pipe as “and then”. It’s easier to show than tell, so let’s look at an example.\n\nc_per_year &lt;- births %&gt;% # start with the births table, and then\n  # filter the table to just emergency c-sections\n  filter(delivery == \"Caesarean - Emergency\") %&gt;% # and then\n  # calculate the total number of births per year\n  summarise(n = sum(livebirths), .by = financial_year) %&gt;% # and then\n  # sort by n, descending\n  arrange(desc(n))\n\nhead(c_per_year)\n\n\n\n\n\n\nfinancial_year\n\n\nn\n\n\n\n\n\n2014/15\n\n\n8964\n\n\n\n\n2015/16\n\n\n8958\n\n\n\n\n2021/22\n\n\n8920\n\n\n\n\n2011/12\n\n\n8916\n\n\n\n\n2013/14\n\n\n8810\n\n\n\n\n2022/23\n\n\n8739\n\n\n\n\n\n\n\nNotice that filter(), summarise()andarrange()` no longer need the first argument to be the data table, it is pulled in from the pipe above. The power of the pipe may not be obvious now, but it will soon prove its worth.\n\n\n\n\n\n\nNote\n\n\n\nBase R recently added a “native pipe” that looks like this: |&gt;, while the tidyverse has traditionally used the “magrittr pipe” that looks like this %&gt;%. They have a few small differences that you don’t need to learn about yet. We’ll be using the magrittr pipe, but you might see the base R pipe in other sources."
  },
  {
    "objectID": "04-summary.html#counting",
    "href": "04-summary.html#counting",
    "title": "4  Data Summaries",
    "section": "\n4.4 Counting",
    "text": "4.4 Counting\nYou can count categorical data with the count() function. This will give you a new table with each combination of the counted columns and a column called n containing the number of observations from that group.\nLet’s figure out how entries there were per delivery type. The first argument is the name of the data table object, and the second argument is the name of the column we want to count.\n\ncount(births, delivery)\n\n\n\n\n\n\ndelivery\n\n\nn\n\n\n\n\n\nSpontaneous\n\n\n25607\n\n\n\n\nCaesarean - Emergency\n\n\n22526\n\n\n\n\nForceps\n\n\n19041\n\n\n\n\nVacuum\n\n\n14573\n\n\n\n\nBreech\n\n\n2483\n\n\n\n\nNot Known\n\n\n430\n\n\n\n\nNA\n\n\n12417\n\n\n\n\n\n\n\nThere are 7 types of deliveries, and the new column n tells you how many rows of the data table there are per type.\nYou can add on a column with the numbers expressed in percent using the function mutate(). We’ll go into more detail on how to use mutate() in ?sec-wrangle, but for now, it can be used to add new columns or overwrite existing columns.\n\ncount(births, delivery) %&gt;%\n  mutate(percent = n/sum(n)*100)\n\n\n\n\n\n\ndelivery\n\n\nn\n\n\npercent\n\n\n\n\n\nSpontaneous\n\n\n25607\n\n\n26.3780298\n\n\n\n\nCaesarean - Emergency\n\n\n22526\n\n\n23.2042605\n\n\n\n\nForceps\n\n\n19041\n\n\n19.6143268\n\n\n\n\nVacuum\n\n\n14573\n\n\n15.0117948\n\n\n\n\nBreech\n\n\n2483\n\n\n2.5577634\n\n\n\n\nNot Known\n\n\n430\n\n\n0.4429474\n\n\n\n\nNA\n\n\n12417\n\n\n12.7908773\n\n\n\n\n\n\n\nWe can also count combination of columns by adding more arguments. The table below shows the number of rows per age group and induction status, sorted by the number of rows. We won’t add on percent just yet as the additional variable requires another function that we’ll come back to later.\n\ncount(births, age_group, induced, sort = TRUE)\n\n\n\n\n\n\nage_group\n\n\ninduced\n\n\nn\n\n\n\n\n\n25-34\n\n\nNot Induced\n\n\n20441\n\n\n\n\n35 and over\n\n\nNot Induced\n\n\n16965\n\n\n\n\nUnder 25\n\n\nNot Induced\n\n\n16805\n\n\n\n\n25-34\n\n\nInduced\n\n\n15176\n\n\n\n\nUnder 25\n\n\nInduced\n\n\n12206\n\n\n\n\n35 and over\n\n\nInduced\n\n\n11711\n\n\n\n\n25-34\n\n\nUnknown\n\n\n1940\n\n\n\n\n35 and over\n\n\nUnknown\n\n\n916\n\n\n\n\nUnder 25\n\n\nUnknown\n\n\n907\n\n\n\n\nUnknown\n\n\nNot Induced\n\n\n6\n\n\n\n\nUnknown\n\n\nInduced\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHow would you create the table of counts below?\n\n\n\n\n\n\n\ninduced\n\n\nn\n\n\n\n\n\nNot Induced\n\n\n54217\n\n\n\n\nInduced\n\n\n39097\n\n\n\n\nUnknown\n\n\n3763\n\n\n\n\n\n\n\n\ncount(induced, births)count(induced, births, sort = TRUE)count(births, induced)count(births, induced, sort = TRUE)\n\n\n\nHowever, the numbers above are not the number of births, but rather the number of rows in the data set. The column live_births contains the number per each category, so we will need to add those numbers together to see the total number of births."
  },
  {
    "objectID": "04-summary.html#sec-summary-summarise",
    "href": "04-summary.html#sec-summary-summarise",
    "title": "4  Data Summaries",
    "section": "\n4.5 Summarise",
    "text": "4.5 Summarise\nThe summarise() function from the dplyr package is loaded as part of the tidyverse and creates summary statistics. It creates a new table with columns that summarise the data from a larger table using summary functions. Check the Data Transformation Cheat Sheet for various summary functions. Some common ones are: n(), min(), max(), sum(), mean(), and quantile().\n\n\n\n\n\n\nWarning\n\n\n\nIf you get the answer NA from a summary function, that usually means that there are missing values in the columns you were summarising. This may seem counter-intuitive but it is actually very logical if you consider that NA means “I don’t know the value of this cell” because the average of 1 + 2 + I don’t know isn’t 1.5, it’s “I don’t know”. We’ll discuss this more in ?sec-missing-values, but you can ignore missing values for many functions by adding the argument na.rm = TRUE.\n\nvalues &lt;- c(1, 2, 4, 3, NA, 2)\nmean(values) # is NA\nmean(values, na.rm = TRUE) # removes NAs first\n\n[1] NA\n[1] 2.4\n\n\n\n\nThis function can be used to answer questions like: How many total live births were there? What are the mean and median number of births per year? Let’s start with a very simple example to calculate the total number of births:\n\nThe first argument that summarise() takes is the data table you wish to summarise, in this case the object delivery.\n\nsummarise() will create a new table. The column names of this new table will be the left hand-side arguments (e.g., total_births)\nThe values of these columns are the result of the summary operation on the right hand-side.\n\n\nsummarise(births,\n          total_births = sum(livebirths))\n\n\n\n\n\n\ntotal_births\n\n\n\n\n1351669\n\n\n\n\n\n\nIf you want to summarise by category, you can use the .by argument, as long as you have a version of dplyr that is 1.1.0 or above (if not, you can use the method in the next section).\n\nsummarise(births,\n          total_births = sum(livebirths),\n          .by = delivery)\n\n\n\n\n\n\ndelivery\n\n\ntotal_births\n\n\n\n\n\nNA\n\n\n156405\n\n\n\n\nCaesarean - Emergency\n\n\n209473\n\n\n\n\nForceps\n\n\n115698\n\n\n\n\nSpontaneous\n\n\n815827\n\n\n\n\nVacuum\n\n\n50470\n\n\n\n\nBreech\n\n\n3282\n\n\n\n\nNot Known\n\n\n514\n\n\n\n\n\n\n\nIf you want to group by more than one column, use the c() function to group the column names.\n\nsummarise(births,\n          total_births = sum(livebirths),\n          .by = c(delivery, induced))\n\n\n\n\n\n\ndelivery\n\n\ninduced\n\n\ntotal_births\n\n\n\n\n\nNA\n\n\nNot Induced\n\n\n154531\n\n\n\n\nCaesarean - Emergency\n\n\nInduced\n\n\n81812\n\n\n\n\nCaesarean - Emergency\n\n\nNot Induced\n\n\n125973\n\n\n\n\nForceps\n\n\nInduced\n\n\n42440\n\n\n\n\nForceps\n\n\nNot Induced\n\n\n72528\n\n\n\n\nSpontaneous\n\n\nInduced\n\n\n225033\n\n\n\n\nSpontaneous\n\n\nNot Induced\n\n\n586595\n\n\n\n\nVacuum\n\n\nNot Induced\n\n\n32492\n\n\n\n\nVacuum\n\n\nInduced\n\n\n17714\n\n\n\n\nBreech\n\n\nInduced\n\n\n300\n\n\n\n\nBreech\n\n\nNot Induced\n\n\n2966\n\n\n\n\nSpontaneous\n\n\nUnknown\n\n\n4199\n\n\n\n\nVacuum\n\n\nUnknown\n\n\n264\n\n\n\n\nCaesarean - Emergency\n\n\nUnknown\n\n\n1688\n\n\n\n\nNot Known\n\n\nNot Induced\n\n\n331\n\n\n\n\nNA\n\n\nInduced\n\n\n1549\n\n\n\n\nForceps\n\n\nUnknown\n\n\n730\n\n\n\n\nNot Known\n\n\nInduced\n\n\n146\n\n\n\n\nBreech\n\n\nUnknown\n\n\n16\n\n\n\n\nNA\n\n\nUnknown\n\n\n325\n\n\n\n\nNot Known\n\n\nUnknown\n\n\n37"
  },
  {
    "objectID": "04-summary.html#sec-grouping",
    "href": "04-summary.html#sec-grouping",
    "title": "4  Data Summaries",
    "section": "\n4.6 Grouping",
    "text": "4.6 Grouping\nYou can also create summary values by group using a combination of group_by() and summarise(). The function group_by() takes an existing data table and converts it into a grouped table, where any operations that are subsequently performed on it are done “by group”.\nIt differs from the .by argument to summarise() in that it is persistent, so the table stays grouped until you explicitly remove the groups using the ungroup() functions, while the .by argument only applies to the function it is inside. Most of the code examples you’ll see use this style, since the .by argument is fairly new.\n\nbirths %&gt;%\n  group_by(delivery) %&gt;%\n  summarise(births = sum(livebirths)) %&gt;%\n  ungroup()\n\n\n\n\n\n\ndelivery\n\n\nbirths\n\n\n\n\n\nSpontaneous\n\n\n815827\n\n\n\n\nCaesarean - Emergency\n\n\n209473\n\n\n\n\nForceps\n\n\n115698\n\n\n\n\nVacuum\n\n\n50470\n\n\n\n\nBreech\n\n\n3282\n\n\n\n\nNot Known\n\n\n514\n\n\n\n\nNA\n\n\n156405\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure you call the ungroup() function when you are done with grouped functions. Failing to do this can cause all sorts of mysterious problems if you use that data table later assuming it isn’t grouped.\n\n\nYou might have noticed that the order of the table above is different from the order when using the .by argument of summarise(). This is because group_by() always sorts the values in the grouping columns in ascending order, while .by leaves them in the order they are first encountered in your data frame. Use the function arrange() to manually change order (see ?sec-arrange).\n\nbirths %&gt;%\n  group_by(delivery) %&gt;%\n  summarise(births = sum(livebirths)) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(births)) # sort by number of births in descending order\n\n\n\n\n\n\ndelivery\n\n\nbirths\n\n\n\n\n\nSpontaneous\n\n\n815827\n\n\n\n\nCaesarean - Emergency\n\n\n209473\n\n\n\n\nNA\n\n\n156405\n\n\n\n\nForceps\n\n\n115698\n\n\n\n\nVacuum\n\n\n50470\n\n\n\n\nBreech\n\n\n3282\n\n\n\n\nNot Known\n\n\n514\n\n\n\n\n\n\n\n\n4.6.1 Multiple groupings\nYou can add multiple variables to group_by() to further break down your data. For example, the below gives us the number of births broken down by delivery type and year.\n\nReverse the order of delivery and financial_yearingroup_by()` to see how it changes the output.\n\n\nbirths %&gt;%\n  group_by(delivery, financial_year) %&gt;%\n  summarise(n = sum(livebirths)) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nWarning\n\n\n\nYou may get the following message when using summarise() after group_by().\n\nsummarise() has grouped output by ‘delivery’. You can override using the .groups argument.\n\nTidyverse recently added a message to remind you whether the summarise() function automatically ungroups grouped data or not (it may do different things depending on how it’s used). You can set the argument .groups to “drop”, “drop_last”, “keep”, or “rowwise” (see the help for ?summarise), but it’s good practice to explicitly use ungroup() when you’re done working by groups, regardless.\n\n\n\n4.6.2 Percent by groups\nCalculating percent by groups is a great example of the flexibility of group_by() but also why you have to be very careful and always check the output of your code.\nWhen we just had one variable to count, adding percent was nice and easy:\n\ncount(births, delivery) %&gt;%\n  mutate(percent = n/sum(n)*100)\n\n\n\n\n\n\ndelivery\n\n\nn\n\n\npercent\n\n\n\n\n\nSpontaneous\n\n\n25607\n\n\n26.3780298\n\n\n\n\nCaesarean - Emergency\n\n\n22526\n\n\n23.2042605\n\n\n\n\nForceps\n\n\n19041\n\n\n19.6143268\n\n\n\n\nVacuum\n\n\n14573\n\n\n15.0117948\n\n\n\n\nBreech\n\n\n2483\n\n\n2.5577634\n\n\n\n\nNot Known\n\n\n430\n\n\n0.4429474\n\n\n\n\nNA\n\n\n12417\n\n\n12.7908773\n\n\n\n\n\n\n\nWith multiple variables, problems can arise if we use the exact same approach because by default, it will calculate the percent that each row contributes to the dataset as a whole. This might be what you want:\n\ncount(births, age_group, induced, sort = TRUE)%&gt;%\n  mutate(percent = n/sum(n)*100)\n\n\n\n\n\n\nage_group\n\n\ninduced\n\n\nn\n\n\npercent\n\n\n\n\n\n25-34\n\n\nNot Induced\n\n\n20441\n\n\n21.0564809\n\n\n\n\n35 and over\n\n\nNot Induced\n\n\n16965\n\n\n17.4758182\n\n\n\n\nUnder 25\n\n\nNot Induced\n\n\n16805\n\n\n17.3110005\n\n\n\n\n25-34\n\n\nInduced\n\n\n15176\n\n\n15.6329512\n\n\n\n\nUnder 25\n\n\nInduced\n\n\n12206\n\n\n12.5735241\n\n\n\n\n35 and over\n\n\nInduced\n\n\n11711\n\n\n12.0636196\n\n\n\n\n25-34\n\n\nUnknown\n\n\n1940\n\n\n1.9984136\n\n\n\n\n35 and over\n\n\nUnknown\n\n\n916\n\n\n0.9435809\n\n\n\n\nUnder 25\n\n\nUnknown\n\n\n907\n\n\n0.9343099\n\n\n\n\nUnknown\n\n\nNot Induced\n\n\n6\n\n\n0.0061807\n\n\n\n\nUnknown\n\n\nInduced\n\n\n4\n\n\n0.0041204\n\n\n\n\n\n\n\nHowever, it’s more likely that you would want to calculate percent by groups. For example, what percent of people in the Induced category were in which age group? Or what percent of 25-34 year olds were induced? To calculate these numbers, we add in a call to group_by():\n\n# group by age, percentages within each age group will sum to 100\ncount(births, age_group, induced)%&gt;% #age then induced\n  group_by(age_group) %&gt;%\n  mutate(percent = n/sum(n)*100)\n\n# group by induced, percentages within each induction group will sum to 100\ncount(births, induced, age_group)%&gt;% #induced then age\n  group_by(induced) %&gt;%\n  mutate(percent = n/sum(n)*100)\n\n\n\n\n\n\nage_group\n\n\ninduced\n\n\nn\n\n\npercent\n\n\n\n\n\nUnder 25\n\n\nNot Induced\n\n\n16805\n\n\n56.170198\n\n\n\n\nUnder 25\n\n\nInduced\n\n\n12206\n\n\n40.798182\n\n\n\n\nUnder 25\n\n\nUnknown\n\n\n907\n\n\n3.031620\n\n\n\n\n25-34\n\n\nNot Induced\n\n\n20441\n\n\n54.426605\n\n\n\n\n25-34\n\n\nInduced\n\n\n15176\n\n\n40.407913\n\n\n\n\n25-34\n\n\nUnknown\n\n\n1940\n\n\n5.165482\n\n\n\n\n35 and over\n\n\nNot Induced\n\n\n16965\n\n\n57.329684\n\n\n\n\n35 and over\n\n\nInduced\n\n\n11711\n\n\n39.574885\n\n\n\n\n35 and over\n\n\nUnknown\n\n\n916\n\n\n3.095431\n\n\n\n\nUnknown\n\n\nNot Induced\n\n\n6\n\n\n60.000000\n\n\n\n\nUnknown\n\n\nInduced\n\n\n4\n\n\n40.000000\n\n\n\n\n\n\n\n\n\n\ninduced\n\n\nage_group\n\n\nn\n\n\npercent\n\n\n\n\n\nNot Induced\n\n\nUnder 25\n\n\n16805\n\n\n30.9958131\n\n\n\n\nNot Induced\n\n\n25-34\n\n\n20441\n\n\n37.7021967\n\n\n\n\nNot Induced\n\n\n35 and over\n\n\n16965\n\n\n31.2909235\n\n\n\n\nNot Induced\n\n\nUnknown\n\n\n6\n\n\n0.0110666\n\n\n\n\nInduced\n\n\nUnder 25\n\n\n12206\n\n\n31.2197867\n\n\n\n\nInduced\n\n\n25-34\n\n\n15176\n\n\n38.8162775\n\n\n\n\nInduced\n\n\n35 and over\n\n\n11711\n\n\n29.9537049\n\n\n\n\nInduced\n\n\nUnknown\n\n\n4\n\n\n0.0102310\n\n\n\n\nUnknown\n\n\nUnder 25\n\n\n907\n\n\n24.1031092\n\n\n\n\nUnknown\n\n\n25-34\n\n\n1940\n\n\n51.5546107\n\n\n\n\nUnknown\n\n\n35 and over\n\n\n916\n\n\n24.3422801\n\n\n\n\n\n\n\nIf you have updated dyplr then you can also use the .by argument in mutate():\n\n# group by age, percentages within each age group will sum to 100\ncount(births, age_group, induced)%&gt;% #age then induced\n  mutate(percent = n/sum(n)*100,\n         .by = age_group)\n\n# group by induced, percentages within each induction group will sum to 100\ncount(births, induced, age_group)%&gt;% #induced then age\n  mutate(percent = n/sum(n)*100,\n         .by = induced)\n\n\n\n\n\n\nage_group\n\n\ninduced\n\n\nn\n\n\npercent\n\n\n\n\n\nUnder 25\n\n\nNot Induced\n\n\n16805\n\n\n56.170198\n\n\n\n\nUnder 25\n\n\nInduced\n\n\n12206\n\n\n40.798182\n\n\n\n\nUnder 25\n\n\nUnknown\n\n\n907\n\n\n3.031620\n\n\n\n\n25-34\n\n\nNot Induced\n\n\n20441\n\n\n54.426605\n\n\n\n\n25-34\n\n\nInduced\n\n\n15176\n\n\n40.407913\n\n\n\n\n25-34\n\n\nUnknown\n\n\n1940\n\n\n5.165482\n\n\n\n\n35 and over\n\n\nNot Induced\n\n\n16965\n\n\n57.329684\n\n\n\n\n35 and over\n\n\nInduced\n\n\n11711\n\n\n39.574885\n\n\n\n\n35 and over\n\n\nUnknown\n\n\n916\n\n\n3.095431\n\n\n\n\nUnknown\n\n\nNot Induced\n\n\n6\n\n\n60.000000\n\n\n\n\nUnknown\n\n\nInduced\n\n\n4\n\n\n40.000000\n\n\n\n\n\n\n\n\n\n\ninduced\n\n\nage_group\n\n\nn\n\n\npercent\n\n\n\n\n\nNot Induced\n\n\nUnder 25\n\n\n16805\n\n\n30.9958131\n\n\n\n\nNot Induced\n\n\n25-34\n\n\n20441\n\n\n37.7021967\n\n\n\n\nNot Induced\n\n\n35 and over\n\n\n16965\n\n\n31.2909235\n\n\n\n\nNot Induced\n\n\nUnknown\n\n\n6\n\n\n0.0110666\n\n\n\n\nInduced\n\n\nUnder 25\n\n\n12206\n\n\n31.2197867\n\n\n\n\nInduced\n\n\n25-34\n\n\n15176\n\n\n38.8162775\n\n\n\n\nInduced\n\n\n35 and over\n\n\n11711\n\n\n29.9537049\n\n\n\n\nInduced\n\n\nUnknown\n\n\n4\n\n\n0.0102310\n\n\n\n\nUnknown\n\n\nUnder 25\n\n\n907\n\n\n24.1031092\n\n\n\n\nUnknown\n\n\n25-34\n\n\n1940\n\n\n51.5546107\n\n\n\n\nUnknown\n\n\n35 and over\n\n\n916\n\n\n24.3422801"
  },
  {
    "objectID": "04-summary.html#additional-functions",
    "href": "04-summary.html#additional-functions",
    "title": "4  Data Summaries",
    "section": "\n4.7 Additional Functions",
    "text": "4.7 Additional Functions\nYou can also use additional functions like filter() after group_by or with the .by argument. You’ll learn more about these in ?sec-wrangle but briefly:\n\n\nfilter() keeps observations (rows) according to specified criteria, e.g., all values above 5, or all induced births\n\narrange() sorts the rows by value\n\nYou can combine functions like this to get detailed insights into your data. For example, you can\n\nrecode the financial year into just the first year, and make it numeric\nfilter your data to remove unknown ages and delivery types\n\n\nbirths_per_year_type_age &lt;- births %&gt;%\n  mutate(year = str_extract(financial_year, \".{4}\"), # takes first four digits\n         year = as.integer(year)) %&gt;% # transform to numeric\n  filter(age_group != \"Unknown\", # remove unknown\n         delivery != \"Not Known\") %&gt;% # remove not known\n  summarise(n = sum(livebirths),\n            .by = c(year, delivery, age_group)) %&gt;%\n  mutate(pcnt = n / sum(n) * 100, \n         .by = c(year, age_group))\n  \n\n# show just the first 6 rows\nhead(births_per_year_type_age)\n\n\n\n\n\n\nyear\n\n\ndelivery\n\n\nage_group\n\n\nn\n\n\npcnt\n\n\n\n\n\n1997\n\n\nCaesarean - Emergency\n\n\n25-34\n\n\n3875\n\n\n12.095390\n\n\n\n\n1997\n\n\nForceps\n\n\n25-34\n\n\n2570\n\n\n8.021975\n\n\n\n\n1997\n\n\nSpontaneous\n\n\n25-34\n\n\n23933\n\n\n74.704248\n\n\n\n\n1997\n\n\nVacuum\n\n\n25-34\n\n\n1534\n\n\n4.788214\n\n\n\n\n1997\n\n\nCaesarean - Emergency\n\n\n35 and over\n\n\n1013\n\n\n15.362451\n\n\n\n\n1997\n\n\nForceps\n\n\n35 and over\n\n\n473\n\n\n7.173188\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRe-write the code above using group_by() instead of the .by argument?\n\n\nNow you can use your skills from Chapter 3 to plot the data! The code below has a few elements you haven’t seen before. For example, it adds a transparent horizontal line at 0, which is a trick to force all the y-axes to start at 0, but allows different scales per facet. It also angles the text in the x-axis.\n\nbirths_per_year_type_age  %&gt;%\n  ggplot(aes(x = year, y = pcnt, color = age_group)) +\n  geom_line() +\n  facet_wrap(~delivery, scales = \"free_y\") +\n  geom_hline(yintercept = 0, color = \"transparent\") + \n  labs(x = NULL, \n       y = \"Percent of Live Births per Year\",\n       color = \"Age Group\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\nFigure 4.1: ?(caption)"
  },
  {
    "objectID": "04-summary.html#exercises",
    "href": "04-summary.html#exercises",
    "title": "4  Data Summaries",
    "section": "\n4.8 Exercises",
    "text": "4.8 Exercises\nTake a break and then try one (or more) of the following:\n\nCreate an Rmd report that presents the above code with nice formatting. For example, hide the code from the output and format the tables.\nExplore the data and add at least one unique insights of your own to the report\nDownload a different data set from Scottish Health and Social Care Open Data and create summary tables and plots.\nIf you have data of your own, practice summarising this in R.\n\n\n4.8.1 Share on Teams\nOnce you’re done, share your knitted report and the Rmd file on Teams in the Week 04 channel."
  },
  {
    "objectID": "04-summary.html#sec-glossary-summary",
    "href": "04-summary.html#sec-glossary-summary",
    "title": "4  Data Summaries",
    "section": "\n4.9 Glossary",
    "text": "4.9 Glossary\n\n\n\nterm\ndefinition\n\n\n\ncategorical\nData that can only take certain values, such as types of pet.\n\n\ncharacter\nA data type representing strings of text.\n\n\ncsv\nComma-separated variable: a file type for representing data where each variable is separated from the next by a comma.\n\n\ndouble\nA data type representing a real decimal number\n\n\nmean\nA descriptive statistic that measures the average value of a set of numbers.\n\n\nmedian\nThe middle number in a distribution where half of the values are larger and half are smaller.\n\n\npipe\nA way to order your code in a more readable format using the symbol %&gt;%\n\n\nvector\nA type of data structure that collects values with the same data type, like T/F values, numbers, or strings."
  },
  {
    "objectID": "04-summary.html#sec-resources-summary",
    "href": "04-summary.html#sec-resources-summary",
    "title": "4  Data Summaries",
    "section": "\n4.10 Further resources",
    "text": "4.10 Further resources\n\nData transformation cheat sheet\n\nChapter 3: Data Transformation in R for Data Science\n\nkableExtra vignettes"
  },
  {
    "objectID": "05-formative.html#assessment-information",
    "href": "05-formative.html#assessment-information",
    "title": "5  Practice Report",
    "section": "5.1 Assessment information",
    "text": "5.1 Assessment information\n\nYou will be given a dataset and a finished report on that data. Your task is to write the code that produces the report.\nPlease check Moodle and the assessment information sheet for the deadline.\nThe solution will be released immediately after the deadline on Moodle.\nThis is a formative activity and does not count towards your course grade.\nYou should submit two files to Moodle to complete the exercise - your .Rmd file and the knitted html document.\nPlease read all the assessment information before attempting the exercise. Additionally, you should not expect to be able to complete it until you have worked through Chapters 1-5 (although particularly Chapters 1-3).\nThe practice report will not be individually graded. Instead, we will release the solution file so that you can compare your code to our solution as generic feedback. If you would like to discuss any aspect of the report, you can attend office hours with the course leads and/or teaching assistants."
  },
  {
    "objectID": "05-formative.html#intended-learning-outcomes-ilos",
    "href": "05-formative.html#intended-learning-outcomes-ilos",
    "title": "5  Practice Report",
    "section": "5.2 Intended Learning Outcomes (ILOs)",
    "text": "5.2 Intended Learning Outcomes (ILOs)\n\nKnowledge and skills\n\nDemonstrate the ability to use R for data wrangling and visualisation\nDemonstrate the ability to use R Markdown for reproducible reports\n\n\n\nEvaluation\n\nDemonstrate the ability to evaluate an output to understand the underlying data wrangling and analysis\n\n\n\nCommunication\n\nDemonstrate the ability to produce a clear and coherent report with appropriate spelling, grammar, and layout."
  },
  {
    "objectID": "05-formative.html#details-and-files",
    "href": "05-formative.html#details-and-files",
    "title": "5  Practice Report",
    "section": "5.3 Details and files",
    "text": "5.3 Details and files\n\nThere are two files you need to download. The first is the dataset: review_data.csv. The second is the finished report that you need to backwards engineer from the data: formative_report_output.html.\nThere are multiple ways to achieve the same outcome when coding. You do not have to use the same solutions that we did; what matters is that the output is the same.\nAll plots, and tables in the report should be fully reproducible, in addition, all numbers in bold should also be reproducible, i.e., you should use inline coding.\nFor any visuals, you should get as close to the example report as possible, although we recognise that it may be difficult to know the exact theme or colours used without seeing the code.\nIn order to replicate the report you will need the following skills:\n\nMarkdown text formatting (e.g., bold, italics, headings)\nAdding images to Markdown from online sources\nData visualisation\nSummarising data in tables Inline coding\n\n\nAlmost everything you need to do generate this report will have been covered at least once in the workbook, but you should also expect to need to Google some things – being able to search for alternative solutions is such a key skill for programming."
  },
  {
    "objectID": "05-formative.html#support",
    "href": "05-formative.html#support",
    "title": "5  Practice Report",
    "section": "5.4 Support",
    "text": "5.4 Support\nThis assessment will require you to use the skills you have learned from Chapter 1 (Intro to R and R Studio) up to and including Chapter 5 (Data Summaries) of the Applied Data Skills workbook. You can also ask for help on Teams, although because this is a formative activity, the help we give will be constrained.\nGoogle and Stack Overflow will help you a lot. Remember to include the names of packages and functions to help ensure the results are closer to what you’re trying to do."
  },
  {
    "objectID": "05-formative.html#helpful-hints",
    "href": "05-formative.html#helpful-hints",
    "title": "5  Practice Report",
    "section": "5.5 Helpful hints",
    "text": "5.5 Helpful hints\nA few hints to help you on your way:\n\nThis dataset is bigger than the ones you’ve used before, which means you might find it takes R a little longer to complete certain tasks.\nGoogling “ggplot rotate x axis labels” will help you out.\ntheme_fivethirtyeight()\nThe verified review definition is formatted as a block quote.\nCreate Awesome HTML Table with knitr::kable and kableExtra\nHow to Turn off scientific notation like 1e+09 in R?\nThere are a couple of ways you can create the final plot, one method might be to calculate the numbers you need first, and then use this new dataset for the plot, another method would be to use stat_summary()."
  },
  {
    "objectID": "05-formative.html#why-am-i-being-assessed-like-this",
    "href": "05-formative.html#why-am-i-being-assessed-like-this",
    "title": "5  Practice Report",
    "section": "5.6 Why am I being assessed like this?",
    "text": "5.6 Why am I being assessed like this?\nThis report serves as a practice for the full report, which will be due at the end of the semester. The practice report gives you the intended output so that you can focus on your coding skills, rather than deciding how to summarise and present the data. You will need to make these decisions for the full report.\nWhilst most of the skills required for the practice report have been explicitly taught, there are minor bits of the coding that will require you to look up solutions independently. This will be good practice for the final summative assessment and for applying your coding skills to your own work."
  },
  {
    "objectID": "app-installing-r.html#installing-base-r",
    "href": "app-installing-r.html#installing-base-r",
    "title": "Appendix A — Installing R",
    "section": "\nA.1 Installing Base R",
    "text": "A.1 Installing Base R\nInstall base R. Choose the download link for your operating system (Linux, Mac OS X, or Windows).\nIf you have a Mac, install the latest release from the newest R-x.x.x.pkg link (or a legacy version if you have an older operating system). You may also need to install XQuartz to be able to use some visualisation packages.\nIf you are installing the Windows version, choose the “base” subdirectory and click on the download link at the top of the page.\nIf you are using Linux, choose your specific operating system and follow the installation instructions.\n\n\n\n\n\n\nInstallation Location\n\n\n\nIt can often cause problems to install R on a network or cloud drive, such as OneDrive or DropBox. It’s better to install these programs on your computer’s drive. Depending on your computer’s settings, you may have to get IT support to give you access to installing programs.\nIt can also cause rare, but hard-to-debug problems if any of the folders in the path where you install R have non-Latin characters, including Chinese characters or Latin characters with accents (e.g., C:\\\\Daniël\\Programs\\)."
  },
  {
    "objectID": "app-installing-r.html#installing-rstudio",
    "href": "app-installing-r.html#installing-rstudio",
    "title": "Appendix A — Installing R",
    "section": "\nA.2 Installing RStudio",
    "text": "A.2 Installing RStudio\nGo to rstudio.com and download the RStudio Desktop (Open Source License) version for your operating system under the list titled Installers for Supported Platforms."
  },
  {
    "objectID": "app-installing-r.html#installing-rtools",
    "href": "app-installing-r.html#installing-rtools",
    "title": "Appendix A — Installing R",
    "section": "\nA.3 Installing RTools",
    "text": "A.3 Installing RTools\nIf you are using Windows, after you install R, you should also install RTools; use the “recommended” version highlighted near the top of the list. RTools is used for installing and loading some packages. You can get started without installing RTools, but if you’re having problems with installing and loading some packages, this should be the first thing you try.\nRTools will require you to put it “on the PATH”. The instructions for this can seem a bit vague - the easiest way to do it is to open RStudio, run the below code in the console:\n\nwrite('PATH=\"${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}\"', file = \"~/.Renviron\", append = TRUE)\n\nOnce you’ve done that, restart R by clicking Session - Restart R and then run the below code in the console which should give you the path to your RTools installation:\n\nSys.which(\"make\")\n\n           make \n\"/usr/bin/make\""
  },
  {
    "objectID": "app-installing-r.html#sec-rstudio-settings",
    "href": "app-installing-r.html#sec-rstudio-settings",
    "title": "Appendix A — Installing R",
    "section": "\nA.4 RStudio Settings",
    "text": "A.4 RStudio Settings\nThere are a few settings you should fix immediately after updating RStudio. Go to Tools &gt; Global Options… (⌘,), and in the General tab, uncheck the box that says Restore .RData into workspace at startup. If you keep things around in your workspace, things will get messy, and unexpected things will happen. You should always start with a clear workspace. This also means that you never want to save your workspace when you exit, so set this to Never. The only thing you want to save are your scripts.\nYou may also want to change the appearance of your code. Different fonts and themes can sometimes help with visual difficulties or dyslexia.\n\n\n\n\nRStudio General and Appearance settings\n\n\n\nYou may also want to change the settings in the Code tab. For example, Lisa prefers two spaces instead of tabs for my code and likes to be able to see the whitespace characters. But these are all a matter of personal preference.\n\n\n\n\nRStudio Code settings"
  },
  {
    "objectID": "app-installing-r.html#installing-latex",
    "href": "app-installing-r.html#installing-latex",
    "title": "Appendix A — Installing R",
    "section": "\nA.5 Installing LaTeX",
    "text": "A.5 Installing LaTeX\nYou can install the LaTeX typesetting system to produce PDF reports from RStudio. Without this additional installation, you will be able to produce reports in HTML but not PDF. To generate PDF reports, you will additionally need to install tinytex(Xie, 2021) and run the following code:\n\n# run this in the console\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n\n\n\n\n\nXie, Y. (2021). Tinytex: Helper functions to install and maintain TeX live, and compile LaTeX documents. https://github.com/yihui/tinytex"
  },
  {
    "objectID": "app-updating-r.html#updating-rstudio",
    "href": "app-updating-r.html#updating-rstudio",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "\nB.1 Updating RStudio",
    "text": "B.1 Updating RStudio\nRStudio is the easiest component to update. Typically, updates to RStudio won’t affect your code, instead they add in new features, like spell-check or upgrades to what RStudio can do. There’s usually very little downside to updating RStudio and it’s easy to do.\nClick Help - Check for updates\n\n\n\n\nUpdating RStudio\n\n\n\nIf an update is available, it will prompt you to download it and you can install it as usual."
  },
  {
    "objectID": "app-updating-r.html#updating-r",
    "href": "app-updating-r.html#updating-r",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "\nB.2 Updating R",
    "text": "B.2 Updating R\nFinally, you may also wish to update R itself. The key thing to be aware of is that when you update R, if you just download the latest version from the website, you will lose all your packages.\n\nB.2.1 Windows\nThe easiest way to update R on Windows and not cause yourself a huge headache is to use the installr package. When you use the updateR() function, a series of dialogue boxes will appear. These should be fairly self-explanatory but there is a full step-by-step guide available for how to use installr, the important bit is to select “Yes” when it asked if you would like to copy your packages from the older version of R.\n\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Run the update function\ninstallR::updateR()\n\n\nB.2.2 Mac\nFor a Mac, you can use the updateR”, “https://github.com/AndreaCirilloAC/updateR”)` package. You’ll need to install this from GitHub. You will be asked to type your system password (that you use to log into your computer) in the console pane. If relevant, it will ask you if you want to restore your packages for a new major version.\n\n# install from github\ndevtools::install_github(\"AndreaCirilloAC/updateR\")\n\n# update your R version, you will need your system password\nupdateR::updateR()"
  },
  {
    "objectID": "app-updating-r.html#updating-packages",
    "href": "app-updating-r.html#updating-packages",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "\nB.3 Updating packages",
    "text": "B.3 Updating packages\nPackage developers will occasionally release updates to their packages. This is typically to add in new functions to the package, or to fix or amend existing functions. Be aware that some package updates may cause your previous code to stop working. This does not tend to happen with minor updates to packages, but occasionally with major updates, you can have serious issues if the developer has made fundamental changes to how the code works. For this reason, we recommend updating all your packages once at the beginning of each academic year (or semester) - don’t do it before an assessment or deadline just in case!\nTo update an individual package, the easiest way is to use the install.packages() function, as this always installs the most recent version of the package.\n\ninstall.packages(\"tidyverse\")\n\nTo update multiple packages, or indeed all packages, RStudio provides helpful tools. Click Tools - Check for Package Updates. A dialogue box will appear and you can select the packages you wish to update. Be aware that if you select all packages, this may take some time and you will be unable to use R whilst the process completes.\n\n\n\n\nUpdating packages with RStudio"
  },
  {
    "objectID": "app-updating-r.html#sec-package-install-troubleshooting",
    "href": "app-updating-r.html#sec-package-install-troubleshooting",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "\nB.4 Troubleshooting",
    "text": "B.4 Troubleshooting\nOccasionally, you might have a few problem packages that seemingly refuse to update. For me, rlang and vctrs cause me no end of trouble. These aren’t packages that you will likely every explicitly load, but they’re required beneath the surface for R to do things like knit your Markdown files etc.\n\nB.4.1 Non-zero exit status\nIf you try to update a package and get an error message that says something like Warning in install.packages : installation of package ‘vctrs’ had non-zero exit status or perhaps Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :  namespace 'rlang' 0.4.9 is being loaded, but &gt;= 0.4.10 is required one solution I have found is to manually uninstall the package, restart R, and then install the package new, rather than trying to update an existing version. The installr package also has a useful function for uninstalling packages.\n\n# Load installr\nlibrary(installr)\n\n# Uninstall the problem package\nuninstall.packages(\"package_name\")\n\n# Then restart R using session - restart R\n# Then install the package fresh\n\ninstall.packages(\"package\")\n\n\nB.4.2 Cannot open file\nYou may get the following error after trying to install any packages at all:\n\nError in install packages : Cannot open file ‘C:/…..’: Permission denied\n\nThis usually indicates a permissions problem with writing to the default library (the folder that packages are kept in). Sometimes this means that you need to install R and RStudio as administrator or run it as administrator.\nOne other fix may be to change the library location using the following code (check in “C:/Program Files/R” for what version you should have instead of “R-3.5.2”):\n\n# change the library path\n.libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))\n\nIf that works and you can install packages, set this library path permanently:\n\nInstall the usethis package\nRun usethis::edit_r_profile() in the console; it will open up a blank file\nPaste into the file (your version of): .libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))\n\nSave and close the file\nRestart R for changes to take effect\n\nThe code in your .Rprofile will now run every time you start up R.\nAs always, if you’re having issues, please ask on Teams or come to office hours."
  },
  {
    "objectID": "app-symbols.html",
    "href": "app-symbols.html",
    "title": "Appendix C — Symbols",
    "section": "",
    "text": "Symbol\npsyTeachR Term\nAlso Known As\n\n\n\n()\n(round) brackets\nparentheses\n\n\n[]\nsquare brackets\nbrackets\n\n\n{}\ncurly brackets\nsquiggly brackets\n\n\n&lt;&gt;\nchevrons\nangled brackets / guillemets\n\n\n&lt;\nless than\n\n\n\n&gt;\ngreater than\n\n\n\n&\nampersand\n“and” symbol\n\n\n#\nhash\npound / octothorpe\n\n\n/\nslash\nforward slash\n\n\n\\\nbackslash\n\n\n\n-\ndash\nhyphen / minus\n\n\n_\nunderscore\n\n\n\n*\nasterisk\nstar\n\n\n^\ncaret\npower symbol\n\n\n~\ntilde\ntwiddle / squiggle\n\n\n=\nequal sign\n\n\n\n==\ndouble equal sign\n\n\n\n.\nfull stop\nperiod / point\n\n\n!\nexclamation mark\nbang / not\n\n\n?\nquestion mark\n\n\n\n’\nsingle quote\nquote / apostrophe\n\n\n”\ndouble quote\nquote\n\n\n%&gt;%\npipe\nmagrittr pipe\n\n\n|\nvertical bar\npipe\n\n\n,\ncomma\n\n\n\n;\nsemi-colon\n\n\n\n:\ncolon\n\n\n\n@\n“at” symbol\nvarious hilarious regional terms\n\n\n…\nglossary(\"ellipsis\")\ndots\n\n\n\n\n\n\n\nFigure C.1: Image by James Chapman/Soundimals"
  },
  {
    "objectID": "app-conventions.html#test-yourself",
    "href": "app-conventions.html#test-yourself",
    "title": "Appendix D — Conventions",
    "section": "\nD.1 Test Yourself",
    "text": "D.1 Test Yourself\nI am going to learn a lot: \nTRUE\nFALSE\n\n\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion\n\n\n\n\n\n\n\nHidden Solutions\n\nYou found it!"
  },
  {
    "objectID": "app-conventions.html#callout-boxes",
    "href": "app-conventions.html#callout-boxes",
    "title": "Appendix D — Conventions",
    "section": "\nD.2 Callout boxes",
    "text": "D.2 Callout boxes\nSee the quarto reference for more options.\n\n\n\n\n\n\nNote\n\n\n\nInformational asides.\n\n\n\n\n\n\n\n\nTip\n\n\n\nTips\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotes to warn you about something.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nNotes about things that could cause serious errors.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNotes about things that are important.\n\n\n\n\n\n\n\n\nTry (click to expand)\n\n\n\n\n\nTry it yourself."
  },
  {
    "objectID": "app-conventions.html#code-and-output",
    "href": "app-conventions.html#code-and-output",
    "title": "Appendix D — Conventions",
    "section": "\nD.3 Code and Output",
    "text": "D.3 Code and Output\n\n# code chunks\npaste(\"Code\", \"Output\", 1, sep = \" \")\n\n[1] \"Code Output 1\"\n\n\n\n\n```{r, fig.width = 2, fig.height = 2}\n# code chunks with headers\nhist(rnorm(100000))\n```\n\n\n## Markdown Example\n\n* Inline code: `r nrow(iris)`\n* *Italics*\n* **Bold**\n\n\n\n\nWickham, H. (2021). Tidyverse: Easily install and load the tidyverse. https://CRAN.R-project.org/package=tidyverse"
  },
  {
    "objectID": "app-teams.html#what-is-the-best-way-to-share-r-code-on-microsoft-teams",
    "href": "app-teams.html#what-is-the-best-way-to-share-r-code-on-microsoft-teams",
    "title": "Appendix E — Using Teams",
    "section": "\nE.1 What is the best way to share R code on Microsoft Teams?",
    "text": "E.1 What is the best way to share R code on Microsoft Teams?\nYou have run into a problem and need to get help on MS Teams. What is the right way to share your code?\nPlease do not share a screenshot unless you are asked, or if it is not the code that is giving you problems, but something weird is happening with the RStudio IDE.\nIf it’s your code that is not working, it is almost always better to copy and paste the code, because then people who are trying to help you can copy and paste the code exactly to try it out, rather than having to re-type everything from the image. Let’s look at an example. Below is a screenshot of how the RStudio IDE might look when your code throws an error. Here the code block labelled cars is causing the error.\n\n\na screenshot of RStudio IDE showing an error indicated by the red arrow\n\nThe particular error that our code threw was\nError in mtcars %&gt;% filter(mpg &gt; 20) : could not find function \"%&gt;%\"\nAnd the code that threw it was\n\nmtcars %&gt;%\n  filter(mpg &gt; 20)\n\nNote that you can select and copy the code above if you wanted to run it yourself, but you could not do that if all you had to rely on was the screenshot.\nCopying the code and/or error in RStudio is easy; just highlight the code using the mouse and press Ctrl-C.\nIf you just paste the code into a Teams channel, the formatting is not so nice; you lose the formatting that allows you to read the code easily.\n\n\nA screenshot of MS Teams with the code pasted directly in. Not pretty!\n\nHere are two ways to get your code into Teams, one that is quick and easy but not very flexible, and another that is far more flexible but requires more steps.\n\nE.1.1 Quick and easy method\nFirst, if it is just a short function call, a single line, or an error, you can signal that text is meant to appear as code by surrounding it by single backticks—i.e., putting a backtick (`) right before and right after the text that you want to be formatted as code. Teams will automatically format it for you.\nFor multi-line code, the easiest and fastest way is just to type three backticks inside your message at the beginning of a line. Any subsequent text you enter will be treated as code. To get to the beginning of a line without submitting your post, press Ctrl-Enter while typing your message. Then type the three backticks, and paste your code right into the gray box that automatically appears. Press Enter twice in a row to get back out of the code entry box. So your message might look like this. \nAbove, I surrounded the error message Error in mtcars %&gt;% filter(mpg &gt; 20) : could not find function \"%&gt;%\" with single backticks to indicate code, and we typed triple backticks at the start of the line to create a code chunk. (The next method might be easier for making multi-line posts.)\n\nE.1.2 More flexible method\nThere is a more flexible (and possibly easier) way. Before pasting any text, click on the icon that looks like the letter “A”, highlighted below.\n\n\nScreenshot of Teams showing the icon that looks like an “A”\n\nThis will open up options for text formatting and will allow you to easily create a multi-line post. From those options, select the icon that looks like &lt;/&gt;, which stands for code.\n\n\nScreenshot of Teams formatting icons, with code icon highlighted\n\nThe code icon will open a window where you can paste your code. In the dropdown menu on the top right, select ‘R’ as the type of code. This will give you syntax highlighting.\n\n\nScreenshot of Teams formatting icons, with code icon highlighted\n\nHere is how you might begin your post.\n\n\nScreenshot of Teams with unsubmitted post\n\n\nE.1.3 Reprex\nYou might see people in coding forums like StackOverflow asking for a “reprex”, or a reproducible example. This is the smallest, completely self-contained example of your problem or question.\nFor example, you may have a question about how to figure out how to select rows that contain the value “test” in a certain column, but it isn’t working. It’s clearer if you can provide a concrete example, but you don’t want to have to type out the whole table you’re using or all the code that got you to this point in your script.\nYou can include a very small table with just the basics or a smaller version of your problem. Make comments at each step about what you expect and what you actually got.\nWhich version is easier for you to figure out the solution?\n\n# this doesn't work\nno_test_data &lt;- data %&gt;%\n  filter(!str_detect(type, \"test\"))\n\n\n# with a minimal example table\ndata &lt;- tribble(\n  ~id, ~type, ~x,\n  1, \"test\", 12,\n  2, \"testosterone\", 15,\n  3, \"estrogen\", 10\n)\n\n# this should keep IDs 2 and 3, but removes ID 2\nno_test_data &lt;- data %&gt;%\n  filter(!str_detect(type, \"test\"))\n\nOne of the big benefits to creating a reprex is that you often solve your own problem while you’re trying to break it down to explain to someone else.\nIf you really want to go down the rabbit hole, you can create a reproducible example using the reprex package from tidyverse."
  },
  {
    "objectID": "app-teams.html#screenshots",
    "href": "app-teams.html#screenshots",
    "title": "Appendix E — Using Teams",
    "section": "\nE.2 Screenshots",
    "text": "E.2 Screenshots\nIf you do need to take a screenshot, for example, if something goes wrong during installation, please use the screenshot functions built-in to your computer rather than taking a photo of your screen using your phone.\n\nE.2.1 Taking a screenshot on Windows\n\nUse the Windows search function to search for “Snip & Sketch”\nClick “New” then “Snip now”\nUse the tool to select the area on the screen you want to take a screenshot of. This photo will automatically be copied to your clipboard, so you can paste it into e.g., a Teams chat or a document using Ctrl + V but you can also click the Save icon in the top right to save the screenshot as an image file.\nThe shortcut for the snipping tool is Win + Shift + S.\n\nE.2.2 Taking a screenshot on Mac\n\nPress Shift + Command (⌘) + 4 to bring up the Screenshot app.\nUse the tool to select the area on the screen you want to take a screenshot of.\nIf you see a thumbnail in the corner of your screen, click it to edit the screenshot or drag it into e.g., a Teams chat.\nThis photo will also automatically save to your desktop."
  },
  {
    "objectID": "app-debugging.html#report-setup",
    "href": "app-debugging.html#report-setup",
    "title": "Appendix F — Debugging",
    "section": "\nF.1 Report Setup",
    "text": "F.1 Report Setup\nCreate a new R Markdown file and delete everything below the setup chunk. Edit the YAML header to use a floating table of contents and add the outline of your report.\n---\ntitle: \"Report\"\ndate: \"2022-12-21\"\noutput: \n  html_document:\n    toc: true\n    toc_float: true\n---\n\n\n\n## Introduction\n\n## Data\n\n### Term 1\n\n### Term 2\n\n## Analysis\n\n## References\nSave this file and knit it. Ideally, this will generate some output in a new tab in the console pane called “Render” that starts with processing file: report-demo.Rmd and ends with Output created: report-demo.html. There will be a lot of output in between, but you don’t need to worry about it until something goes wrong."
  },
  {
    "objectID": "app-debugging.html#yaml-errors",
    "href": "app-debugging.html#yaml-errors",
    "title": "Appendix F — Debugging",
    "section": "\nF.2 YAML Errors",
    "text": "F.2 YAML Errors\nOne of the more frequent problems is errors in the YAML header. Let’s create a few to see how to deal with them.\n\nF.2.1 YAML borders\nDelete the last dash below the header and knit.\n---\ntitle: \"Report\"\ndate: \"2022-12-21\"\noutput: \n  html_document:\n    toc: true\n    toc_float: true\n--\nThis will actually knit without error (and look odd), but you’ll get a warning about the empty title. This is because R Markdown doesn’t recognise that there even is a YAML header if the three dashes to start and end it aren’t right.\n\nF.2.2 Spaces\nUnlike R and markdown, YAML is extremely picky about spaces. Try removing the space after the colon after “toc”.\n---\ntitle: \"Report\"\ndate: \"2022-12-21\"\noutput: \n  html_document:\n    toc:true\n    toc_float: true\n---\nYou should get an error that looks like this:\nError in yaml::yaml.load(..., eval.expr = TRUE) : \n  Scanner error: mapping values are not allowed in this context at line 6, column 14\nCalls: &lt;Anonymous&gt; ... parse_yaml_front_matter -&gt; yaml_load -&gt; &lt;Anonymous&gt;\nExecution halted\nIf you see Error in yaml and it gives you a line and column number, this refers to the YAML line, so start counting with 1 at the title line. Sometimes the actual problem is in the line above or below the reference. Here, the problem is a missing space in the toc line, but that doesn’t cause an error in the YAML parsing until it gets to the next line.\n\nF.2.3 Indenting\nYAML is also extremely picky about indenting. A common error is not putting html_document: on a separate line when adding options like a table of contents.\n---\ntitle: \"Report\"\ndate: \"2022-12-21\"\noutput: html_document:\n    toc: true\n    toc_float: true\n---\nYou should get an error that looks like this:\nError in yaml::yaml.load(..., eval.expr = TRUE) : \n  Scanner error: mapping values are not allowed in this context at line 3, column 22\nSome indenting problems don’t cause an error, but result in an output that isn’t doing what you expect. Try removing the indent for the table of contents lines and knitting.\n---\ntitle: \"Report\"\ndate: \"2022-12-21\"\noutput: \n  html_document:\n  toc: true\n  toc_float: true\n---"
  },
  {
    "objectID": "app-debugging.html#common-errors",
    "href": "app-debugging.html#common-errors",
    "title": "Appendix F — Debugging",
    "section": "\nF.3 Common Errors",
    "text": "F.3 Common Errors\nThe best way to learn to deal with errors is to make a lot of them. That way, the next time you encounter a similar error, you’ll have some experience solving it.\nRun the following code in the console; don’t add it to the report script.\n\n\n\nRun in the console\n\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8     ✔ forcats 0.5.2\n✔ stringr 1.4.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ faux::%||%()             masks purrr::%||%()\n✖ dplyr::filter()          masks stats::filter()\n✖ kableExtra::group_rows() masks dplyr::group_rows()\n✖ rvest::guess_encoding()  masks readr::guess_encoding()\n✖ dplyr::lag()             masks stats::lag()\n\n\nNow, make a code chunk somewhere in your report like this and run it interactively (not by knitting). It should create a new table called droids with 6 rows.\ndroids &lt;- starwars %&gt;% filter(species == \"Droid\")\nNow try to knit the report. Because you didn’t load the tidyverse package bundle in the script, you’ll get an error about not being able to find the function %&gt;% (you’ll learn about the pipe in Section 4.3.4). When you knit, any objects in your global environment or packages that you’ve loaded are unavailable and the script only has access to objects it creates and packages it loads.\nAdd library(tidyverse) to the setup chunk and knit to confirm this works.\n\nF.3.1 Could not find function\n\ntitle &lt;- pasteO(\"Lavendar\", \"Haze\")\n\nError in pasteO(\"Lavendar\", \"Haze\"): could not find function \"pasteO\"\n\n\nWhen you get the message could not find function \"func\", usually one of two things has happened: you haven’t loaded the package that the function is from or you’ve made a typo in the function name. In this example, the function is actually paste0() with a zero.\n\nF.3.2 Unused argument\n\nrnorm(N = 10)\n\nError in rnorm(N = 10): unused argument (N = 10)\n\n\nWhen you get the error “unused argument”, it usually means either that you’ve made a typo in an argument name, or the function doesn’t have that argument. Remember that argument, like functions and objects, are case-sensitive. Check the arguments with tab-autocomplete or checking the help for that function.\n\nF.3.3 Non-numeric argument to binary operator\n\n1 + \"A\"\n\nError in 1 + \"A\": non-numeric argument to binary operator\n\n\nWhen you try to apply mathematical operations to objects that aren’t numbers, you get this error. You might see this from a function that internally applies these operators; it just means that the person who wrote the function didn’t specifically check that the arguments you input were numeric and write a more specific error message, they just used what you provided and relied on the error messages from the binary operators. Either way, to solve this you need to figure out what should be numeric, but isn’t.\n\nF.3.4 Tibble columns must have compatible sizes\n\ntibble::tibble(\n  x = 1:2,\n  y = 1:3\n)\n\nError:\n! Tibble columns must have compatible sizes.\n• Size 2: Existing data.\n• Size 3: Column `y`.\nℹ Only values of size one are recycled.\n\n\nThis error occurs when you’re creating a table using tibble() and the columns have different lengths. You can set a column to a single value (i.e., a vector with length 1) and it will be “recycled” for every row, but you can’t give two columns values with different lengths if their lengths are greater than 1.\nThe same problem occurs if the function you’re using adds columns to a tibble. The tidyverse error messages are generall very useful in this case.\n\nmtcars3 &lt;- mutate(mtcars, newcol = 1:3)\n\nError in `mutate()`:\n! Problem while computing `newcol = 1:3`.\n✖ `newcol` must be size 32 or 1, not 3.\n\n\n\nF.3.5 Arguments imply differing number of rows\n\ndata.frame(\n  x = 1:2,\n  y = 1:3\n)\n\nError in data.frame(x = 1:2, y = 1:3): arguments imply differing number of rows: 2, 3\n\n\nA similar problem occurs if you’re using the base R function data.frame() (or the function you’re using does). The error message is different, but it’s the same problem. You will also see a related error message if you use base R techniques to add a column with a different length to the data frame.\n\nmtcars$newcol &lt;- 1:3\n\nError in `$&lt;-.data.frame`(`*tmp*`, newcol, value = 1:3): replacement has 3 rows, data has 32"
  },
  {
    "objectID": "app-debugging.html#debugging-methods",
    "href": "app-debugging.html#debugging-methods",
    "title": "Appendix F — Debugging",
    "section": "\nF.4 Debugging methods",
    "text": "F.4 Debugging methods\n\nF.4.1 Restart and rerun\nIt’s very useful to be able to run code interactively, but this can sometimes lead to confusion about what objects are available in your code. You might have made a data table called profits, and then decided to edit the code to make it slightly differently. If you forgot to re-run the code, you’ll be using the old table in your interactive code, but the new table when you knit.\nRestart R (under the Session menu) and run the code in order up to the chunk where you’re having a problem. You can use the Run menu in the upper right of the source pane to run all chunks above your cursor position.\n\nF.4.2 Comment out\nA useful method of debugging a tricky error is commenting out parts of your code and re-running the code to figure out exactly which code is causing the problem. Try\n\ndat &lt;- starwars %&gt;%\n  select(name, height, mass, species) %&gt;%\n  filter(Species == \"Droid\") %&gt;%\n  select(-species) %&gt;%\n  filter(mass &lt; 100)\n\nError in `filter()`:\n! Problem while computing `..1 = Species == \"Droid\"`.\nCaused by error in `mask$eval_all_filter()`:\n! object 'Species' not found\n\n\nImagine the error message was a bit less helpful. You can try running the code line by line. Either select just the code you want to run, or comment out the code you don’t want to run. Remember to also comment out linking functions at the end of lines, like the pipe (%&gt;%) or the ggplot plus (+).\n\ndat &lt;- starwars #%&gt;%\n  # select(name, height, mass, species) %&gt;%\n  # filter(Species == \"Droid\") %&gt;%\n  # select(-species) %&gt;%\n  # filter(mass &lt; 100)\n\n\n\n\n\n\n\nTip\n\n\n\nYou can comment out multiple lines by selecting them with your cursor and choosing Code &gt; Comment/Uncomment Lines (or using the keyboard shortcut).\n\n\nSelect more code or delete the comments until you locate the error.\n\ndat &lt;- starwars %&gt;%\n  select(name, height, mass, species) %&gt;%\n  filter(Species == \"Droid\") #%&gt;%\n\nError in `filter()`:\n! Problem while computing `..1 = Species == \"Droid\"`.\nCaused by error in `mask$eval_all_filter()`:\n! object 'Species' not found\n\n  # select(-species) %&gt;%\n  # filter(mass &lt; 100)\n\n\nF.4.3 Google the error\nMany error messages seem incomprehensible. Googling this message can often lead you to solutions. Take the famous example of “object of type ‘closure’ is not subsettable”.\n\ndata$x &lt;- 1\n\nError in data$x &lt;- 1: object of type 'closure' is not subsettable\n\n\nA Google search will show several sources explaining this confounding message and how to fix it. Although you may also find Jenny Bryan’s famous talk of the same name, which is an excellent discussion of troubleshooting in R.\n\n\n\n\n\n\nNote\n\n\n\nAn “object of type ‘closure’” is coding jargon for a function (like the type of 1 is numeric or the type of \"A\" is character). And “subsetting” is accessing part of a table using $ or square brackets. Here, it means that data isn’t a table, but actually a function, so you can’t add a column to it.\n\n\n\nF.4.4 Reproducible examples\nYou might see people in coding forums like StackOverflow asking for a “reprex”, or a reproducible example. This is the smallest, completely self-contained example of your problem or question.\nFor example, you may have a question about how to figure out how to select rows that contain the value “test” in a certain column, but it isn’t working. It’s clearer if you can provide a concrete example, but you don’t want to have to type out the whole table you’re using or all the code that got you to this point in your script.\nYou can include a very small table with just the basics or a smaller version of your problem. Make comments at each step about what you expect and what you actually got.\nWhich version is easier for you to figure out the solution?\n\n# this doesn't work\nno_test_data &lt;- data |&gt;\n  filter(!str_detect(type, \"test\"))\n\n… OR …\n\nlibrary(tidyverse)\n\n# with a minimal example table\ndata &lt;- tribble(\n  ~id, ~type, ~x,\n  1, \"test\", 12,\n  2, \"testosterone\", 15,\n  3, \"estrogen\", 10\n)\n\n# this should keep IDs 2 and 3, but removes ID 2\nno_test_data &lt;- data |&gt;\n  filter(!str_detect(type, \"test\"))\n\n# expected to be true\nall(no_test_data$type == c(\"testosterone\", \"estrogen\"))\n\nOne of the big benefits to creating a reprex is that you often solve your own problem while you’re trying to break it down to explain to someone else.\nIf you really want to go down the rabbit hole, you can create a reproducible example using the reprex package from tidyverse."
  },
  {
    "objectID": "app-import.html#sec-ilo-data",
    "href": "app-import.html#sec-ilo-data",
    "title": "Appendix G — Data Import",
    "section": "Intended Learning Outcomes",
    "text": "Intended Learning Outcomes\n\nBe able to inspect data\nBe able to import data from a range of sources\nBe able to identify and handle common problems with data import"
  },
  {
    "objectID": "app-import.html#sec-walkthrough-data",
    "href": "app-import.html#sec-walkthrough-data",
    "title": "Appendix G — Data Import",
    "section": "Walkthrough video",
    "text": "Walkthrough video\nThere is a walkthrough video of this chapter available via Echo360. Please note that there may have been minor edits to the book since the video was recorded. Where there are differences, the book should always take precedence."
  },
  {
    "objectID": "app-import.html#sec-setup-data",
    "href": "app-import.html#sec-setup-data",
    "title": "Appendix G — Data Import",
    "section": "\nG.1 Set-up",
    "text": "G.1 Set-up\nCreate a new project for the work we’ll do in this chapter named app-data-import. Then, create and save a new R Markdown document named data.Rmd, get rid of the default template text, and load the packages in the set-up code chunk. You should have all of these packages installed already, but if you get the message Error in library(x) : there is no package called ‘x’, please refer to Section 1.4.1.\n\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)     # includes readr & tibble\nlibrary(rio)           # for almost any data import/export\nlibrary(haven)         # for SPSS, Stata,and SAS files\nlibrary(readxl)        # for Excel files\nlibrary(googlesheets4) # for Google Sheets\n```\n\n\nWe’d recommend making a new code chunk for each different activity, and using the white space to make notes on any errors you make, things you find interesting, or questions you’d like to ask the course team.\nDownload the Data import cheatsheet."
  },
  {
    "objectID": "app-import.html#sec-builtin",
    "href": "app-import.html#sec-builtin",
    "title": "Appendix G — Data Import",
    "section": "\nG.2 Built-in data",
    "text": "G.2 Built-in data\nYou’ll likely want to import you own data to work with, however, Base R also comes with built-in datasets and these can be very useful for learning new functions and packages. Additionally, some packages, like tidyr, also contain data. The data() function lists the datasets available.\n\n# list datasets built in to base R\ndata()\n\n# lists datasets in a specific package\ndata(package = \"tidyr\")\n\nType the name of a dataset into the console to see the data. For example, type ?table1 into the console to see the dataset description for table1, which is a dataset included with tidyr.\n\n?table1\n\nYou can also use the data() function to load a dataset into your global environment.\n\n# loads table1 into the environment\ndata(\"table1\")"
  },
  {
    "objectID": "app-import.html#looking-at-data",
    "href": "app-import.html#looking-at-data",
    "title": "Appendix G — Data Import",
    "section": "\nG.3 Looking at data",
    "text": "G.3 Looking at data\nNow that you’ve loaded some data, look the upper right hand window of RStudio, under the Environment tab. You will see the object table1 listed, along with the number of observations (rows) and variables (columns). This is your first check that everything went OK.\nAlways, always, always, look at your data once you’ve created or loaded a table. Also look at it after each step that transforms your table. There are three main ways to look at your table: View(), print(), tibble::glimpse().\n\nG.3.1 View()\nA familiar way to look at the table is given by View() (uppercase ‘V’), which opens up a data table in the console pane using a viewer that looks a bit like Excel. This command can be useful in the console, but don’t ever put this one in a script because it will create an annoying pop-up window when the user runs it. You can also click on an object in the environment pane to open it in the same interface. You can close the tab when you’re done looking at it; it won’t remove the object.\n\nView(table1)\n\n\nG.3.2 print()\nThe print() method can be run explicitly, but is more commonly called by just typing the variable name on a blank line. The default is not to print the entire table, but just the first 10 rows.\nLet’s look at the table1 table that we loaded above. Depending on how wide your screen is, you might need to click on an arrow at the right of the table to see the last column.\n\n# call print explicitly\nprint(table1)\n\n# more common method of just calling object name\ntable1\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\nG.3.3 glimpse()\nThe function tibble::glimpse() gives a sideways version of the table. This is useful if the table is very wide and you can’t easily see all of the columns. It also tells you the data type of each column in angled brackets after each column name.\n\nglimpse(table1)\n\nRows: 6\nColumns: 4\n$ country    &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Brazil\", \"Brazil\", \"China\", …\n$ year       &lt;dbl&gt; 1999, 2000, 1999, 2000, 1999, 2000\n$ cases      &lt;dbl&gt; 745, 2666, 37737, 80488, 212258, 213766\n$ population &lt;dbl&gt; 19987071, 20595360, 172006362, 174504898, 1272915272, 12804…\n\n\n\nG.3.4 summary()\nYou can get a quick summary of a dataset with the summary() function, which can be useful for spotting things like if the minimum or maximum values are clearly wrong, or if R thinks that a &lt;a href=‘https://psyteachr.github.io/glossary/n#nominal’ target=’_blank’ class=‘glossary’ title=‘Categorical variables that don’t have an inherent order, such as types of animal.’&gt;nominal variable is numeric. For example, if you had labelled gender as 1, 2, and 3 rather than male, female, and non-binary, summary() would calculate a mean and median even though this isn’t appropriate for the data. This can be a useful flag that you need to take further steps to correct your data.\nNote that because population is a very, very large number, R will use scientific notation.\n\nsummary(table1)\n\n   country               year          cases          population       \n Length:6           Min.   :1999   Min.   :   745   Min.   :1.999e+07  \n Class :character   1st Qu.:1999   1st Qu.: 11434   1st Qu.:5.845e+07  \n Mode  :character   Median :2000   Median : 59112   Median :1.733e+08  \n                    Mean   :2000   Mean   : 91277   Mean   :4.901e+08  \n                    3rd Qu.:2000   3rd Qu.:179316   3rd Qu.:9.983e+08  \n                    Max.   :2000   Max.   :213766   Max.   :1.280e+09"
  },
  {
    "objectID": "app-import.html#sec-import_data",
    "href": "app-import.html#sec-import_data",
    "title": "Appendix G — Data Import",
    "section": "\nG.4 Importing data",
    "text": "G.4 Importing data\nBuilt-in data are nice for examples, but you’re probably more interested in your own data. There are many different types of files that you might work with when doing data analysis. These different file types are usually distinguished by the three-letter extension following a period at the end of the file name (e.g., .xls).\nDownload this directory of data files, unzip the folder, and save the data directory in the 04-data project directory.\n\nG.4.1 rio::import()\nThe type of data files you have to work with will likely depend on the software that you typically use in your workflow. The rio package has very straightforward functions for reading and saving data in most common formats: rio::import() and rio::export().\n\ndemo_tsv  &lt;- import(\"data/demo.tsv\")  # tab-separated values\ndemo_csv  &lt;- import(\"data/demo.csv\")  # comma-separated values\ndemo_xls  &lt;- import(\"data/demo.xlsx\") # Excel format\ndemo_sav  &lt;- import(\"data/demo.sav\")  # SPSS format\n\n\nG.4.2 File type specific import\nHowever, it is also useful to know the specific functions that are used to import different file types because it is easier to discover features to deal with complicated cases, such as when you need to skip rows, rename columns, or choose which Excel sheet to use.\n\ndemo_tsv &lt;- readr::read_tsv(\"data/demo.tsv\")\ndemo_csv &lt;- readr::read_csv(\"data/demo.csv\")\ndemo_xls &lt;- readxl::read_excel(\"data/demo.xlsx\")\ndemo_sav &lt;- haven::read_sav(\"data/demo.sav\")\n\n\n\n\n\n\n\nNote\n\n\n\nLook at the help for each function above and read through the Arguments section to see how you can customise import.\n\n\nIf you keep data in Google Sheets, you can access it directly from R using &lt;pkg&gt;googlesheets4\", \"https://googlesheets4.tidyverse.org/\"). The code below imports data from a public sheet. You can set the ss argument to the entire URL for the target sheet, or just the section after “https://docs.google.com/spreadsheets/d/”.\n\ngs4_deauth() # skip authorisation for public data\n\ndemo_gs4  &lt;- googlesheets4::read_sheet(\n  ss = \"16dkq0YL0J7fyAwT1pdgj1bNNrheckAU_2-DKuuM6aGI\"\n)\n\n\nG.4.3 Column data types\nUse glimpse() to see how these different functions imported the data with slightly different data types. This is because the different file types store data slightly differently. For example, SPSS stores factors as numbers, so the factor column contains the values 1, 2, 3 rather than low, med, high. It also stores logical values as 0 and 1 instead or TRUE and FALSE.\n\nglimpse(demo_csv)\n\nRows: 6\nColumns: 6\n$ character &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    &lt;chr&gt; \"high\", \"low\", \"med\", \"high\", \"low\", \"med\"\n$ integer   &lt;dbl&gt; 1, 2, 3, 4, 5, 6\n$ double    &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, NA, TRUE\n$ date      &lt;date&gt; 2024-03-20, 2024-03-19, 2024-03-18, 2024-03-17, 2024-03-16, …\n\n\n\nglimpse(demo_xls)\n\nRows: 6\nColumns: 6\n$ character &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    &lt;chr&gt; \"high\", \"low\", \"med\", \"high\", \"low\", \"med\"\n$ integer   &lt;dbl&gt; 1, 2, 3, 4, 5, 6\n$ double    &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, NA, TRUE\n$ date      &lt;dttm&gt; 2024-03-20, 2024-03-19, 2024-03-18, 2024-03-17, 2024-03-16, …\n\n\n\nglimpse(demo_sav)\n\nRows: 6\nColumns: 6\n$ character &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    &lt;dbl+lbl&gt; 3, 1, 2, 3, 1, 2\n$ integer   &lt;dbl&gt; 1, 2, 3, 4, 5, 6\n$ double    &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   &lt;dbl&gt; 1, 1, 0, 0, NA, 1\n$ date      &lt;date&gt; 2024-03-20, 2024-03-19, 2024-03-18, 2024-03-17, 2024-03-16, …\n\n\n\nglimpse(demo_gs4)\n\nRows: 6\nColumns: 6\n$ character &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    &lt;chr&gt; \"high\", \"low\", \"med\", \"high\", \"low\", \"med\"\n$ integer   &lt;dbl&gt; 1, 2, 3, 4, 5, 6\n$ double    &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, NA, TRUE\n$ date      &lt;dttm&gt; 2021-11-22, 2021-11-21, 2021-11-20, 2021-11-19, 2021-11-18, …\n\n\nThe readr functions display a message when you import data explaining what data type each column is.\n\ndemo &lt;- readr::read_csv(\"data/demo.csv\")\n\nRows: 6 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): character, factor\ndbl  (2): integer, double\nlgl  (1): logical\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe “Column specification” tells you which data type each column is. You can review data types in Appendix H. Options are:\n\n\nchr: character\n\n\ndbl: double\n\n\nlgl: logical\n\n\nint: integer\n\n\ndate: date\n\ndttm: date/time\n\nread_csv() will guess what type of data each variable is and normally it is pretty good at this. However, if it makes a mistake, such as reading the “date” column as a character, you can manually set the column data types.\nFirst, run spec() on the dataset which will give you the full column specification that you can copy and paste:\n\nspec(demo)\n\ncols(\n  character = col_character(),\n  factor = col_character(),\n  integer = col_double(),\n  double = col_double(),\n  logical = col_logical(),\n  date = col_date(format = \"\")\n)\n\n\nThen, we create an object using the code we just copied that lists the correct column types. Factor columns will always import as character data types, so you have to set their data type manually with col_factor() and set the order of levels with the levels argument. Otherwise, the order defaults to the order they appear in the dataset. For our demo dataset, we will tell R that the factor variable is a factor by using col_factor() and we can also specify the order of the levels so that they don’t just appear alphabetically. Additionally, we can also specify exactly what format our date variable is in using %Y-%m-%d.\nWe then save this column specification to an object, and then add this to the col_types argument when we call read_csv().\n\ncorrected_cols &lt;- cols(\n  character = col_character(),\n  factor = col_factor(levels = c(\"low\", \"med\", \"high\")),\n  integer = col_integer(),\n  double = col_double(),\n  logical = col_logical(),\n  date = col_date(format = \"%Y-%m-%d\")\n)\n\ndemo &lt;- readr::read_csv(\"data/demo.csv\", col_types = corrected_cols)\n\n\n\n\n\n\n\nNote\n\n\n\nFor dates, you might need to set the format your dates are in. See ?strptime for a list of the codes used to represent different date formats. For example, \"%d-%b-%y\" means that the dates are formatted like 31-Jan-21.\n\n\nThe functions from readxl for loading .xlsx sheets have a different, more limited way to specify the column types. You will have to convert factor columns and dates using mutate(), which you’ll learn about in ?sec-wrangle, so most people let read_excel() guess data types and don’t set the col_types argument.\nFor SPSS data, whilst rio::import() will just read the numeric values of factors and not their labels, the function read_sav() from haven reads both. However, you have to convert factors from a haven-specific “labelled double” to a factor (we have no idea why haven doesn’t do this for you).\n\ndemo_sav$factor &lt;- haven::as_factor(demo_sav$factor)\n\nglimpse(demo_sav)\n\nRows: 6\nColumns: 6\n$ character &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    &lt;fct&gt; high, low, med, high, low, med\n$ integer   &lt;dbl&gt; 1, 2, 3, 4, 5, 6\n$ double    &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   &lt;dbl&gt; 1, 1, 0, 0, NA, 1\n$ date      &lt;date&gt; 2024-03-20, 2024-03-19, 2024-03-18, 2024-03-17, 2024-03-16, …\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe way you specify column types for googlesheets4 is a little different from readr, although you can also use the shortcodes described in the help for read_sheet() with readr functions. There is currently no column specification for factors."
  },
  {
    "objectID": "app-import.html#creating-data",
    "href": "app-import.html#creating-data",
    "title": "Appendix G — Data Import",
    "section": "\nG.5 Creating data",
    "text": "G.5 Creating data\nIf you need to create a small data table from scratch in R, use the tibble::tibble() function, and type the data right in. The tibble package is part of the tidyverse package that we loaded at the start of this chapter.\nLet’s create a small table with the names of three Avatar characters and their bending type. The tibble() function takes arguments with the names that you want your columns to have. The values are vectors that list the column values in order.\nIf you don’t know the value for one of the cells, you can enter NA, which we have to do for Sokka because he doesn’t have any bending ability. If all the values in the column are the same, you can just enter one value and it will be copied for each row.\n\navatar &lt;- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\"),\n  bends = c(\"water\", \"earth\", NA),\n  friendly = TRUE\n)\n\n# print it\navatar\n\n\n\n\nname\nbends\nfriendly\n\n\n\nKatara\nwater\nTRUE\n\n\nToph\nearth\nTRUE\n\n\nSokka\nNA\nTRUE\n\n\n\n\n\n\nYou can also use the tibble::tribble() function to create a table by row, rather than by column. You start by listing the column names, each preceded by a tilde (~), then you list the values for each column, row by row, separated by commas (don’t forget a comma at the end of each row).\n\navatar_by_row &lt;- tribble(\n  ~name,    ~bends,  ~friendly,\n  \"Katara\", \"water\", TRUE,\n  \"Toph\",   \"earth\", TRUE,\n  \"Sokka\",  NA,      TRUE\n)\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t have to line up the columns in a tribble, but it can make it easier to spot errors.\n\n\nYou may not need to do this very often if you are primarily working with data that you import from spreadsheets, but it is useful to know how to do it anyway."
  },
  {
    "objectID": "app-import.html#writing-data",
    "href": "app-import.html#writing-data",
    "title": "Appendix G — Data Import",
    "section": "\nG.6 Writing data",
    "text": "G.6 Writing data\nIf you have data that you want to save, use rio::export(), as follows.\n\nexport(avatar, \"data/avatar.csv\")\n\nThis will save the data in CSV format to your working directory.\nWriting to Google Sheets is a little trickier (if you never use Google Sheets feel free to skip this section). Even if a Google Sheet is publicly editable, you can’t add data to it without authorising your account.\nYou can authorise interactively using the following code (and your own email), which will prompt you to authorise “Tidyverse API Packages” the first time you do this. If you don’t tick the checkbox authorising it to “See, edit, create, and delete all your Google Sheets spreadsheets”, the next steps will fail.\n\n# authorise your account \n# this only needs to be done once per script\ngs4_auth(email = \"myemail@gmail.com\")\n\n# create a new sheet\nsheet_id &lt;- gs4_create(name = \"demo-file\", \n                       sheets = \"letters\")\n\n# define the data table to save\nletter_data &lt;- tibble(\n  character = LETTERS[1:5],\n  integer = 1:5,\n  double = c(1.1, 2.2, 3.3, 4.4, 5.5),\n  logical = c(T, F, T, F, T),\n  date = lubridate::today()\n)\n\nwrite_sheet(data = letter_data, \n            ss = sheet_id, \n            sheet = \"letters\")\n\n## append some data\nnew_data &lt;- tibble(\n  character = \"F\",\n  integer = 6L,\n  double = 6.6,\n  logical = FALSE,\n  date = lubridate::today()\n)\nsheet_append(data = new_data,\n             ss = sheet_id,\n             sheet = \"letters\")\n\n# read the data\ndemo &lt;- read_sheet(ss = sheet_id, sheet = \"letters\")\n\n\n\n\n\n\n\nNote\n\n\n\n\nCreate a new table called family with the first name, last name, and age of your family members (biological, adopted, or chosen).\nSave it to a CSV file called “family.csv”.\nClear the object from your environment by restarting R or with the code remove(family).\nLoad the data back in and view it.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# create the table\nfamily &lt;- tribble(\n  ~first_name, ~last_name, ~age,\n  \"Lisa\", \"DeBruine\", 45,\n  \"Robbie\", \"Jones\", 14\n)\n\n# save the data to CSV\nexport(family, \"data/family.csv\")\n\n# remove the object from the environment\nremove(family)\n\n# load the data\nfamily &lt;- import(\"data/family.csv\")\n\n\n\n\n\n\nWe’ll be working with tabular data a lot in this class, but tabular data is made up of vectors, which groups together data with the same basic data type. Appendix H explains some of this terminology to help you understand the functions we’ll be learning to process and analyse data."
  },
  {
    "objectID": "app-import.html#troubleshooting",
    "href": "app-import.html#troubleshooting",
    "title": "Appendix G — Data Import",
    "section": "\nG.7 Troubleshooting",
    "text": "G.7 Troubleshooting\nWhat if you import some data and it guesses the wrong column type? The most common reason is that a numeric column has some non-numbers in it somewhere. Maybe someone wrote a note in an otherwise numeric column. Columns have to be all one data type, so if there are any characters, the whole column is converted to character strings, and numbers like 1.2 get represented as \"1.2\", which will cause very weird errors like \"100\" &lt; \"9\" == TRUE. You can catch this by using glimpse() to check your data.\nThe data directory you downloaded contains a file called “mess.csv”. Let’s try loading this dataset.\n\nmess &lt;- rio::import(\"data/mess.csv\")\n\nWarning in (function (input = \"\", file = NULL, text = NULL, cmd = NULL, :\nStopped early on line 5. Expected 7 fields but found 0. Consider fill=TRUE and\ncomment.char=. First discarded non-empty line: &lt;&lt;junk,missing,0.72,b,1,2 -\n3,2020-01-2&gt;&gt;\n\n\nWhen importing goes wrong, it’s often easier to fix it using the specific importing function for that file type (e.g., use read_csv() rather than rio::import(). This is because the problems tend to be specific to the file format and you can look up the help for these functions more easily. For CSV files, the import function is readr::read_csv.\n\n# lazy = FALSE loads the data right away so you can see error messages\n# this default changed in late 2021 and might change back soon\nmess &lt;- read_csv(\"data/mess.csv\", lazy = FALSE)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 27 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): This is my messy dataset\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou’ll get a warning about parsing issues and the data table is just a single column. View the file data/mess.csv by clicking on it in the File pane, and choosing “View File”. Here are the first 10 lines. What went wrong?\n\n\n\nThis is my messy dataset\n\n\n\njunk,order,score,letter,good,min_max,date\n\n\njunk,1,-1,a,1,1 - 2,2020-01-1\n\n\njunk,missing,0.72,b,1,2 - 3,2020-01-2\n\n\njunk,3,-0.62,c,FALSE,3 - 4,2020-01-3\n\n\njunk,4,2.03,d,T,4 - 5,2020-01-4\n\n\njunk,5,NA,e,1,5 - 6,2020-01-5\n\n\n\n\nFirst, the file starts with a note: “This is my messy dataset” and then a blank line. The first line of data should be the column headings, so we want to skip the first two lines. You can do this with the argument skip in read_csv().\n\nmess &lt;- read_csv(\"data/mess.csv\", \n                 skip = 2,\n                 lazy = FALSE)\n\nRows: 26 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): junk, order, letter, good, min_max, date\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(mess)\n\nRows: 26\nColumns: 7\n$ junk    &lt;chr&gt; \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\"…\n$ order   &lt;chr&gt; \"1\", \"missing\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\",…\n$ score   &lt;dbl&gt; -1.00, 0.72, -0.62, 2.03, NA, 0.99, 0.03, 0.67, 0.57, 0.90, -1…\n$ letter  &lt;chr&gt; \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m…\n$ good    &lt;chr&gt; \"1\", \"1\", \"FALSE\", \"T\", \"1\", \"0\", \"T\", \"TRUE\", \"1\", \"T\", \"F\", …\n$ min_max &lt;chr&gt; \"1 - 2\", \"2 - 3\", \"3 - 4\", \"4 - 5\", \"5 - 6\", \"6 - 7\", \"7 - 8\",…\n$ date    &lt;chr&gt; \"2020-01-1\", \"2020-01-2\", \"2020-01-3\", \"2020-01-4\", \"2020-01-5…\n\n\nOK, that’s a little better, but this table is still a serious mess in several ways:\n\n\njunk is a column that we don’t need\n\norder should be an integer column\n\ngood should be a logical column\n\ngood uses all kinds of different ways to record TRUE and FALSE values\n\nmin_max contains two pieces of numeric information, but is a character column\n\ndate should be a date column\n\nWe’ll learn how to deal with this mess in ?sec-tidy and ?sec-wrangle, but we can fix a few things by setting the col_types argument in read_csv() to specify the column types for our two columns that were guessed wrong and skip the “junk” column. The argument col_types takes a list where the name of each item in the list is a column name and the value is from the table below. You can use the function, like col_double() or the abbreviation, like \"d\"; for consistency with earlier in this chapter we will use the function names. Omitted column names are guessed.\n\n\nfunction\n\nabbreviation\n\n\n\ncol_logical()\nl\nlogical values\n\n\ncol_integer()\ni\ninteger values\n\n\ncol_double()\nd\nnumeric values\n\n\ncol_character()\nc\nstrings\n\n\ncol_factor(levels, ordered)\nf\na fixed set of values\n\n\ncol_date(format = ““)\nD\nwith the locale’s date_format\n\n\ncol_time(format = ““)\nt\nwith the locale’s time_format\n\n\ncol_datetime(format = ““)\nT\nISO8601 date time\n\n\ncol_number()\nn\nnumbers containing the grouping_mark\n\n\ncol_skip()\n_, -\ndon’t import this column\n\n\ncol_guess()\n?\nparse using the “best” type based on the input\n\n\n\n\n# omitted values are guessed\n# ?col_date for format options\nct &lt;- cols(\n  junk = col_skip(), # skip this column\n  order = col_integer(),\n  good = col_logical(),\n  date = col_date(format = \"%Y-%m-%d\")\n)\n\ntidier &lt;- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   col_types = ct,\n                   lazy = FALSE)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nYou will get a message about parsing issues when you run this that tells you to run the problems() function to see a table of the problems. Warnings look scary at first, but always start by reading the message.\n\nproblems()\n\n\n\n\n\n\nrow\ncol\nexpected\nactual\nfile\n\n\n3\n2\nan integer\nmissing\ndata/mess.csv\n\n\n\n\n\nThe output of problems() tells you what row (3) and column (2) the error was found in, what kind of data was expected (an integer), and what the actual value was (missing). If you specifically tell read_csv() to import a column as an integer, any characters (i.e., not numbers) in the column will produce a warning like this and then be recorded as NA. You can manually set what missing values are recorded as with the na argument.\n\ntidiest &lt;- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   na = \"missing\",\n                   col_types = ct,\n                   lazy = FALSE)\n\nNow order is an integer variable where any empty cells contain NA. The variable good is a logical value, where 0 and F are converted to FALSE, while 1 and T are converted to TRUE. The variable date is a date type (adding leading zeros to the day). We’ll learn in later chapters how to fix other problems, such as the min_max column containing two different types of data.\n\n\n\n\n\norder\nscore\nletter\ngood\nmin_max\ndate\n\n\n\n1\n-1\na\nTRUE\n1 - 2\n2020-01-01\n\n\nNA\n0.72\nb\nTRUE\n2 - 3\n2020-01-02\n\n\n3\n-0.62\nc\nFALSE\n3 - 4\n2020-01-03\n\n\n4\n2.03\nd\nTRUE\n4 - 5\n2020-01-04\n\n\n5\nNA\ne\nTRUE\n5 - 6\n2020-01-05\n\n\n6\n0.99\nf\nFALSE\n6 - 7\n2020-01-06"
  },
  {
    "objectID": "app-import.html#working-with-real-data",
    "href": "app-import.html#working-with-real-data",
    "title": "Appendix G — Data Import",
    "section": "\nG.8 Working with real data",
    "text": "G.8 Working with real data\nIt’s worth highlighting at this point that working with real data can be difficult because each dataset can be messy in its own way. Throughout this course we will show you common errors and how to fix them, but be prepared that when you start with working your own data, you’ll likely come across problems we don’t cover in the course and that’s just part of joy of learning programming. You’ll also get better at looking up solutions using sites like Stack Overflow and there’s a fantastic #rstats community on Twitter you can ask for help.\nYou may also be tempted to fix messy datasets by, for example, opening up Excel and editing them there. Whilst this might seem easier in the short term, there’s two serious issues with doing this. First, you will likely work with datasets that have recurring messy problems. By taking the time to solve these problems with code, you can apply the same solutions to a large number of future datasets so it’s more efficient in the long run. Second, if you edit the spreadsheet, there’s no record of what you did. By solving these problems with code, you do so reproducibly and you don’t edit the original data file. This means that if you make an error, you haven’t lost the original data and can recover."
  },
  {
    "objectID": "app-import.html#exercises",
    "href": "app-import.html#exercises",
    "title": "Appendix G — Data Import",
    "section": "\nG.9 Exercises",
    "text": "G.9 Exercises\nFor the final step in this chapter, we will create a report using one of the in-built datasets to practice the skills you have used so far. You may need to refer back to previous chapters to help you complete these exercises and you may also want to take a break before you work through this section. We’d also recommend you knit at every step so that you can see how your output changes.\n\nG.9.1 New Markdown\nCreate and save a new R Markdown document named starwars_report.Rmd. In the set-up code chunk load the packages tidyverse and rio.\nWe’re going to use the built-in starwars dataset that contains data about Star Wars characters. You can learn more about the dataset by using the ?help function.\n\nG.9.2 Import and export the dataset\n\nFirst, load the in-built dataset into the environment. Type and run the code to do this in the console; do not save it in your Markdown.\n\nThen, export the dataset to a .csv file and save it in your data directory. Again, do this in the console.\nFinally, import this version of the dataset using read_csv() to an object named starwars - you can put this code in your Markdown.\n\n\n\nSolution\n\n\ndata(starwars)\nexport(starwars, \"data/starwars.csv\")\nstarwars &lt;- read_csv(\"data/starwars.csv\")\n\nRows: 87 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): name, hair_color, skin_color, eye_color, sex, gender, homeworld, s...\ndbl  (3): height, mass, birth_year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nG.9.3 Convert column types\n\nCheck the column specification of starwars.\nCreate a new column specification that lists the following columns as factors: hair_color, skin_color, eye_color, sex, gender, homeworld, and species and skips the following columns: films, vehicles, and starships (this is because these columns contain multiple values and are stored as lists, which we haven’t covered how to work with). You do not have to set the factor orders (although you can if you wish).\nRe-import the dataset, this time with the corrected column types.\n\n\n\nSolution\n\n\nspec(starwars)\ncorrected_cols &lt;- cols(\n  name = col_character(),\n  height = col_double(),\n  mass = col_double(),\n  hair_color = col_factor(),\n  skin_color = col_factor(),\n  eye_color = col_factor(),\n  birth_year = col_double(),\n  sex = col_factor(),\n  gender = col_factor(),\n  homeworld = col_factor(),\n  species = col_factor(),\n  films = col_skip(),\n  vehicles = col_skip(),\n  starships = col_skip()\n)\n\nstarwars &lt;- read_csv(\"data/starwars.csv\", col_types = corrected_cols)\n\ncols(\n  name = col_character(),\n  height = col_double(),\n  mass = col_double(),\n  hair_color = col_character(),\n  skin_color = col_character(),\n  eye_color = col_character(),\n  birth_year = col_double(),\n  sex = col_character(),\n  gender = col_character(),\n  homeworld = col_character(),\n  species = col_character(),\n  films = col_character(),\n  vehicles = col_character(),\n  starships = col_character()\n)\n\n\n\n\nG.9.4 Plots\nProduce the following plots and one plot of your own choosing. Write a brief summary of what each plot shows and any conclusions you might reach from the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\nggplot(starwars, aes(height)) +\n  geom_histogram(binwidth = 25, colour = \"black\", alpha = .3) +\n  scale_x_continuous(breaks = seq(from = 50, to = 300, by = 25)) +\n  labs(title = \"Height (cm) distribution of Star Wars Characters\") +\n  theme_classic()\n\n\nggplot(starwars, aes(height, mass)) +\n  geom_point() +\n  labs(title = \"Mass (kg) by height (cm) distribution of Star Wars Characters\") +\n  theme_classic() +\n  scale_x_continuous(breaks = seq(from = 0, to = 300, by = 50)) +\n  scale_y_continuous(breaks = seq(from = 0, to = 2000, by = 100)) +\n  coord_cartesian(xlim = c(0, 300))\n\n\nggplot(starwars, aes(x = gender, fill = gender)) +\n  geom_bar(show.legend = FALSE, colour = \"black\") +\n  scale_x_discrete(name = \"Gender of character\", labels = (c(\"Masculine\", \"Feminine\", \"Missing\"))) +\n  scale_fill_brewer(palette = 2) +\n  labs(title = \"Number of Star Wars characters of each gender\") +\n  theme_bw()\n\n\n\nG.9.5 Make it look nice\n\nAdd at least one Star Wars related image from an online source\nHide the code and any messages from the knitted output\nResize any images as you see fit\n\n\n\nSolution\n\n\n\n```{r, echo = FALSE, out.width = \"50%\", fig.cap=\"Adaptation of Star Wars logo created by Weweje; original logo by Suzy Rice, 1976. CC-BY-3.0\"}\nknitr::include_graphics(\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/Star_wars2.svg/2880px-Star_wars2.svg.png\")\n```\n\n\n\n\n\n\nAdaptation of Star Wars logo created by Weweje; original logo by Suzy Rice, 1976. CC-BY-3.0"
  },
  {
    "objectID": "app-import.html#sec-glossary-data",
    "href": "app-import.html#sec-glossary-data",
    "title": "Appendix G — Data Import",
    "section": "\nG.10 Glossary",
    "text": "G.10 Glossary\n\n\n\n\nterm\ndefinition\n\n\n\nargument\nA variable that provides input to a function.\n\n\ncharacter\nA data type representing strings of text.\n\n\nconsole\nThe pane in RStudio where you can type in commands and view output messages.\n\n\ndata-type\nThe kind of data represented by an object.\n\n\ndouble\nA data type representing a real decimal number\n\n\nextension\nThe end part of a file name that tells you what type of file it is (e.g., .R or .Rmd).\n\n\nglobal-environment\nThe interactive workspace where your script runs\n\n\ninteger\nA data type representing whole numbers.\n\n\nlogical\nA data type representing TRUE or FALSE values.\n\n\nna\nA missing value that is \"Not Available\"\n\n\nnominal\nCategorical variables that don't have an inherent order, such as types of animal.\n\n\nnumeric\nA data type representing a real decimal number or integer.\n\n\npanes\nRStudio is arranged with four window \"panes\".\n\n\ntabular-data\nData in a rectangular table format, where each row has an entry for each column.\n\n\ntidyverse\nA set of R packages that help you create and work with tidy data\n\n\nurl\nThe address of a web page (uniform resource locator)\n\n\nvector\nA type of data structure that collects values with the same data type, like T/F values, numbers, or strings."
  },
  {
    "objectID": "app-import.html#sec-resources-data",
    "href": "app-import.html#sec-resources-data",
    "title": "Appendix G — Data Import",
    "section": "\nG.11 Further resources",
    "text": "G.11 Further resources\n\nData import cheatsheet\n\nChapter 11: Data Import in R for Data Science\n\nMulti-row headers"
  },
  {
    "objectID": "app-datatypes.html#basic-data-types",
    "href": "app-datatypes.html#basic-data-types",
    "title": "Appendix H — Data Types",
    "section": "\nH.1 Basic data types",
    "text": "H.1 Basic data types\nData can be numbers, words, true/false values or combinations of these. The basic data types in R are: numeric, character, and logical, as well as the special classes of factor and date/times.\n\n\n\n\nData types are like the categories when you format cells in Excel.\n\n\n\n\nH.1.1 Numeric data\nAll of the numbers are numeric data types. There are two types of numeric data, integer and double. Integers are the whole numbers, like -1, 0 and 1. Doubles are numbers that can have fractional amounts. If you just type a plain number such as 10, it is stored as a double, even if it doesn’t have a decimal point. If you want it to be an exact integer, you can use the L suffix (10L), but this distinction doesn’t make much difference in practice.\nIf you ever want to know the data type of something, use the typeof function.\n\ntypeof(10)   # double\ntypeof(10.0) # double\ntypeof(10L)  # integer\n\n[1] \"double\"\n[1] \"double\"\n[1] \"integer\"\n\n\nIf you want to know if something is numeric (a double or an integer), you can use the function is.numeric() and it will tell you if it is numeric (TRUE) or not (FALSE).\n\nis.numeric(10L)\nis.numeric(10.0)\nis.numeric(\"Not a number\")\n\n[1] TRUE\n[1] TRUE\n[1] FALSE\n\n\n\nH.1.2 Character data\nCharacters (also called “strings”) are any text between quotation marks.\n\ntypeof(\"This is a character string\")\ntypeof('You can use double or single quotes')\n\n[1] \"character\"\n[1] \"character\"\n\n\nThis can include quotes, but you have to escape quotes using a backslash to signal that the quote isn’t meant to be the end of the string.\n\nmy_string &lt;- \"The instructor said, \\\"R is cool,\\\" and the class agreed.\"\ncat(my_string) # cat() prints the arguments\n\nThe instructor said, \"R is cool,\" and the class agreed.\n\n\n\nH.1.3 Logical Data\nLogical data (also sometimes called “boolean” values) is one of two values: true or false. In R, we always write them in uppercase: TRUE and FALSE.\n\nclass(TRUE)\nclass(FALSE)\n\n[1] \"logical\"\n[1] \"logical\"\n\n\nWhen you compare two values with an operator, such as checking to see if 10 is greater than 5, the resulting value is logical.\n\nis.logical(10 &gt; 5)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou might also see logical values abbreviated as T and F, or 0 and 1. This can cause some problems down the road, so we will always spell out the whole thing.\n\n\n\nH.1.4 Factors\nA factor is a specific type of integer that lets you specify the categories and their order. This is useful in data tables to make plots display with categories in the correct order.\n\nmyfactor &lt;- factor(\"B\", levels = c(\"A\", \"B\",\"C\"))\nmyfactor\n\n[1] B\nLevels: A B C\n\n\nFactors are a type of integer, but you can tell that they are factors by checking their class().\n\ntypeof(myfactor)\nclass(myfactor)\n\n[1] \"integer\"\n[1] \"factor\"\n\n\n\nH.1.5 Dates and Times\nDates and times are represented by doubles with special classes. Although typeof() will tell you they are a double, you can tell that they are dates by checking their class(). Datetimes can have one or more of a few classes that start with POSIX.\n\ndate &lt;- as.Date(\"2022-01-24\")\ndatetime &lt;- ISOdatetime(2022, 1, 24, 10, 35, 00, \"GMT\")\ntypeof(date)\ntypeof(datetime)\nclass(date)\nclass(datetime)\n\n[1] \"double\"\n[1] \"double\"\n[1] \"Date\"\n[1] \"POSIXct\" \"POSIXt\" \n\n\nSee Appendix I for how to use lubridate to work with dates and times.\n\n\n\n\n\n\nNote\n\n\n\nWhat data types are these:\n\n\n100 \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\n100L \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\n\"100\" \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\n100.0 \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\n-100L \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\nfactor(100) \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\nTRUE \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\n\"TRUE\" \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\nFALSE \ninteger\ndouble\ncharacter\nlogical\nfactor\n\n\n1 == 2 \ninteger\ndouble\ncharacter\nlogical\nfactor"
  },
  {
    "objectID": "app-datatypes.html#sec-containers",
    "href": "app-datatypes.html#sec-containers",
    "title": "Appendix H — Data Types",
    "section": "\nH.2 Basic container types",
    "text": "H.2 Basic container types\nIndividual data values can be grouped together into containers. The main types of containers we’ll work with are vectors, lists, and data tables.\n\nH.2.1 Vectors\nA vector in R is a set of items (or ‘elements’) in a specific order. All of the elements in a vector must be of the same data type (numeric, character, logical). You can create a vector by enclosing the elements in the function c().\n\n## put information into a vector using c(...)\nc(1, 2, 3, 4)\nc(\"this\", \"is\", \"cool\")\n1:6 # shortcut to make a vector of all integers x:y\n\n[1] 1 2 3 4\n[1] \"this\" \"is\"   \"cool\"\n[1] 1 2 3 4 5 6\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat happens when you mix types? What class is the variable mixed?\n\nmixed &lt;- c(2, \"good\", 2L, \"b\", TRUE)\n\n\n\n\nSolution\n\ntypeof(mixed)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nYou can’t mix data types in a vector; all elements of the vector must be the same data type. If you mix them, R will coerce them so that they are all the same. If you mix doubles and integers, the integers will be changed to doubles. If you mix characters and numeric types, the numbers will be coerced to characters, so 10 would turn into \"10\".\n\n\n\nH.2.1.1 Selecting values from a vector\nIf we wanted to pick specific values out of a vector by position, we can use square brackets (an extract operator, or []) after the vector.\n\nvalues &lt;- c(10, 20, 30, 40, 50)\nvalues[2] # selects the second value\n\n[1] 20\n\n\nYou can select more than one value from the vector by putting a vector of numbers inside the square brackets. For example, you can select the 18th, 19th, 20th, 21st, 4th, 9th and 15th letter from the built-in vector LETTERS (which gives all the uppercase letters in the Latin alphabet).\n\nword &lt;- c(18, 19, 20, 21, 4, 9, 15)\nLETTERS[word]\n\n[1] \"R\" \"S\" \"T\" \"U\" \"D\" \"I\" \"O\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nCan you decode the secret message?\n\nsecret &lt;- c(14, 5, 22, 5, 18, 7, 15, 14, 14, 1, 7, 9, 22, 5, 25, 15, 21, 21, 16)\n\n\n\n\nSolution\n\nLETTERS[secret]\n\n [1] \"N\" \"E\" \"V\" \"E\" \"R\" \"G\" \"O\" \"N\" \"N\" \"A\" \"G\" \"I\" \"V\" \"E\" \"Y\" \"O\" \"U\" \"U\" \"P\"\n\n\n\n\n\nYou can also create ‘named’ vectors, where each element has a name. For example:\n\nvec &lt;- c(first = 77.9, second = -13.2, third = 100.1)\nvec\n\n first second  third \n  77.9  -13.2  100.1 \n\n\nWe can then access elements by name using a character vector within the square brackets. We can put them in any order we want, and we can repeat elements:\n\nvec[c(\"third\", \"second\", \"second\")]\n\n third second second \n 100.1  -13.2  -13.2 \n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can get the vector of names using the names() function, and we can set or change them using something like names(vec2) &lt;- c(\"n1\", \"n2\", \"n3\").\n\n\nAnother way to access elements is by using a logical vector within the square brackets. This will pull out the elements of the vector for which the corresponding element of the logical vector is TRUE. If the logical vector doesn’t have the same length as the original, it will repeat. You can find out how long a vector is using the length() function.\n\nlength(LETTERS)\nLETTERS[c(TRUE, FALSE)]\n\n[1] 26\n [1] \"A\" \"C\" \"E\" \"G\" \"I\" \"K\" \"M\" \"O\" \"Q\" \"S\" \"U\" \"W\" \"Y\"\n\n\n\nH.2.1.2 Repeating Sequences\nHere are some useful tricks to save typing when creating vectors.\nIn the command x:y the : operator would give you the sequence of number starting at x, and going to y in increments of 1.\n\n1:10\n15.3:20.5\n0:-10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n[1] 15.3 16.3 17.3 18.3 19.3 20.3\n [1]   0  -1  -2  -3  -4  -5  -6  -7  -8  -9 -10\n\n\nWhat if you want to create a sequence but with something other than integer steps? You can use the seq() function. Look at the examples below and work out what the arguments do.\n\nseq(from = -1, to = 1, by = 0.2)\nseq(0, 100, length.out = 11)\nseq(0, 10, along.with = LETTERS)\n\n [1] -1.0 -0.8 -0.6 -0.4 -0.2  0.0  0.2  0.4  0.6  0.8  1.0\n [1]   0  10  20  30  40  50  60  70  80  90 100\n [1]  0.0  0.4  0.8  1.2  1.6  2.0  2.4  2.8  3.2  3.6  4.0  4.4  4.8  5.2  5.6\n[16]  6.0  6.4  6.8  7.2  7.6  8.0  8.4  8.8  9.2  9.6 10.0\n\n\nWhat if you want to repeat a vector many times? You could either type it out (painful) or use the rep() function, which can repeat vectors in different ways.\n\nrep(0, 10)                      # ten zeroes\nrep(c(1L, 3L), times = 7)       # alternating 1 and 3, 7 times\nrep(c(\"A\", \"B\", \"C\"), each = 2) # A to C, 2 times each\n\n [1] 0 0 0 0 0 0 0 0 0 0\n [1] 1 3 1 3 1 3 1 3 1 3 1 3 1 3\n[1] \"A\" \"A\" \"B\" \"B\" \"C\" \"C\"\n\n\nThe rep() function is useful to create a vector of logical values (TRUE/FALSE or 1/0) to select values from another vector.\n\n# Get IDs in the pattern Y Y N N ...\nids &lt;- 1:40\nyynn &lt;- rep(c(TRUE, FALSE), each = 2, \n            length.out = length(ids))\nids[yynn]\n\n [1]  1  2  5  6  9 10 13 14 17 18 21 22 25 26 29 30 33 34 37 38\n\n\n\nH.2.2 Lists\nRecall that vectors can contain data of only one type. What if you want to store a collection of data of different data types? For that purpose you would use a list. Define a list using the list() function.\n\ndata_types &lt;- list(\n  double = 10.0,\n  integer = 10L,\n  character = \"10\",\n  logical = TRUE\n)\n\nstr(data_types) # str() prints lists in a condensed format\n\nList of 4\n $ double   : num 10\n $ integer  : int 10\n $ character: chr \"10\"\n $ logical  : logi TRUE\n\n\nYou can refer to elements of a list using square brackets like a vector, but you can also use the dollar sign notation ($) if the list items have names.\n\ndata_types$logical\n\n[1] TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nExplore the 5 ways shown below to extract a value from a list. What data type is each object? What is the difference between the single and double brackets? Which one is the same as the dollar sign?\n\nbracket1 &lt;- data_types[1]\nbracket2 &lt;- data_types[[1]]\nname1    &lt;- data_types[\"double\"]\nname2    &lt;- data_types[[\"double\"]]\ndollar   &lt;- data_types$double\n\n\n\nThe single brackets (bracket1 and name1) return a list with the subset of items inside the brackets. In this case, that’s just one item, but can be more (try data_types[1:2]). The items keep their names if they have them, so the returned value is list(double = 10).\nThe double brackets (bracket2 and name2 return a single item as a vector. You can’t select more than one item; data_types[[1:2]] will give you a “subscript out of bounds” error.\nThe dollar-sign notation is the same as double-brackets. If the name has spaces or any characters other than letters, numbers, underscores, and full stops, you need to surround the name with backticks (e.g., sales$`Customer ID`).\n\nH.2.3 Tables\nTabular data structures allow for a collection of data of different types (characters, integers, logical, etc.) but subject to the constraint that each “column” of the table (element of the list) must have the same number of elements. The base R version of a table is called a data.frame, while the ‘tidyverse’ version is called a tibble. Tibbles are far easier to work with, so we’ll be using those. To learn more about differences between these two data structures, see vignette(\"tibble\").\n\n# construct a table by column with tibble\navatar &lt;- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\"),\n  bends = c(\"water\", \"earth\", NA),\n  friendly = TRUE\n)\n\n# or by row with tribble\navatar &lt;- tribble(\n  ~name,    ~bends,  ~friendly,\n  \"Katara\", \"water\", TRUE,\n  \"Toph\",   \"earth\", TRUE,\n  \"Sokka\",  NA,      TRUE\n)\n\n\n# export the data to a file\nrio::export(avatar, \"data/avatar.csv\")\n\n# or by importing data from a file\navatar &lt;- rio::import(\"data/avatar.csv\")\n\nTabular data becomes especially important for when we talk about tidy data in ?sec-tidy, which consists of a set of simple principles for structuring data.\n\nH.2.3.1 Table info\nWe can get information about the table using the following functions.\n\n\nncol(): number of columns\n\nnrow(): number of rows\n\ndim(): the number of rows and number of columns\n\nname(): the column names\n\nglimpse(): the column types\n\n\nnrow(avatar)\nncol(avatar)\ndim(avatar)\nnames(avatar)\nglimpse(avatar)\n\n[1] 3\n[1] 3\n[1] 3 3\n[1] \"name\"     \"bends\"    \"friendly\"\nRows: 3\nColumns: 3\n$ name     &lt;chr&gt; \"Katara\", \"Toph\", \"Sokka\"\n$ bends    &lt;chr&gt; \"water\", \"earth\", NA\n$ friendly &lt;lgl&gt; TRUE, TRUE, TRUE\n\n\n\nH.2.3.2 Accessing rows and columns\nThere are various ways of accessing specific columns or rows from a table. You’ll be learning more about this in ?sec-tidy and ?sec-wrangle.\n\nsiblings   &lt;- avatar %&gt;% slice(1, 3) # rows (by number)\nbends      &lt;- avatar %&gt;% pull(2) # column vector (by number)\nfriendly   &lt;- avatar %&gt;% pull(friendly) # column vector (by name)\nbends_name &lt;- avatar %&gt;% select(bends, name) # subset table (by name)\ntoph       &lt;- avatar %&gt;% pull(name) %&gt;% pluck(2) # single cell\n\nThe code below uses base R to produce the same subsets as the functions above. This format is useful to know about, since you might see them in other people’s scripts.\n\n# base R access\n\nsiblings   &lt;- avatar[c(1, 3), ] # rows (by number)\nbends      &lt;- avatar[, 2] # column vector (by number)\nfriendly   &lt;- avatar$friendly  # column vector (by name)\nbends_name &lt;- avatar[, c(\"bends\", \"name\")] # subset table (by name)\ntoph       &lt;- avatar[[2, 1]] # single cell (row, col)"
  },
  {
    "objectID": "app-datatypes.html#sec-glossary-datatypes",
    "href": "app-datatypes.html#sec-glossary-datatypes",
    "title": "Appendix H — Data Types",
    "section": "\nH.3 Glossary",
    "text": "H.3 Glossary\n\n\n\n\n\nterm\n\n\ndefinition\n\n\n\n\n\nbase r\n\n\nThe set of R functions that come with a basic installation of R, before you add external packages.\n\n\n\n\ncharacter\n\n\nA data type representing strings of text.\n\n\n\n\ncoercion\n\n\nChanging the data type of values in a vector to a single compatible type.\n\n\n\n\ndata type\n\n\nThe kind of data represented by an object.\n\n\n\n\ndouble\n\n\nA data type representing a real decimal number\n\n\n\n\nescape\n\n\nInclude special characters like ” inside of a string by prefacing them with a backslash.\n\n\n\n\nextract operator\n\n\nA symbol used to get values from a container object, such as [, [[, or $\n\n\n\n\nfactor\n\n\nA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimenter\n\n\n\n\ninteger\n\n\nA data type representing whole numbers.\n\n\n\n\nlist\n\n\nA container data type that allows items with different data types to be grouped together.\n\n\n\n\nlogical\n\n\nA data type representing TRUE or FALSE values.\n\n\n\n\nnumeric\n\n\nA data type representing a real decimal number or integer.\n\n\n\n\noperator\n\n\nA symbol that performs some mathematical or comparative process.\n\n\n\n\ntabular data\n\n\nData in a rectangular table format, where each row has an entry for each column.\n\n\n\n\ntidy data\n\n\nA format for data that maps the meaning onto the structure.\n\n\n\n\nvector\n\n\nA type of data structure that collects values with the same data type, like T/F values, numbers, or strings."
  },
  {
    "objectID": "app-dates.html#formats",
    "href": "app-dates.html#formats",
    "title": "Appendix I — Dates and Times",
    "section": "\nI.1 Formats",
    "text": "I.1 Formats\nWhile there is only one correct way to write date (The ISO 8601 format of “YYYY-MM-DD”), dates can be found in many formats. When you are reading a data file, you might need to specify the date format so it can be read properly. Date format specification uses abbreviations to represent the different ways people can write. the year, month, and day (as well as hours, minutes, and seconds). For example, the date 2023-01-03 is represented by the formatting string \"%Y-%m-%d. The fastest way to find the list of formatting abbreviations is to look in the help for the function col_date().\n\n\n\nRun in the console\n\n?col_date\n\n\n\n# create a table with some different date formats\ndate_formats &lt;- tibble(\n  best = \"2022-01-03\",\n  ok = \"2022 January 3\",\n  bad = \"January 3, 2022\",\n  terrible = \"Mon is 3 22 1\"\n)\n\n# save it as a CSV file\nwrite_csv(date_formats, \"data/date_formats.csv\")\n\n# read it in\ndf &lt;- read_csv(\"data/date_formats.csv\")\n\nRows: 1 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): ok, bad, terrible\ndate (1): best\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou can see that only the first column read as a date, and the rest read as characters. You can set the date format using the col_types argument and two helper functions, cols() and col_date().\n\nct &lt;- cols(ok = col_date(\"%Y %B %d\"),\n           bad = col_date(\"%B %d, %Y\"),\n           terrible = col_date(\"%a is %m %y %d\"))\n\nread_csv(\"data/date_formats.csv\", \n         col_types = ct)\n\n\n\n\nbest\nok\nbad\nterrible\n\n\n2022-01-03\n2022-01-03\n2022-01-03\n2022-03-01"
  },
  {
    "objectID": "app-dates.html#parsing",
    "href": "app-dates.html#parsing",
    "title": "Appendix I — Dates and Times",
    "section": "\nI.2 Parsing",
    "text": "I.2 Parsing\nThe ymd functions can deal with almost all date formats, regardless of the punctuation used in the format. All of the examples below produce a date in the standard format “2022-01-03”.\n\n# year-month-day orders\nymd(\"22 Jan 3\")\nymd(\"2022 January 3rd\")\n\n# month-day-year orders\nmdy(\"January 3, 2022\")\nmdy(\"Jan/03/22\")\n\n# day-month-year orders\ndmy(\"3JAN22\")\ndmy(\"3rd of January in the year 2022\")\n\n\n\n\n\n\n\nNote\n\n\n\nSee if you can make a date format that one of the parsers can’t handle.\n\n\nThere are similar functions for date/times, too.\n\nymd_hms(\"2022 Jan 3, 6:05 and 20s pm\")\nmdy_h(\"January 3rd, 2022 at 6pm\")\n\n[1] \"2022-01-03 18:05:20 UTC\"\n[1] \"2022-01-03 18:00:00 UTC\"\n\n\nThe date/time functions can also take a timezone argument. If you don’t specify it, it defaults to “UTC”.\n\nymd_hm(\"2022-01-03 18:05\", tz = \"GMT\")\n\n[1] \"2022-01-03 18:05:00 GMT\""
  },
  {
    "objectID": "app-dates.html#get-parts",
    "href": "app-dates.html#get-parts",
    "title": "Appendix I — Dates and Times",
    "section": "\nI.3 Get Parts",
    "text": "I.3 Get Parts\nYou frequently need to extract parts of a date/time for plotting. The following functions extract specific parts of a date or datetime object. This is a godsend for those of us who never have a clue what week of the year it is today.\n\n# get the date and time when this function is run\nnow &lt;- now(tzone = \"GMT\")\n\n# get separate parts\ntime_parts &lt;- list(\n  second  = second(now),\n  minute  = minute(now),\n  hour    = hour(now),\n  day     = day(now),  # day of the month (same as mday())\n  wday    = wday(now), # day of the week\n  yday    = yday(now), # day of the year\n  week    = week(now),\n  isoweek = isoweek(now), # ISO 8501 week calendar (Monday start)\n  epiweek = epiweek(now), # CDC epidemiological week (Sunday Start)\n  month   = month(now),\n  year    = year(now),\n  tz      = tz(now)\n)\n\nstr(time_parts)\n\nList of 12\n $ second : num 47.3\n $ minute : int 10\n $ hour   : int 15\n $ day    : int 20\n $ wday   : num 4\n $ yday   : num 80\n $ week   : num 12\n $ isoweek: num 12\n $ epiweek: num 12\n $ month  : num 3\n $ year   : num 2024\n $ tz     : chr \"GMT\"\n\n\nThe month() and wday() functions can return factor labels.\n\njan1 &lt;- ymd(20220101)\nwday(jan1, label = TRUE)\nwday(jan1, label = TRUE, abbr = TRUE)\nmonth(jan1, label = TRUE)\nmonth(jan1, label = TRUE, abbr = TRUE)\n\n[1] Sat\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n[1] Sat\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n[1] Jan\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n[1] Jan\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat day of the week were you born?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nbirthdate &lt;- ymd(19761118) # put your own birthdate here\nwday(birthdate, label = TRUE)\n\n[1] Thu\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat"
  },
  {
    "objectID": "app-dates.html#date-arithmetic",
    "href": "app-dates.html#date-arithmetic",
    "title": "Appendix I — Dates and Times",
    "section": "\nI.4 Date Arithmetic",
    "text": "I.4 Date Arithmetic\nYou can add and subtract dates. For example, you can get the dates two weeks from today by adding weeks(2) to today(). You can probably guess how to add and subtract seconds, minutes, days, months, and years.\n\ntoday() + weeks(1)\n\n[1] \"2024-03-27\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat day of the week will your 100th birthday be?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nbirthdate &lt;- ymd(19761118) # put your own birthdate here\ncentennial &lt;- birthdate + years(100)\nwday(centennial, label = TRUE, abbr = FALSE)\n\n[1] Wednesday\n7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhat do you think will happen if you subtract one month from March 31st? You get NA, since February doesn’t have a 31st day.\n\nymd(20220331) - months(1)\n\n[1] NA\n\n\nUse the special date operators %m+% and %m-% to add and subtract months without risking an impossible date.\n\nymd(20220331) %m-% months(1)\n\n[1] \"2022-02-28\"\n\n\n\n\n\nI.4.1 First and last of month\nFor things like billing, you might need to find the first or last days of the current, previous, or next month. The rollback() and rollforward() functions are easier than trying to parse dates.\n\nd &lt;- ymd(\"2022-01-24\")\nrollback(d)                          # last day of the previous month\nrollforward(d)                       # last day of the current month\nrollback(d, roll_to_first = TRUE)    # first day of the current month\nrollforward(d, roll_to_first = TRUE) # first day of the next month\n\n[1] \"2021-12-31\"\n[1] \"2022-01-31\"\n[1] \"2022-01-01\"\n[1] \"2022-02-01\"\n\n\n\nI.4.2 Rounding\nYou can round dates and times to the nearest unit. This can be useful when you have, for example, time measured to the nearest second, but want to group data by the nearest hour, rather than extract the hour component.\n\nymd_hm(\"2022-01-24 10:25\") %&gt;% round_date(unit = \"hour\")\nymd_hm(\"2022-01-24 10:30\") %&gt;% round_date(unit = \"hour\")\nymd_hm(\"2022-01-24 10:35\") %&gt;% round_date(unit = \"hour\")\n\n[1] \"2022-01-24 10:00:00 UTC\"\n[1] \"2022-01-24 11:00:00 UTC\"\n[1] \"2022-01-24 11:00:00 UTC\""
  },
  {
    "objectID": "app-dates.html#internationalisation",
    "href": "app-dates.html#internationalisation",
    "title": "Appendix I — Dates and Times",
    "section": "\nI.5 Internationalisation",
    "text": "I.5 Internationalisation\nYou may need to work with dates from a different locale than your computer’s defaults, such as dates written in French or Russian. Or your computer may have a non-English locale. Set the locale argument to the relevant language code.\n\nymd(\"2022 January 24\", locale = \"en_GB\")\nymd(\"2022 Janvier 24\", locale = \"fr_FR\")\nwday(\"2022-01-03\", label = TRUE, locale = \"ru_RU\")\n\n[1] \"2022-01-24\"\n[1] \"2022-01-24\"\n[1] пн\nLevels: вс &lt; пн &lt; вт &lt; ср &lt; чт &lt; пт &lt; сб\n\n\nSome of the locale functions only work on unix-based machines, like Macs or machines running linux.\n\n# check your own locale; doesn't work for Windows\nlocale()\n\n&lt;locale&gt;\nNumbers:  123,456.78\nFormats:  %AD / %AT\nTimezone: UTC\nEncoding: UTF-8\n&lt;date_names&gt;\nDays:   Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday\n        (Thu), Friday (Fri), Saturday (Sat)\nMonths: January (Jan), February (Feb), March (Mar), April (Apr), May (May),\n        June (Jun), July (Jul), August (Aug), September (Sep), October\n        (Oct), November (Nov), December (Dec)\nAM/PM:  AM/PM\n\n\n\n# check which locales are available on your computer\n# doesn't work for Windows\nsystem(\"locale -a\")"
  },
  {
    "objectID": "app-dates.html#example",
    "href": "app-dates.html#example",
    "title": "Appendix I — Dates and Times",
    "section": "\nI.6 Example",
    "text": "I.6 Example\nLet’s work through some examples with downloaded tweets from the class data.\n\n# read all metrics files in data/tweets/\ntweets &lt;- list.files(\n  path = \"data/tweets\", \n  pattern = \"^tweet_activity_metrics\",\n  full.names = TRUE\n) %&gt;%\n  map_df(read_csv) %&gt;%\n  select(!starts_with(\"promoted\"))\n\nThe time column is already in date/time (POSIXct) format, but what if we wanted to plot tweets by hour for each day of the week?\n\ntweets %&gt;%\n  mutate(weekday = wday(time, label = TRUE),\n         hour = hour(time)) %&gt;%\n  ggplot(aes(x = hour, fill = weekday)) +\n  geom_bar(size = 1, alpha = 0.5, show.legend = FALSE) +\n  facet_grid(~weekday) +\n  scale_fill_manual(values = rainbow(7)) +\n  scale_x_continuous(breaks = seq(0, 24, 4))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nA nice side-effect of using the lubridate function to get days of the week or months of the year is that the results are an ordered factor, so display correctly in a plot. Let’s display the months in Greek (if that’s available on your system).\n\ntweets %&gt;%\n  mutate(month = month(time, label = TRUE, abbr = FALSE, locale = \"el_GR.UTF-8\")) %&gt;%\n  ggplot(aes(x = month, fill = month)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = NULL, guide = guide_axis(n.dodge=2))"
  },
  {
    "objectID": "app-styling.html#aesthetics",
    "href": "app-styling.html#aesthetics",
    "title": "Appendix J — Styling Plots",
    "section": "\nJ.1 Aesthetics",
    "text": "J.1 Aesthetics\n\nJ.1.1 Colour/Fill\nThe colour argument changes the point and line colour, while the fill argument changes the interior colour of shapes. Type colours() into the console to see a list of all the named colours in R. Alternatively, you can use hexadecimal colours like \"#FF8000\" or the rgb() function to set red, green, and blue values on a scale from 0 to 1.\nHover over a colour to see its R name.\n\n\n\n\nblack\n\n\ngray1\n\n\ngray2\n\n\ngray3\n\n\ngray4\n\n\ngray5\n\n\ngray6\n\n\ngray7\n\n\ngray8\n\n\ngray9\n\n\ngray10\n\n\ngray11\n\n\ngray12\n\n\ngray13\n\n\ngray14\n\n\ngray15\n\n\ngray16\n\n\ngray17\n\n\ngray18\n\n\ngray19\n\n\ngray20\n\n\ngray21\n\n\ngray22\n\n\ngray23\n\n\ngray24\n\n\ngray25\n\n\ngray26\n\n\ngray27\n\n\ngray28\n\n\ngray29\n\n\ngray30\n\n\ngray31\n\n\ngray32\n\n\ngray33\n\n\ngray34\n\n\ngray35\n\n\ngray36\n\n\ngray37\n\n\ngray38\n\n\ngray39\n\n\ngray40\n\n\ndimgray\n\n\ngray42\n\n\ngray43\n\n\ngray44\n\n\ngray45\n\n\ngray46\n\n\ngray47\n\n\ngray48\n\n\ngray49\n\n\ngray50\n\n\ngray51\n\n\ngray52\n\n\ngray53\n\n\ngray54\n\n\ngray55\n\n\ngray56\n\n\ngray57\n\n\ngray58\n\n\ngray59\n\n\ngray60\n\n\ngray61\n\n\ngray62\n\n\ngray63\n\n\ngray64\n\n\ngray65\n\n\ndarkgray\n\n\ngray66\n\n\ngray67\n\n\ngray68\n\n\ngray69\n\n\ngray70\n\n\ngray71\n\n\ngray72\n\n\ngray73\n\n\ngray74\n\n\ngray\n\n\ngray75\n\n\ngray76\n\n\ngray77\n\n\ngray78\n\n\ngray79\n\n\ngray80\n\n\ngray81\n\n\ngray82\n\n\ngray83\n\n\nlightgray\n\n\ngray84\n\n\ngray85\n\n\ngainsboro\n\n\ngray86\n\n\ngray87\n\n\ngray88\n\n\ngray89\n\n\ngray90\n\n\ngray91\n\n\ngray92\n\n\ngray93\n\n\ngray94\n\n\ngray95\n\n\ngray96\n\n\ngray97\n\n\ngray98\n\n\ngray99\n\n\nwhite\n\n\nsnow4\n\n\nsnow3\n\n\nsnow2\n\n\nsnow\n\n\nrosybrown4\n\n\nrosybrown\n\n\nrosybrown3\n\n\nrosybrown2\n\n\nrosybrown1\n\n\nlightcoral\n\n\nindianred\n\n\nindianred4\n\n\nindianred2\n\n\nindianred1\n\n\nindianred3\n\n\nbrown4\n\n\nbrown\n\n\nbrown3\n\n\nbrown2\n\n\nbrown1\n\n\nfirebrick4\n\n\nfirebrick\n\n\nfirebrick3\n\n\nfirebrick1\n\n\nfirebrick2\n\n\ndarkred\n\n\nred3\n\n\nred2\n\n\nred\n\n\nmistyrose3\n\n\nmistyrose4\n\n\nmistyrose2\n\n\nmistyrose\n\n\nsalmon\n\n\ntomato3\n\n\ncoral4\n\n\ncoral3\n\n\ncoral2\n\n\ncoral1\n\n\ntomato2\n\n\ntomato\n\n\ntomato4\n\n\ndarksalmon\n\n\nsalmon4\n\n\nsalmon3\n\n\nsalmon2\n\n\nsalmon1\n\n\ncoral\n\n\norangered4\n\n\norangered3\n\n\norangered2\n\n\nlightsalmon3\n\n\nlightsalmon2\n\n\nlightsalmon\n\n\nlightsalmon4\n\n\nsienna\n\n\nsienna3\n\n\nsienna2\n\n\nsienna1\n\n\nsienna4\n\n\norangered\n\n\nseashell4\n\n\nseashell3\n\n\nseashell2\n\n\nseashell\n\n\nchocolate4\n\n\nchocolate3\n\n\nchocolate\n\n\nchocolate2\n\n\nchocolate1\n\n\nlinen\n\n\npeachpuff4\n\n\npeachpuff3\n\n\npeachpuff2\n\n\npeachpuff\n\n\nsandybrown\n\n\ntan4\n\n\nperu\n\n\ntan2\n\n\ntan1\n\n\ndarkorange4\n\n\ndarkorange3\n\n\ndarkorange2\n\n\ndarkorange1\n\n\nantiquewhite3\n\n\nantiquewhite2\n\n\nantiquewhite1\n\n\nbisque4\n\n\nbisque3\n\n\nbisque2\n\n\nbisque\n\n\nburlywood4\n\n\nburlywood3\n\n\nburlywood\n\n\nburlywood2\n\n\nburlywood1\n\n\ndarkorange\n\n\nantiquewhite4\n\n\nantiquewhite\n\n\npapayawhip\n\n\nblanchedalmond\n\n\nnavajowhite4\n\n\nnavajowhite3\n\n\nnavajowhite2\n\n\nnavajowhite\n\n\ntan\n\n\nfloralwhite\n\n\noldlace\n\n\nwheat4\n\n\nwheat3\n\n\nwheat2\n\n\nwheat\n\n\nwheat1\n\n\nmoccasin\n\n\norange4\n\n\norange3\n\n\norange2\n\n\norange\n\n\ngoldenrod\n\n\ngoldenrod1\n\n\ngoldenrod4\n\n\ngoldenrod3\n\n\ngoldenrod2\n\n\ndarkgoldenrod4\n\n\ndarkgoldenrod\n\n\ndarkgoldenrod3\n\n\ndarkgoldenrod2\n\n\ndarkgoldenrod1\n\n\ncornsilk\n\n\ncornsilk4\n\n\ncornsilk3\n\n\ncornsilk2\n\n\nlightgoldenrod4\n\n\nlightgoldenrod3\n\n\nlightgoldenrod\n\n\nlightgoldenrod2\n\n\nlightgoldenrod1\n\n\ngold4\n\n\ngold3\n\n\ngold2\n\n\ngold\n\n\nlemonchiffon4\n\n\nlemonchiffon3\n\n\nlemonchiffon2\n\n\nlemonchiffon\n\n\npalegoldenrod\n\n\nkhaki\n\n\ndarkkhaki\n\n\nkhaki4\n\n\nkhaki3\n\n\nkhaki2\n\n\nkhaki1\n\n\nivory4\n\n\nivory3\n\n\nivory2\n\n\nivory\n\n\nbeige\n\n\nlightyellow4\n\n\nlightyellow3\n\n\nlightyellow2\n\n\nlightyellow\n\n\nlightgoldenrodyellow\n\n\nyellow4\n\n\nyellow3\n\n\nyellow2\n\n\nyellow\n\n\nolivedrab\n\n\nolivedrab4\n\n\nolivedrab3\n\n\nolivedrab2\n\n\nolivedrab1\n\n\ndarkolivegreen\n\n\ndarkolivegreen4\n\n\ndarkolivegreen3\n\n\ndarkolivegreen2\n\n\ndarkolivegreen1\n\n\ngreenyellow\n\n\nchartreuse4\n\n\nchartreuse3\n\n\nchartreuse2\n\n\nlawngreen\n\n\nchartreuse\n\n\nhoneydew4\n\n\nhoneydew3\n\n\nhoneydew2\n\n\nhoneydew\n\n\ndarkseagreen4\n\n\ndarkseagreen\n\n\ndarkseagreen3\n\n\ndarkseagreen2\n\n\ndarkseagreen1\n\n\nlightgreen\n\n\npalegreen\n\n\npalegreen4\n\n\npalegreen3\n\n\npalegreen1\n\n\nforestgreen\n\n\nlimegreen\n\n\ndarkgreen\n\n\ngreen4\n\n\ngreen3\n\n\ngreen2\n\n\ngreen\n\n\nmediumseagreen\n\n\nseagreen\n\n\nseagreen3\n\n\nseagreen2\n\n\nseagreen1\n\n\nmintcream\n\n\nspringgreen4\n\n\nspringgreen3\n\n\nspringgreen2\n\n\nspringgreen\n\n\naquamarine3\n\n\naquamarine2\n\n\naquamarine\n\n\nmediumspringgreen\n\n\naquamarine4\n\n\nturquoise\n\n\nmediumturquoise\n\n\nlightseagreen\n\n\nazure4\n\n\nazure3\n\n\nazure2\n\n\nazure\n\n\nlightcyan4\n\n\nlightcyan3\n\n\nlightcyan2\n\n\nlightcyan\n\n\npaleturquoise\n\n\npaleturquoise4\n\n\npaleturquoise3\n\n\npaleturquoise2\n\n\npaleturquoise1\n\n\ndarkslategray\n\n\ndarkslategray4\n\n\ndarkslategray3\n\n\ndarkslategray2\n\n\ndarkslategray1\n\n\ncyan4\n\n\ncyan3\n\n\ndarkturquoise\n\n\ncyan2\n\n\ncyan\n\n\ncadetblue4\n\n\ncadetblue\n\n\nturquoise4\n\n\nturquoise3\n\n\nturquoise2\n\n\nturquoise1\n\n\npowderblue\n\n\ncadetblue3\n\n\ncadetblue2\n\n\ncadetblue1\n\n\nlightblue4\n\n\nlightblue3\n\n\nlightblue\n\n\nlightblue2\n\n\nlightblue1\n\n\ndeepskyblue4\n\n\ndeepskyblue3\n\n\ndeepskyblue2\n\n\ndeepskyblue\n\n\nskyblue\n\n\nlightskyblue4\n\n\nlightskyblue3\n\n\nlightskyblue2\n\n\nlightskyblue1\n\n\nlightskyblue\n\n\nskyblue4\n\n\nskyblue3\n\n\nskyblue2\n\n\nskyblue1\n\n\naliceblue\n\n\nslategray\n\n\nlightslategray\n\n\nslategray3\n\n\nslategray2\n\n\nslategray1\n\n\nsteelblue4\n\n\nsteelblue\n\n\nsteelblue3\n\n\nsteelblue2\n\n\nsteelblue1\n\n\ndodgerblue4\n\n\ndodgerblue3\n\n\ndodgerblue2\n\n\ndodgerblue\n\n\nlightsteelblue4\n\n\nlightsteelblue3\n\n\nlightsteelblue\n\n\nlightsteelblue2\n\n\nlightsteelblue1\n\n\nslategray4\n\n\ncornflowerblue\n\n\nroyalblue\n\n\nroyalblue4\n\n\nroyalblue3\n\n\nroyalblue2\n\n\nroyalblue1\n\n\nghostwhite\n\n\nlavender\n\n\nmidnightblue\n\n\nnavy\n\n\nblue4\n\n\nblue3\n\n\nblue2\n\n\nblue\n\n\ndarkslateblue\n\n\nslateblue\n\n\nmediumslateblue\n\n\nlightslateblue\n\n\nslateblue1\n\n\nslateblue4\n\n\nslateblue3\n\n\nslateblue2\n\n\nmediumpurple4\n\n\nmediumpurple3\n\n\nmediumpurple\n\n\nmediumpurple2\n\n\nmediumpurple1\n\n\npurple4\n\n\npurple3\n\n\nblueviolet\n\n\npurple1\n\n\npurple2\n\n\npurple\n\n\ndarkorchid\n\n\ndarkorchid4\n\n\ndarkorchid3\n\n\ndarkorchid2\n\n\ndarkorchid1\n\n\ndarkviolet\n\n\nmediumorchid4\n\n\nmediumorchid3\n\n\nmediumorchid\n\n\nmediumorchid2\n\n\nmediumorchid1\n\n\nthistle4\n\n\nthistle3\n\n\nthistle\n\n\nthistle2\n\n\nthistle1\n\n\nplum4\n\n\nplum3\n\n\nplum2\n\n\nplum1\n\n\nplum\n\n\nviolet\n\n\ndarkmagenta\n\n\nmagenta3\n\n\nmagenta2\n\n\nmagenta\n\n\norchid4\n\n\norchid3\n\n\norchid\n\n\norchid2\n\n\norchid1\n\n\nmaroon4\n\n\nvioletred\n\n\nmaroon3\n\n\nmaroon2\n\n\nmaroon1\n\n\nmediumvioletred\n\n\ndeeppink3\n\n\ndeeppink2\n\n\ndeeppink\n\n\ndeeppink4\n\n\nhotpink2\n\n\nhotpink1\n\n\nhotpink4\n\n\nhotpink\n\n\nvioletred4\n\n\nvioletred3\n\n\nvioletred2\n\n\nvioletred1\n\n\nhotpink3\n\n\nlavenderblush4\n\n\nlavenderblush3\n\n\nlavenderblush2\n\n\nlavenderblush\n\n\nmaroon\n\n\npalevioletred4\n\n\npalevioletred3\n\n\npalevioletred\n\n\npalevioletred2\n\n\npalevioletred1\n\n\npink4\n\n\npink3\n\n\npink2\n\n\npink1\n\n\npink\n\n\nlightpink\n\n\nlightpink4\n\n\nlightpink3\n\n\nlightpink2\n\n\nlightpink1\n\n\n\n\nJ.1.2 Alpha\nThe alpha argument changes transparency (0 = totally transparent, 1 = totally opaque).\n\n\n\n\nVarying alpha values.\n\n\n\n\nJ.1.3 Shape\nThe shape argument changes the shape of points.\n\n\n\n\nThe 25 shape values\n\n\n\n\nJ.1.4 Linetype\nYou can probably guess what the linetype argument does.\n\n\n\n\nThe 6 linetype values at different sizes."
  },
  {
    "objectID": "app-styling.html#palettes",
    "href": "app-styling.html#palettes",
    "title": "Appendix J — Styling Plots",
    "section": "\nJ.2 Palettes",
    "text": "J.2 Palettes\nDiscrete palettes change depending on the number of categories.\n\n\n\n\nDefault discrete palette with different numbers of levels.\n\n\n\n\nJ.2.1 Viridis Palettes\nViridis palettes are very good for colourblind-safe and greyscale-safe plots. The work with any number of categories, but are best for larger numbers of categories or continuous colours.\n\nJ.2.1.1 Discrete Viridis Palettes\nSet discrete viridis colours with scale_colour_viridis_d() or scale_fill_viridis_d() and set the option argument to one of the options below. Set direction = -1 to reverse the order of colours.\n\n\n\n\nDiscrete viridis palettes.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the end colour is too light for your plot or the start colour too dark, you can set the begin and end arguments to values between 0 and 1, such as scale_colour_viridis_c(begin = .1, end = .9).\n\n\n\nJ.2.1.2 Continuous Viridis Palettes\nSet continuous viridis colours with scale_colour_viridis_c() or scale_fill_viridis_c() and set the option argument to one of the options below. Set direction = -1 to reverse the order of colours.\n\n\n\n\nContinuous viridis palettes.\n\n\n\n\nJ.2.2 Brewer Palettes\nBrewer palettes give you a lot of control over plot colour and fill. You set them with scale_color_brewer() or scale_fill_brewer() and set the palette argument to one of the palettes below. Set direction = -1 to reverse the order of colours.\n\nJ.2.2.1 Qualitative Brewer Palettes\nThese palettes are good for categorical data with up to 8 categories (some palettes can handle up to 12). The “Paired” palette is useful if your categories are arranged in pairs.\n\n\n\n\nQualitative brewer palettes.\n\n\n\n\nJ.2.2.2 Sequential Brewer Palettes\nThese palettes are good for up to 9 ordinal categories with a lot of categories.\n\n\n\n\nSequential brewer palettes.\n\n\n\n\nJ.2.2.3 Diverging Brewer Palettes\nThese palettes are good for ordinal categories with up to 11 levels where the centre level is a neutral or baseline category and the levels above and below it differ in an important way, such as agree versus disagree options.\n\n\n\n\nDiverging brewer palettes."
  },
  {
    "objectID": "app-styling.html#sec-themes-appendix",
    "href": "app-styling.html#sec-themes-appendix",
    "title": "Appendix J — Styling Plots",
    "section": "\nJ.3 Themes",
    "text": "J.3 Themes\nggplot2 has 8 built-in themes that you can add to a plot like plot + theme_bw() or set as the default theme at the top of your script like theme_set(theme_bw()).\n\n\n\n\n{ggplot2} themes.\n\n\n\n\nJ.3.1 ggthemes\nYou can get more themes from add-on packages, like ggthemes”, “https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/”). Most of the themes also have customscale_functions likescale_colour_economist()`. Their website has extensive examples and instructions for alternate or dark versions of these themes.\n\n\n\n\n{ggthemes} themes.\n\n\n\n\nJ.3.2 Fonts\nYou can customise the fonts used in themes. All computers should be able to recognise the families “sans”, “serif”, and “mono”, and some computers will be able to access other installed fonts by name.\n\nsans &lt;- g + theme_bw(base_family = \"sans\") + \n  ggtitle(\"Sans\")\nserif &lt;- g + theme_bw(base_family = \"serif\") + \n  ggtitle(\"Serif\")\nmono &lt;- g + theme_bw(base_family = \"mono\") + \n  ggtitle(\"Mono\")\nfont &lt;- g + theme_bw(base_family = \"Comic Sans MS\") + \n  ggtitle(\"Comic Sans MS\")\n\nsans + serif + mono + font + plot_layout(nrow = 1)\n\n\n\nDifferent fonts.\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you are working on a Windows machine and get the error “font family not found in Windows font database”, you may need to explicitly map the fonts. In your setup code chunk, add the following code, which should fix the error. You may need to do this for any fonts that you specify.\n\n\nThe showtext package is a flexible way to add fonts.\nIf you have a .ttf file from a font site, like Font Squirrel, you can load the file directly using font_add(). Set regular as the path to the file for the regular version of the font, and optionally add other versions. Set the family to the name you want to use for the font. You will need to include any local font files if you are sharing your script with others.\n\nlibrary(showtext)\n\n# font from https://www.fontsquirrel.com/fonts/SF-Cartoonist-Hand\n\nfont_add(\n  regular = \"fonts/cartoonist/SF_Cartoonist_Hand.ttf\",\n  bold = \"fonts/cartoonist/SF_Cartoonist_Hand_Bold.ttf\",\n  italic = \"fonts/cartoonist/SF_Cartoonist_Hand_Italic.ttf\",\n  bolditalic = \"fonts/cartoonist/SF_Cartoonist_Hand_Bold_Italic.ttf\",\n  family = \"cartoonist\" \n)\n\nTo download fonts directly from Google fonts, use the function font_add_google(), set the name to the exact name from the site, and the family to the name you want to use for the font.\n\n# download fonts from Google\nfont_add_google(name = \"Courgette\", family = \"courgette\")\nfont_add_google(name = \"Poiret One\", family = \"poiret\")\n\nAfter you’ve added fonts from local files or Google, you need to make them available to R using showtext_auto(). You will have to do these steps in each script where you want to use the custom fonts.\n\nshowtext_auto() # load the fonts\n\nTo change the fonts used overall in a plot, use the theme() function and set text to element_text(family = \"new_font_family\").\n\na &lt;- g + theme(text = element_text(family = \"courgette\")) +\n  ggtitle(\"Courgette\")\nb &lt;- g + theme(text = element_text(family = \"cartoonist\")) +\n  ggtitle(\"Cartoonist Hand\")\nc &lt;- g + theme(text = element_text(family = \"poiret\")) +\n  ggtitle(\"Poiret One\")\n\na + b + c\n\n\n\nCustom Fonts.\n\n\n\nTo set the fonts for individual elements in the plot, you need to find the specific argument for that element. You can use the argument face to choose “bold”, “italic”, or “bolditalic” versions, if they are available.\n\ng + ggtitle(\"Cartoonist Hand\") +\n  theme(\n    title = element_text(family = \"cartoonist\", face = \"bold\"),\n    strip.text = element_text(family = \"cartoonist\", face = \"italic\"),\n    axis.text = element_text(family = \"sans\")\n  )\n\n\n\nMultiple custom fonts on the same plot."
  },
  {
    "objectID": "app-webpage.html#sec-webpage-create",
    "href": "app-webpage.html#sec-webpage-create",
    "title": "Appendix K — Webpages",
    "section": "\nK.1 Create a webpage",
    "text": "K.1 Create a webpage\n\nK.1.1 Create a project\n\nChoose New Project... from the File menu (don’t save any workspaces)\nChoose New Directory &gt; Simple R Markdown Website\n\nSet your project name to “mywebpage”\n\nK.1.2 Site header\nThis is where you can set options like whether to show a table of contents and what the navigation bar will look like. We’ll edit this later to add a section menu.\n\nOpen the file _site.yml\n\nReplace the text with the following:\nname: \"mywebpage\"  \nauthor: \"YOUR NAME\"  \noutput_dir: \"docs\"  \noutput:  \n  html_document:  \n    self_contained: no  \n    theme: \n      version: 4\n      bootswatch: yeti \nnavbar:  \n  title: \"My First Webpage\"  \n    left:\n    - text: \"Home\"\n      href: index.html\n    - text: \"About\"\n      href: about.html\n\nSave the file (do not change the name)\n\nK.1.3 Edit the pages\nEdit the text in the index.Rmd and about.Rmd pages. You can use R markdown, including code chunks.\n\nK.1.4 Render the site\nIn the upper right “Build” pane, click on the “Build website” hammer icon. This will render the website and automatically open it in a browser window. Alternatively, type the following into the Console pane:\n\nbrowseURL(rmarkdown::render_site(encoding = 'UTF-8'))\n\nIf you accidentally close the website and want to look at it again, you don’t have to re-render it. Click on the docs directory in the Files tab of the lower right pane, then click on index.html and choose View in Web Browser."
  },
  {
    "objectID": "app-webpage.html#sec-webpage-pages",
    "href": "app-webpage.html#sec-webpage-pages",
    "title": "Appendix K — Webpages",
    "section": "\nK.2 Add pages",
    "text": "K.2 Add pages\n\nCreate a new .Rmd file for each webpage\nAdd content to the webpages using R Markdown\nRe-render the site\n\nIf you include linked content like image files, make sure they are copied to your main project directory and linked using relative paths.\nTo get your webpage online, copy the contents of the docs directory to a web server. If you don’t have access to a web server, you can make free websites using a GitHub repository and GitHub Pages)."
  },
  {
    "objectID": "app-webpage.html#sec-webpage-styles",
    "href": "app-webpage.html#sec-webpage-styles",
    "title": "Appendix K — Webpages",
    "section": "\nK.3 Styles",
    "text": "K.3 Styles\nYou can change the appearance of your website by changing the theme in the _site.yml file (see Appendix J), but the instructions below will help you to customise things even further.\n\nK.3.1 Add custom styles\nYou can add a custom style sheet (a document that determines how each element of your website should look) by adding the line css: style.css under html_document: in the _site.yml file.\noutput:  \n  html_document:  \n    self_contained: no  \n    theme: \n      version: 4\n      bootswatch: readable\n    css: style.css\nThen you need to create a file named style.css and add your custom styles there. The web has thousands of guides to CSS, but codeacademy has great interactive tutorials for learning html, css, and even more advanced web coding like javascript.\nHowever, the basics of css are easy to learn and it’s best to just start playing around with it. Add the following text to your style.css file and re-render the website.\n\nK.3.2 Change global fonts and colours\nbody {\n  font-size: 2em;\n  font-family: \"Times New Roman\";\n  color: white;\n  background-color: #660000;\n}\n\n\nThis will make the text on your website larger, a different font, and change the text and background colours.\n\nThe theme you’re using might have css that blocks the styles you’re trying to change. You can add !important before the end colon to override that.\n\nK.3.3 Change certain elements\nMaybe you only want to change the font colour for your headings, not the rest of the text. You can apply a style to a specific element type by specifying the element name before the curly brackets.\nh1, h2, h3 {\n  text-align: center;\n  color: hsl(0, 100%, 20%);\n}\n\nh3 {\n  font-style: italic;\n}\n\np {\n  border: 1px solid green;\n  padding: 10px;\n  line-height: 2;\n}\n\nul {\n  border: 3px dotted red;\n  border-radius: 10px;\n  padding: 10px 30px;\n}"
  },
  {
    "objectID": "app-webpage.html#example-using-the-styles-above",
    "href": "app-webpage.html#example-using-the-styles-above",
    "title": "Appendix K — Webpages",
    "section": "\nK.4 Example using the styles above",
    "text": "K.4 Example using the styles above\nThe CSS above changes the styles for three levels of headers (h2, h3, h4) and sets the third level to italics.\n\nK.4.1 Level 3 header\nIt also gives paragraphs (p) a green border and double-spacing.\n\nK.4.1.1 Level 4 header\nUnordered Lists (ul) get:\n\ndotted red border\nround corners\nincreased padding on top (10px) and sides (30px)"
  }
]